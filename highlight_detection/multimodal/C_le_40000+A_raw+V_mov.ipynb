{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "\n",
    "        with open('./data/chat_feature_real.pickle',\"rb\") as f1:  \n",
    "            self.chat_result=pickle.load(f1)\n",
    "        \n",
    "        with open('./LSTM_feature_extractor_Audio_13_ver2/features',\"rb\") as f2:  \n",
    "            self.audio=json.load(f2)\n",
    "        with open('./video_raw_feature_sum_moving_average/video_feature.pickle',\"rb\") as f2:  \n",
    "            self.video=pickle.load(f2)\n",
    "        with open('./label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.real_result[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            for idx in range(7): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<len(self.real_result[game_id]):\n",
    "                    s_window+=((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=self.video[game_id][vframe+idx]\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*384\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([[-0.00925446, -0.20702465, -0.01853031, ..., -0.04624566,\n",
      "        -0.14462242, -0.06322261],\n",
      "       [-0.00232657, -0.13041367, -0.09969565, ..., -0.04575907,\n",
      "        -0.1425308 , -0.06174482],\n",
      "       [-0.13500546, -0.34459695, -0.09441447, ..., -0.04569324,\n",
      "        -0.14201146, -0.06145829],\n",
      "       ...,\n",
      "       [-0.0023752 , -0.14328398, -0.00136574, ..., -0.04594754,\n",
      "        -0.14237592, -0.06187927],\n",
      "       [-0.00104911, -0.45583484, -0.03600711, ..., -0.04616952,\n",
      "        -0.14312899, -0.06243758],\n",
      "       [-0.00051031, -0.10495079, -0.00081716, ..., -0.04634051,\n",
      "        -0.14388086, -0.06295124]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "\n",
    "print(train[100])\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=40000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[100][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=384\n",
    "hidden_size=128\n",
    "length=7\n",
    "num_layers=3\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,3,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=LSTM().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_dir='./C_le_40000+A_raw+V_mov_7/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.3808926045894623,p 0.6839399547604359, r 0.7342163355408389, f 0.7081869477270307\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.482410192489624,p 0.5641309504981813, r 0.7874172185430464, f 0.6573297705703492\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.45492297410964966,p 0.6088149545532499, r 0.7836644591611479, f 0.6852620403435963\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.4068935811519623,p 0.6617950159265505, r 0.779690949227373, f 0.7159217594000202\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.40065470337867737,p 0.632481624081204, r 0.7977924944812362, f 0.7055837563451778\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.39577263593673706,p 0.6600587371512482, r 0.7938189845474614, f 0.7207857286029266\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.3762287497520447,p 0.6276865797935353, r 0.8187637969094923, f 0.7106044640291216\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.3994317650794983,p 0.6020793950850661, r 0.8437086092715231, f 0.7027027027027026\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.35353440046310425,p 0.6334621199395263, r 0.8324503311258278, f 0.7194505389678527\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.4348161518573761,p 0.5751672862453532, r 0.8538631346578367, f 0.6873389604620169\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.35715052485466003,p 0.6283215051988777, r 0.8403973509933775, f 0.7190480687505902\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.4462200701236725,p 0.5686131386861314, r 0.8598233995584988, f 0.6845342706502636\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.38069456815719604,p 0.6010563927295324, r 0.854083885209713, f 0.7055712592322422\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.3439943194389343,p 0.6200225697243269, r 0.8490066225165563, f 0.7166682195099227\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0 , val_loss : 0.3091558814048767,p 0.6295136026380874, r 0.8428256070640177, f 0.7207173194903256\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0 , val_loss : 0.3313954174518585,p 0.6280367695338148, r 0.8445916114790287, f 0.7203916399924685\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0 , val_loss : 0.31707829236984253,p 0.6338308457711442, r 0.8437086092715231, f 0.7238636363636364\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0 , val_loss : 0.4067845046520233,p 0.5710955710955711, r 0.8653421633554084, f 0.6880814463752852\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0 , val_loss : 0.29385438561439514,p 0.6411903956712884, r 0.8370860927152318, f 0.7261585599387208\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0 , val_loss : 0.3273649215698242,p 0.627121409921671, r 0.8483443708609272, f 0.7211484331018952\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0 , val_loss : 0.321821391582489,p 0.6201550387596899, r 0.847682119205298, f 0.7162842753217683\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0 , val_loss : 0.3583795428276062,p 0.6153477218225419, r 0.8496688741721854, f 0.713769123783032\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.3259733319282532,p 0.6289081682763137, r 0.8481236203090508, f 0.7222483316101138\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.3698296844959259,p 0.574736225087925, r 0.8657836644591611, f 0.6908578474546415\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.3527272045612335,p 0.612867530825166, r 0.8558498896247241, f 0.7142593957258659\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.3348526358604431,p 0.617765597291633, r 0.8459161147902869, f 0.7140594428398398\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.306445837020874,p 0.6359416445623343, r 0.8467991169977925, f 0.7263775800037872\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.3865240812301636,p 0.5829250185597624, r 0.8666666666666667, f 0.6970261873058144\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.3632974922657013,p 0.6189863234111022, r 0.8492273730684327, f 0.7160539785946952\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.41816917061805725,p 0.5654778887303852, r 0.8750551876379691, f 0.6870017331022531\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.326644629240036,p 0.6343605036447979, r 0.8452538631346579, f 0.7247775884913874\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.32167932391166687,p 0.6237671786580437, r 0.8516556291390729, f 0.7201119925338312\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.3057989180088043,p 0.6430268069222939, r 0.8366445916114791, f 0.727168073676132\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.3474554419517517,p 0.5959177409453652, r 0.8571743929359823, f 0.7030599311968132\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.3885160982608795,p 0.5628563283922463, r 0.8717439293598234, f 0.6840464230036377\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.43083953857421875,p 0.5229465449804432, r 0.885430463576159, f 0.6575409836065573\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.38281500339508057,p 0.5727603787327021, r 0.8679911699779249, f 0.6901272487933304\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.3416005074977875,p 0.5820627802690583, r 0.8596026490066225, f 0.6941176470588235\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.32821014523506165,p 0.6189561319244317, r 0.8534216335540838, f 0.7175204157386785\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.3330243229866028,p 0.6230670103092784, r 0.8538631346578367, f 0.7204321102626189\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.38794147968292236,p 0.5812712994517706, r 0.8660044150110375, f 0.6956290451281141\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.3561432361602783,p 0.5927382753403934, r 0.8649006622516556, f 0.703411131059246\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.3580908477306366,p 0.5804351043362439, r 0.8657836644591611, f 0.694958802161779\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.2899739444255829,p 0.6304455038632254, r 0.8465783664459161, f 0.722698577216621\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.35614854097366333,p 0.5886706948640483, r 0.8602649006622517, f 0.6990134529147982\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.3478425443172455,p 0.6220497898480439, r 0.8494481236203091, f 0.7181784247853676\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.30921170115470886,p 0.618932819029251, r 0.8501103752759381, f 0.7163318452380952\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.30148306488990784,p 0.6317970822281167, r 0.841280353200883, f 0.7216436281007385\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.3141595721244812,p 0.6317434210526316, r 0.8479028697571744, f 0.7240339302544769\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.3771474063396454,p 0.5731225296442688, r 0.8642384105960265, f 0.6891998943754951\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.31744179129600525,p 0.6175438596491228, r 0.8547461368653422, f 0.717037037037037\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.3492478132247925,p 0.584068151247945, r 0.8626931567328918, f 0.6965511095267801\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.3737373352050781,p 0.603931279987618, r 0.8613686534216336, f 0.7100354835774724\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.3026030659675598,p 0.6221540448893913, r 0.850551876379691, f 0.7186421710342256\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.4198382496833801,p 0.5551197646729233, r 0.8748344370860928, f 0.6792355814551375\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.32975324988365173,p 0.6119828815977175, r 0.8523178807947019, f 0.7124273456960973\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.33295950293540955,p 0.6090965926852141, r 0.8602649006622517, f 0.7132137628111275\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0 , val_loss : 0.3474965989589691,p 0.6128981393882056, r 0.8580573951434879, f 0.7150478292862398\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0 , val_loss : 0.36638039350509644,p 0.593939393939394, r 0.8653421633554084, f 0.7044025157232704\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0 , val_loss : 0.3014734089374542,p 0.6336092715231788, r 0.844812362030905, f 0.7241248817407758\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0 , val_loss : 0.3280792236328125,p 0.6207285622179239, r 0.8501103752759381, f 0.7175330724799701\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0 , val_loss : 0.3087482452392578,p 0.628785411917942, r 0.8525386313465784, f 0.7237631184407797\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0 , val_loss : 0.3363093137741089,p 0.6068309419837804, r 0.8589403973509934, f 0.7112045329921404\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0 , val_loss : 0.36904990673065186,p 0.5698299665746258, r 0.8655629139072848, f 0.6872316186136185\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0 , val_loss : 0.34598150849342346,p 0.5957123308499316, r 0.8649006622516556, f 0.7055010353830917\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0 , val_loss : 0.34000542759895325,p 0.6187290969899666, r 0.8576158940397351, f 0.7188454066056064\n",
      "\n",
      "66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66 train_loss : 0 , val_loss : 0.3249671459197998,p 0.6193589539148461, r 0.8573951434878587, f 0.7191926673456162\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0 , val_loss : 0.2946758270263672,p 0.6349784696919509, r 0.8463576158940397, f 0.7255866767600303\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0 , val_loss : 0.2778470516204834,p 0.6521363085971286, r 0.8322295805739515, f 0.7312578799340511\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0 , val_loss : 0.3012472689151764,p 0.6271872974724563, r 0.8545253863134658, f 0.7234161838908616\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0 , val_loss : 0.35283520817756653,p 0.6005522319374137, r 0.8642384105960265, f 0.7086614173228346\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0 , val_loss : 0.3073374629020691,p 0.6311045558833169, r 0.8501103752759381, f 0.7244168547780285\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0 , val_loss : 0.34185683727264404,p 0.5691304347826087, r 0.866887417218543, f 0.6871391076115485\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0 , val_loss : 0.36818501353263855,p 0.5897628339837887, r 0.8673289183222959, f 0.702108649035025\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0 , val_loss : 0.2949454188346863,p 0.6398128029416681, r 0.8450331125827815, f 0.7282412251498146\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0 , val_loss : 0.35219982266426086,p 0.5967888518630718, r 0.869757174392936, f 0.7078692058929215\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0 , val_loss : 0.38096243143081665,p 0.581333725894303, r 0.8717439293598234, f 0.6975183255321027\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0 , val_loss : 0.34911444783210754,p 0.5913410770855333, r 0.8653421633554084, f 0.702571915046151\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0 , val_loss : 0.3476991057395935,p 0.5865586558655865, r 0.8631346578366446, f 0.6984637370489459\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0 , val_loss : 0.2843168377876282,p 0.6466178224569773, r 0.8377483443708609, f 0.7298778728723915\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0 , val_loss : 0.3200272023677826,p 0.6258876694641704, r 0.8560706401766004, f 0.7231027410031697\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0 , val_loss : 0.45235851407051086,p 0.5377981404123433, r 0.8810154525386313, f 0.6678939000920424\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0 , val_loss : 0.3529101014137268,p 0.598776758409786, r 0.8644591611479029, f 0.7074977416440831\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0 , val_loss : 0.3531644642353058,p 0.6126154327750821, r 0.8640176600441501, f 0.7169154684494916\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0 , val_loss : 0.30581608414649963,p 0.6337820091923835, r 0.8523178807947019, f 0.726981736019582\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0 , val_loss : 0.3457822799682617,p 0.6200031852205765, r 0.8593818984547461, f 0.7203256545471366\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0 , val_loss : 0.3077261745929718,p 0.6322138897945876, r 0.8560706401766004, f 0.7273068267066767\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0 , val_loss : 0.3277715742588043,p 0.6163382072472982, r 0.8560706401766004, f 0.7166882276843467\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0 , val_loss : 0.3645833432674408,p 0.6075870646766169, r 0.8626931567328918, f 0.7130085750775406\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0 , val_loss : 0.34957361221313477,p 0.6331041257367387, r 0.8536423841059603, f 0.7270163564579809\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0 , val_loss : 0.317262202501297,p 0.6340860392286138, r 0.8492273730684327, f 0.7260545437387941\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0 , val_loss : 0.2847777009010315,p 0.6468395187256397, r 0.8426048565121412, f 0.7318569648164126\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0 , val_loss : 0.33367040753364563,p 0.6212582039378902, r 0.8567328918322296, f 0.7202375429154683\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0 , val_loss : 0.4075923562049866,p 0.5570987654320988, r 0.8766004415011037, f 0.6812489277749185\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0 , val_loss : 0.3094920814037323,p 0.6118980169971672, r 0.8582781456953642, f 0.7144432194046307\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0 , val_loss : 0.357124924659729,p 0.5879194630872483, r 0.8701986754966887, f 0.70173564753004\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0 , val_loss : 0.35120487213134766,p 0.6141534599089911, r 0.8640176600441501, f 0.7179675318719618\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0 , val_loss : 0.3142048418521881,p 0.6251806648466356, r 0.8593818984547461, f 0.7238077530910105\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0 , val_loss : 0.31922346353530884,p 0.6165876777251185, r 0.8615894039735099, f 0.7187845303867404\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0 , val_loss : 0.3188331723213196,p 0.6207775653282346, r 0.8600441501103753, f 0.7210808809920416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(100):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out,_=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out,_=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "8 0 23 1 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 16 14 tensor(2) tensor(16)\n",
      "14 0 15 3 tensor(14) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 6 14 3 tensor(15) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "14 0 14 4 tensor(14) tensor(18)\n",
      "6 1 23 2 tensor(7) tensor(8)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "10 0 19 3 tensor(10) tensor(13)\n",
      "6 16 10 0 tensor(22) tensor(6)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 2 17 0 tensor(15) tensor(13)\n",
      "3 5 24 0 tensor(8) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 6 19 0 tensor(13) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 1 14 1 tensor(17) tensor(17)\n",
      "3 20 1 8 tensor(23) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 2 17 0 tensor(15) tensor(13)\n",
      "22 5 4 1 tensor(27) tensor(23)\n",
      "10 19 3 0 tensor(29) tensor(10)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 26 6 0 tensor(26) tensor(0)\n",
      "28 0 2 2 tensor(28) tensor(30)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "8 2 19 3 tensor(10) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 3 17 0 tensor(15) tensor(12)\n",
      "7 8 15 2 tensor(15) tensor(9)\n",
      "15 7 6 4 tensor(22) tensor(19)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 10 3 tensor(19) tensor(22)\n",
      "16 0 15 1 tensor(16) tensor(17)\n",
      "25 0 4 3 tensor(25) tensor(28)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "13 5 10 4 tensor(18) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "17 6 8 1 tensor(23) tensor(18)\n",
      "7 9 16 0 tensor(16) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "8 20 4 0 tensor(28) tensor(8)\n",
      "9 0 22 1 tensor(9) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "10 10 12 0 tensor(20) tensor(10)\n",
      "17 4 10 1 tensor(21) tensor(18)\n",
      "5 8 19 0 tensor(13) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 10 6 0 tensor(26) tensor(16)\n",
      "21 0 7 4 tensor(21) tensor(25)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 8 13 0 tensor(19) tensor(11)\n",
      "15 0 14 3 tensor(15) tensor(18)\n",
      "15 7 7 3 tensor(22) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 12 6 0 tensor(26) tensor(14)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "14 0 17 1 tensor(14) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "14 0 15 3 tensor(14) tensor(17)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 23 2 tensor(7) tensor(9)\n",
      "10 10 9 3 tensor(20) tensor(13)\n",
      "10 1 21 0 tensor(11) tensor(10)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "11 10 11 0 tensor(21) tensor(11)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 9 20 0 tensor(12) tensor(3)\n",
      "20 8 4 0 tensor(28) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 22 0 tensor(10) tensor(8)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "27 3 2 0 tensor(30) tensor(27)\n",
      "24 3 4 1 tensor(27) tensor(25)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "12 15 5 0 tensor(27) tensor(12)\n",
      "17 5 8 2 tensor(22) tensor(19)\n",
      "6 18 8 0 tensor(24) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "22 3 6 1 tensor(25) tensor(23)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "5 0 24 3 tensor(5) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 7 23 0 tensor(9) tensor(2)\n",
      "23 0 3 6 tensor(23) tensor(29)\n",
      "7 10 6 9 tensor(17) tensor(16)\n",
      "16 1 15 0 tensor(17) tensor(16)\n",
      "19 13 0 0 tensor(32) tensor(19)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 4 27 0 tensor(5) tensor(1)\n",
      "15 0 14 3 tensor(15) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 27 3 tensor(2) tensor(5)\n",
      "13 0 5 14 tensor(13) tensor(27)\n",
      "10 5 15 2 tensor(15) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 5 6 tensor(21) tensor(27)\n",
      "18 3 8 3 tensor(21) tensor(21)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 1 16 2 tensor(14) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 8 11 2 tensor(19) tensor(13)\n",
      "14 8 10 0 tensor(22) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 2 19 0 tensor(13) tensor(11)\n",
      "15 0 16 1 tensor(15) tensor(16)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "22 6 2 2 tensor(28) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "14 0 16 2 tensor(14) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 20 2 tensor(10) tensor(10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "17 5 10 0 tensor(22) tensor(17)\n",
      "8 5 14 5 tensor(13) tensor(13)\n",
      "10 5 17 0 tensor(15) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "14 9 9 0 tensor(23) tensor(14)\n",
      "4 0 21 7 tensor(4) tensor(11)\n",
      "9 19 3 1 tensor(28) tensor(10)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 8 9 0 tensor(23) tensor(15)\n",
      "7 0 23 2 tensor(7) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "3 18 11 0 tensor(21) tensor(3)\n",
      "31 0 0 1 tensor(31) tensor(32)\n",
      "18 0 12 2 tensor(18) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "28 0 3 1 tensor(28) tensor(29)\n",
      "8 0 20 4 tensor(8) tensor(12)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 1 10 5 tensor(17) tensor(21)\n",
      "13 3 3 13 tensor(16) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 1 29 0 tensor(3) tensor(2)\n",
      "18 0 12 2 tensor(18) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "22 0 8 2 tensor(22) tensor(24)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "10 1 21 0 tensor(11) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 6 2 5 tensor(25) tensor(24)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "17 0 10 5 tensor(17) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 13 4 tensor(15) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 4 11 tensor(17) tensor(28)\n",
      "6 15 9 2 tensor(21) tensor(8)\n",
      "16 4 11 1 tensor(20) tensor(17)\n",
      "3 0 28 1 tensor(3) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 4 20 0 tensor(12) tensor(8)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 18 1 0 tensor(31) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "6 8 18 0 tensor(14) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 15 1 tensor(16) tensor(17)\n",
      "11 1 18 2 tensor(12) tensor(13)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 18 5 tensor(9) tensor(14)\n",
      "5 16 11 0 tensor(21) tensor(5)\n",
      "0 8 19 5 tensor(8) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 16 12 0 tensor(20) tensor(4)\n",
      "17 6 9 0 tensor(23) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "19 0 11 2 tensor(19) tensor(21)\n",
      "29 0 1 2 tensor(29) tensor(31)\n",
      "14 0 18 0 tensor(14) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 9 3 tensor(20) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "18 4 4 6 tensor(22) tensor(24)\n",
      "9 0 21 2 tensor(9) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 10 7 0 tensor(25) tensor(15)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "4 10 13 5 tensor(14) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "27 0 0 5 tensor(27) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "8 4 20 0 tensor(12) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 16 2 0 tensor(30) tensor(14)\n",
      "5 0 25 2 tensor(5) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 5 19 0 tensor(13) tensor(8)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "13 11 0 8 tensor(24) tensor(21)\n",
      "26 3 0 3 tensor(29) tensor(29)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "27 0 0 5 tensor(27) tensor(32)\n",
      "12 4 16 0 tensor(16) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "23 0 0 9 tensor(23) tensor(32)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 11 5 tensor(16) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 23 5 tensor(4) tensor(9)\n",
      "27 0 2 3 tensor(27) tensor(30)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "12 2 15 3 tensor(14) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 5 17 0 tensor(15) tensor(10)\n",
      "3 0 28 1 tensor(3) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 22 0 tensor(10) tensor(8)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 22 1 tensor(9) tensor(10)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "12 7 13 0 tensor(19) tensor(12)\n",
      "2 3 27 0 tensor(5) tensor(2)\n",
      "5 12 14 1 tensor(17) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 3 6 3 tensor(23) tensor(23)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 9 18 0 tensor(14) tensor(5)\n",
      "4 13 10 5 tensor(17) tensor(9)\n",
      "0 3 18 11 tensor(3) tensor(11)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "5 0 25 2 tensor(5) tensor(7)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 16 4 tensor(12) tensor(16)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 10 12 0 tensor(20) tensor(10)\n",
      "26 0 0 6 tensor(26) tensor(32)\n",
      "2 1 27 2 tensor(3) tensor(4)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 10 12 0 tensor(20) tensor(10)\n",
      "1 0 29 2 tensor(1) tensor(3)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "1 0 24 7 tensor(1) tensor(8)\n",
      "23 0 3 6 tensor(23) tensor(29)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 14 11 0 tensor(21) tensor(7)\n",
      "25 0 4 3 tensor(25) tensor(28)\n",
      "9 5 18 0 tensor(14) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "10 3 18 1 tensor(13) tensor(11)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 23 3 tensor(6) tensor(9)\n",
      "7 0 23 2 tensor(7) tensor(9)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "4 6 22 0 tensor(10) tensor(4)\n",
      "0 27 5 0 tensor(27) tensor(0)\n",
      "8 15 7 2 tensor(23) tensor(10)\n",
      "11 5 15 1 tensor(16) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 5 24 0 tensor(8) tensor(3)\n",
      "20 5 4 3 tensor(25) tensor(23)\n",
      "8 8 15 1 tensor(16) tensor(9)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 10 15 7 tensor(10) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "12 9 11 0 tensor(21) tensor(12)\n",
      "11 0 12 9 tensor(11) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "7 13 12 0 tensor(20) tensor(7)\n",
      "0 1 29 2 tensor(1) tensor(2)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "8 2 22 0 tensor(10) tensor(8)\n",
      "17 6 3 6 tensor(23) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 7 6 2 tensor(24) tensor(19)\n",
      "2 11 19 0 tensor(13) tensor(2)\n",
      "8 0 13 11 tensor(8) tensor(19)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 30 2 0 tensor(30) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "16 0 3 13 tensor(16) tensor(29)\n",
      "10 0 19 3 tensor(10) tensor(13)\n",
      "2 15 13 2 tensor(17) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "11 13 6 2 tensor(24) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 4 9 4 tensor(19) tensor(19)\n",
      "22 8 0 2 tensor(30) tensor(24)\n",
      "3 1 28 0 tensor(4) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "17 0 13 2 tensor(17) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "7 10 13 2 tensor(17) tensor(9)\n",
      "13 9 10 0 tensor(22) tensor(13)\n",
      "16 7 4 5 tensor(23) tensor(21)\n",
      "15 0 15 2 tensor(15) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "11 3 18 0 tensor(14) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "11 0 17 4 tensor(11) tensor(15)\n",
      "7 9 14 2 tensor(16) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "22 0 7 3 tensor(22) tensor(25)\n",
      "12 0 9 11 tensor(12) tensor(23)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "6 9 17 0 tensor(15) tensor(6)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "24 5 3 0 tensor(29) tensor(24)\n",
      "11 14 6 1 tensor(25) tensor(12)\n",
      "4 13 15 0 tensor(17) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 5 11 0 tensor(21) tensor(16)\n",
      "5 0 17 10 tensor(5) tensor(15)\n",
      "12 2 18 0 tensor(14) tensor(12)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 0 20 3 tensor(9) tensor(12)\n",
      "1 14 17 0 tensor(15) tensor(1)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "16 4 7 5 tensor(20) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "24 8 0 0 tensor(32) tensor(24)\n",
      "3 0 28 1 tensor(3) tensor(4)\n",
      "3 7 22 0 tensor(10) tensor(3)\n",
      "22 0 3 7 tensor(22) tensor(29)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 5 26 0 tensor(6) tensor(1)\n",
      "20 6 6 0 tensor(26) tensor(20)\n",
      "21 2 8 1 tensor(23) tensor(22)\n",
      "10 0 20 2 tensor(10) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 11 1 tensor(20) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 3 18 1 tensor(13) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 2 21 0 tensor(11) tensor(9)\n",
      "5 0 25 2 tensor(5) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "22 3 0 7 tensor(25) tensor(29)\n",
      "22 6 4 0 tensor(28) tensor(22)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "14 4 12 2 tensor(18) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 9 7 tensor(16) tensor(23)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "22 0 0 10 tensor(22) tensor(32)\n",
      "25 4 0 3 tensor(29) tensor(28)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "8 24 0 0 tensor(32) tensor(8)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 25 0 tensor(7) tensor(7)\n",
      "3 1 28 0 tensor(4) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 0 7 2 tensor(23) tensor(25)\n",
      "18 0 13 1 tensor(18) tensor(19)\n",
      "12 9 10 1 tensor(21) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 15 8 tensor(9) tensor(17)\n",
      "20 0 8 4 tensor(20) tensor(24)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "17 12 2 1 tensor(29) tensor(18)\n",
      "8 8 9 7 tensor(16) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "29 0 1 2 tensor(29) tensor(31)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 3 10 2 tensor(20) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 5 19 0 tensor(13) tensor(8)\n",
      "23 5 1 3 tensor(28) tensor(26)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "16 10 4 2 tensor(26) tensor(18)\n",
      "30 1 1 0 tensor(31) tensor(30)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 9 5 4 tensor(23) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 3 21 0 tensor(11) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 7 12 4 tensor(16) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 13 17 0 tensor(15) tensor(2)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 6 5 0 tensor(27) tensor(21)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "4 3 25 0 tensor(7) tensor(4)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6 26 0 tensor(6) tensor(0)\n",
      "28 4 0 0 tensor(32) tensor(28)\n",
      "3 13 14 2 tensor(16) tensor(5)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "23 3 6 0 tensor(26) tensor(23)\n",
      "13 3 15 1 tensor(16) tensor(14)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "7 7 18 0 tensor(14) tensor(7)\n",
      "29 1 2 0 tensor(30) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "22 8 2 0 tensor(30) tensor(22)\n",
      "7 7 18 0 tensor(14) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "19 7 4 2 tensor(26) tensor(21)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 16 0 tensor(16) tensor(16)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 10 19 tensor(3) tensor(22)\n",
      "22 0 3 7 tensor(22) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 2 13 2 tensor(17) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 3 27 0 tensor(5) tensor(2)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "17 0 9 6 tensor(17) tensor(23)\n",
      "11 3 18 0 tensor(14) tensor(11)\n",
      "2 13 17 0 tensor(15) tensor(2)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 3 17 1 tensor(14) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 11 15 0 tensor(17) tensor(6)\n",
      "10 16 4 2 tensor(26) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "28 0 1 3 tensor(28) tensor(31)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 12 11 0 tensor(21) tensor(9)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 5 9 4 tensor(19) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 19 6 tensor(7) tensor(13)\n",
      "15 0 10 7 tensor(15) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "17 0 6 9 tensor(17) tensor(26)\n",
      "2 15 15 0 tensor(17) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "23 0 0 9 tensor(23) tensor(32)\n",
      "2 0 26 4 tensor(2) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "19 10 3 0 tensor(29) tensor(19)\n",
      "9 0 15 8 tensor(9) tensor(17)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "23 7 0 2 tensor(30) tensor(25)\n",
      "12 5 15 0 tensor(17) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 3 21 0 tensor(11) tensor(8)\n",
      "12 9 11 0 tensor(21) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "16 12 3 1 tensor(28) tensor(17)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "3 0 28 1 tensor(3) tensor(4)\n",
      "3 11 18 0 tensor(14) tensor(3)\n",
      "25 0 0 7 tensor(25) tensor(32)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "25 5 2 0 tensor(30) tensor(25)\n",
      "10 3 19 0 tensor(13) tensor(10)\n",
      "21 0 9 2 tensor(21) tensor(23)\n",
      "8 5 19 0 tensor(13) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "12 0 19 1 tensor(12) tensor(13)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 12 17 0 tensor(15) tensor(3)\n",
      "22 7 2 1 tensor(29) tensor(23)\n",
      "27 5 0 0 tensor(32) tensor(27)\n",
      "8 0 21 3 tensor(8) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 3 16 0 tensor(16) tensor(13)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 14 3 tensor(15) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 0 1 8 tensor(23) tensor(31)\n",
      "14 0 11 7 tensor(14) tensor(21)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "6 0 24 2 tensor(6) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 2 21 0 tensor(11) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 4 20 0 tensor(12) tensor(8)\n",
      "10 0 17 5 tensor(10) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 0 6 3 tensor(23) tensor(26)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 10 1 tensor(21) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 0 14 4 tensor(14) tensor(18)\n",
      "21 3 8 0 tensor(24) tensor(21)\n",
      "12 5 15 0 tensor(17) tensor(12)\n",
      "10 0 18 4 tensor(10) tensor(14)\n",
      "20 8 4 0 tensor(28) tensor(20)\n",
      "5 10 17 0 tensor(15) tensor(5)\n",
      "11 6 13 2 tensor(17) tensor(13)\n",
      "14 6 12 0 tensor(20) tensor(14)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "5 0 22 5 tensor(5) tensor(10)\n",
      "3 2 27 0 tensor(5) tensor(3)\n",
      "16 10 6 0 tensor(26) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 3 28 0 tensor(4) tensor(1)\n",
      "18 11 3 0 tensor(29) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "15 0 2 15 tensor(15) tensor(30)\n",
      "3 0 25 4 tensor(3) tensor(7)\n",
      "31 0 0 1 tensor(31) tensor(32)\n",
      "29 2 1 0 tensor(31) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "22 5 5 0 tensor(27) tensor(22)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "5 11 16 0 tensor(16) tensor(5)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "24 0 7 1 tensor(24) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 4 7 0 tensor(25) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 7 16 3 tensor(13) tensor(9)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "1 0 24 7 tensor(1) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 8 9 15 tensor(8) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 3 28 0 tensor(4) tensor(1)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "1 20 11 0 tensor(21) tensor(1)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "12 13 7 0 tensor(25) tensor(12)\n",
      "20 8 4 0 tensor(28) tensor(20)\n",
      "21 0 10 1 tensor(21) tensor(22)\n",
      "12 3 2 0 tensor(15) tensor(12)\n",
      "5340 3002 894\n",
      "[1100/1101], prec:0.6401342603692161, recall:0.8565928777670837, f1:73.27113062568607, acc: 0.8893716103018429\n"
     ]
    }
   ],
   "source": [
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output,_=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212431058132\n",
      "precision : 0.6316831683168317, recall : 0.8372703412073491, f1 : 0.7200902934537246, accuracy : 0.8993506493506493\n",
      "102844341902586509\n",
      "precision : 0.5501165501165501, recall : 0.932806324110672, f1 : 0.6920821114369502, accuracy : 0.90177736202058\n",
      "102844401152267937\n",
      "precision : 0.6601073345259392, recall : 0.917910447761194, f1 : 0.7679500520291362, accuracy : 0.9025775447793797\n",
      "102844212430927059\n",
      "precision : 0.6707466340269278, recall : 0.8303030303030303, f1 : 0.7420446851726472, accuracy : 0.899815934788325\n",
      "102844412708953395\n",
      "precision : 0.5943152454780362, recall : 0.8333333333333334, f1 : 0.693815987933635, accuracy : 0.9012645914396887\n",
      "102844212429944013\n",
      "precision : 0.6227180527383367, recall : 0.8274932614555256, f1 : 0.710648148148148, accuracy : 0.8778103616813294\n",
      "102844341912679064\n",
      "precision : 0.5638629283489096, recall : 0.8008849557522124, f1 : 0.6617915904936015, accuracy : 0.904639175257732\n",
      "102844235753749959\n",
      "precision : 0.5794573643410853, recall : 0.7608142493638677, f1 : 0.6578657865786578, accuracy : 0.8596570397111913\n",
      "102844341908026005\n",
      "precision : 0.61345496009122, recall : 0.8163884673748103, f1 : 0.7005208333333334, accuracy : 0.8423037367158039\n",
      "102844283023206486\n",
      "precision : 0.6161228406909789, recall : 0.8991596638655462, f1 : 0.7312072892938498, accuracy : 0.87117903930131\n",
      "102844224147717245\n",
      "precision : 0.6532066508313539, recall : 0.8870967741935484, f1 : 0.7523939808481532, accuracy : 0.9013086150490731\n",
      "102844412704890154\n",
      "precision : 0.6204690831556503, recall : 0.9478827361563518, f1 : 0.75, accuracy : 0.9065060240963856\n",
      "102844212430599377\n",
      "precision : 0.5240641711229946, recall : 0.8305084745762712, f1 : 0.6426229508196721, accuracy : 0.9066381156316916\n",
      "102844412711443769\n",
      "precision : 0.7780645161290323, recall : 0.8893805309734514, f1 : 0.8300068823124571, accuracy : 0.9029088050314465\n",
      "102844235747982779\n",
      "precision : 0.714123006833713, recall : 0.8648275862068966, f1 : 0.7822832189644416, accuracy : 0.8720674486803519\n",
      "==precision : 0.6261675004498373, recall : 0.858404011775604, f1 : 0.722354920721227, accuracy : 0.8899869629023293\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('./label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
