{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레인함과 동시에 f1스코어 계산 & csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=json.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=json.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=json.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio['102844412722519367'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:1\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=json.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=json.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=json.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = int(chat_size)+int(audio_size)+int(video_size)\n",
    "            \n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "                    s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=list(self.video[game_id][vframe+idx])\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "\n",
      "\n",
      "datset testing....\n",
      "('102844412722519367', array([[ 0.02620566,  0.0118512 , -0.02706682, ...,  0.03830636,\n",
      "         0.12896176,  0.06082911],\n",
      "       [-0.06698951, -0.03389126, -0.00954571, ...,  0.03830636,\n",
      "         0.12896176,  0.06082911],\n",
      "       [-0.06153676, -0.02784403, -0.01758359, ...,  0.03830636,\n",
      "         0.12896176,  0.06082911],\n",
      "       ...,\n",
      "       [-0.08774932, -0.03491368, -0.01236366, ...,  0.03830636,\n",
      "         0.12896176,  0.06082911],\n",
      "       [-0.0150439 , -0.00701944, -0.01754227, ...,  0.03830636,\n",
      "         0.12896176,  0.06082911],\n",
      "       [ 0.01076563,  0.00668381, -0.01694852, ...,  0.03830636,\n",
      "         0.12896176,  0.06082911]]), 0)\n",
      "23\n",
      "\n",
      "****************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('test')## 그래프 그리기위해 val 없이 test로 바로진행\n",
    "\n",
    "#test\n",
    "print(\"\\n\\ndatset testing....\")\n",
    "print(train[0])\n",
    "print(len(train[100][1]))\n",
    "print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "#loader행\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "global input_size,hidden_size,num_layers\n",
    "input_size=total_size\n",
    "hidden_size=conf['trn_args']['hidden_size']\n",
    "num_layers=conf['trn_args']['num_layer']\n",
    "\n",
    "print(input_size)\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = conf['trn_args']['lr']\n",
    "\n",
    "model=LSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.3853747844696045,p 0.573218233498263, r 0.8734359961501443, f 0.6921756816881713\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.32972151041030884,p 0.5836923739767341, r 0.8692653192171961, f 0.6984147441680629\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.37819090485572815,p 0.55372229400656, r 0.8936477382098171, f 0.6837680270021479\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.33566612005233765,p 0.6174036415228187, r 0.8376644209175489, f 0.7108630547236592\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.32345324754714966,p 0.560637977730966, r 0.8965351299326275, f 0.6898722458803925\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.3285118341445923,p 0.5517410495340853, r 0.9023099133782483, f 0.6847647452675149\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.27946168184280396,p 0.6185377086931491, r 0.8617260186076355, f 0.7201555064012333\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.3060380816459656,p 0.5949435180204411, r 0.8870709015078602, f 0.7122158542082555\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.29391032457351685,p 0.6007159127888058, r 0.888354186717998, f 0.7167540283440109\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.3329333961009979,p 0.5746018866010751, r 0.9087263394289381, f 0.7040328092959672\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.3049924373626709,p 0.58012066673484, r 0.9100096246390761, f 0.7085493036907513\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.2655409276485443,p 0.6368231046931407, r 0.848893166506256, f 0.7277227722772277\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.3023405969142914,p 0.5663887759251728, r 0.8936477382098171, f 0.6933416303671438\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.29036980867385864,p 0.5944402542829437, r 0.884985563041386, f 0.7111827263938125\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0 , val_loss : 0.31589603424072266,p 0.5675621491579792, r 0.9082451074751363, f 0.6985811227637261\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0 , val_loss : 0.28617584705352783,p 0.6105967651979922, r 0.8780879050368945, f 0.7203105467464964\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0 , val_loss : 0.31634190678596497,p 0.5472817764165391, r 0.917228103946102, f 0.6855293130320106\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0 , val_loss : 0.26610976457595825,p 0.6348281194242893, r 0.856111645813282, f 0.7290485622566765\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0 , val_loss : 0.2860172390937805,p 0.6056743876759393, r 0.8766442091754892, f 0.7163924755849774\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0 , val_loss : 0.2691577076911926,p 0.6188803263825929, r 0.8760025665704203, f 0.7253287289148624\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0 , val_loss : 0.29695627093315125,p 0.5925142736307888, r 0.8989412897016362, f 0.714249299005863\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0 , val_loss : 0.2845726013183594,p 0.6039408866995074, r 0.884985563041386, f 0.7179387077884053\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.3053027093410492,p 0.5876752458673362, r 0.9010266281681104, f 0.7113728470111449\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.2926279604434967,p 0.5950369023424965, r 0.8923644529996791, f 0.7139831868061348\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.2880900204181671,p 0.6015200868621065, r 0.8886750080205326, f 0.7174307174307174\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.2802432179450989,p 0.6081021576398062, r 0.8861084376002567, f 0.7212429821125473\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.29450663924217224,p 0.5988987259771108, r 0.8897978825794033, f 0.7159266907589056\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.2869754433631897,p 0.6013902465515368, r 0.8881937760667308, f 0.7171815296936727\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.2839307188987732,p 0.6133870606671143, r 0.879050368944498, f 0.7225738396624473\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.29887619614601135,p 0.591791517197721, r 0.8997433429579724, f 0.7139765784114053\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.2873309254646301,p 0.6025068119891008, r 0.8867500802053256, f 0.7175027581283665\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.2906907796859741,p 0.603561284684291, r 0.8862688482515239, f 0.7180920197556538\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.33365899324417114,p 0.5617647058823529, r 0.9191530317613089, f 0.6973347937203358\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.30684518814086914,p 0.5800613496932515, r 0.9100096246390761, f 0.7085050580741852\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.30898356437683105,p 0.5816127375449409, r 0.9082451074751363, f 0.7091239276097439\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.2830123007297516,p 0.6044051902736888, r 0.8891562399743344, f 0.7196364816617982\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.25880956649780273,p 0.6340425531914894, r 0.8604427333974976, f 0.7300939158840344\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.28950363397598267,p 0.5971223021582733, r 0.8920436316971447, f 0.7153791728307711\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.2663593292236328,p 0.6230240549828179, r 0.8724735322425409, f 0.726944667201283\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.2900790274143219,p 0.5985643882579815, r 0.896214308630093, f 0.717754367934224\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.29487258195877075,p 0.5948843133092762, r 0.8991017003529035, f 0.7160194174757281\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.308022677898407,p 0.5778323610684679, r 0.9056785370548605, f 0.7055295220243674\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.2765684723854065,p 0.616271186440678, r 0.8748796920115496, f 0.7231503579952268\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.26688218116760254,p 0.6226738212124672, r 0.8748796920115496, f 0.7275395184419395\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.3033972680568695,p 0.5952863389143649, r 0.8954122553737568, f 0.7151367625392352\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.30995458364486694,p 0.5838335748292279, r 0.9048764837985243, f 0.7097382989431303\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.3042825162410736,p 0.5821171634121275, r 0.9085659287776708, f 0.7095965923327489\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.29591986536979675,p 0.600988928302698, r 0.896855951235162, f 0.7197013580485293\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.32928919792175293,p 0.568802781917536, r 0.9183509785049727, f 0.7024970857107797\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.33202046155929565,p 0.5545498314877226, r 0.9238049406480591, f 0.6930621577712257\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.33272120356559753,p 0.5554048818287486, r 0.919794674366378, f 0.6925957241212707\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.3096337616443634,p 0.5812858312858313, r 0.9108116778954123, f 0.7096612923384578\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.2860078811645508,p 0.6034856029443603, r 0.8942893808148861, f 0.7206566701137539\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.2778732180595398,p 0.6057378830688981, r 0.8941289701636189, f 0.7222078258616222\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.37244823575019836,p 0.5194399857321206, r 0.9343920436316971, f 0.6676983035304905\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.29952481389045715,p 0.5849740932642487, r 0.9055181264035932, f 0.7107781415260639\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.2811943292617798,p 0.5979744136460554, r 0.8997433429579724, f 0.718457794287178\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0 , val_loss : 0.2758472263813019,p 0.6130820399113082, r 0.8870709015078602, f 0.7250557230890259\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0 , val_loss : 0.2904711663722992,p 0.603304892536991, r 0.8960538979788258, f 0.7210998515458595\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0 , val_loss : 0.2944147288799286,p 0.5891011587848418, r 0.9051973051010587, f 0.7137165623221401\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0 , val_loss : 0.2708197236061096,p 0.6263521288837745, r 0.8731151748476099, f 0.729429107477888\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0 , val_loss : 0.27238866686820984,p 0.6222727272727273, r 0.8784087263394289, f 0.7284821072236265\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0 , val_loss : 0.2727692425251007,p 0.60872424375274, r 0.890920757138274, f 0.7232712592785518\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0 , val_loss : 0.2812608778476715,p 0.6068814855270344, r 0.8912415784408084, f 0.7220742088504776\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0 , val_loss : 0.2915242314338684,p 0.597618034878775, r 0.9015078601219121, f 0.7187619900242997\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0 , val_loss : 0.271992564201355,p 0.6068246033470984, r 0.8957330766762913, f 0.7235034983156258\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0 , val_loss : 0.29652783274650574,p 0.5855640037496094, r 0.9018286814244466, f 0.7100726239343227\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0 , val_loss : 0.3081541061401367,p 0.5769974554707379, r 0.909367982034007, f 0.7060215455507814\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0 , val_loss : 0.2696317434310913,p 0.6169332289453081, r 0.8848251523901187, f 0.7269851729818781\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0 , val_loss : 0.3137766718864441,p 0.5815617334423548, r 0.9127366057106192, f 0.7104507429142215\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0 , val_loss : 0.27377840876579285,p 0.6147742512293249, r 0.88241899262111, f 0.7246739560005269\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0 , val_loss : 0.269945353269577,p 0.6088480070083224, r 0.8918832210458775, f 0.7236756475335155\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0 , val_loss : 0.2972719669342041,p 0.5988210075026795, r 0.896214308630093, f 0.7179388332048317\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0 , val_loss : 0.29577749967575073,p 0.5915015365052453, r 0.8954122553737568, f 0.7123986982324038\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0 , val_loss : 0.3110639452934265,p 0.5730190571715146, r 0.9164260506897658, f 0.7051345346827944\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0 , val_loss : 0.2702636420726776,p 0.6230982019363762, r 0.8671799807507219, f 0.7251509054325956\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0 , val_loss : 0.2986243665218353,p 0.5930708661417323, r 0.9061597690086621, f 0.7169236626689511\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0 , val_loss : 0.2664415240287781,p 0.623087462891071, r 0.8753609239653513, f 0.7279882604055495\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0 , val_loss : 0.29487720131874084,p 0.5943545829368855, r 0.9018286814244466, f 0.7164978015675778\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0 , val_loss : 0.28043824434280396,p 0.6181942700604954, r 0.8687840872633943, f 0.7223741247082361\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0 , val_loss : 0.2887994050979614,p 0.5994666666666667, r 0.9015078601219121, f 0.7200973797168301\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0 , val_loss : 0.3092748522758484,p 0.5836680053547524, r 0.9092075713827398, f 0.7109438695515836\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0 , val_loss : 0.30995607376098633,p 0.5821826736217653, r 0.9130574270131536, f 0.7110111798138778\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0 , val_loss : 0.2924940884113312,p 0.5972620184654569, r 0.9027911453320501, f 0.7189116689020886\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0 , val_loss : 0.2855513393878937,p 0.6027293404094011, r 0.8926852743022137, f 0.7195965604189565\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0 , val_loss : 0.27882006764411926,p 0.6135292797846085, r 0.8772858517805582, f 0.7220755215209927\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0 , val_loss : 0.3019789755344391,p 0.5840826873385013, r 0.9064805903111967, f 0.7104154880885033\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0 , val_loss : 0.30777138471603394,p 0.5821910749252809, r 0.9061597690086621, f 0.7089163581602561\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0 , val_loss : 0.29918792843818665,p 0.5873725816517579, r 0.9058389477061277, f 0.7126451287228672\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0 , val_loss : 0.3171621263027191,p 0.5746685998343, r 0.8901187038819378, f 0.69842668344871\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0 , val_loss : 0.3261931538581848,p 0.5594460929772502, r 0.9072826435675329, f 0.6921194322075379\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0 , val_loss : 0.28394776582717896,p 0.5991855106633801, r 0.896855951235162, f 0.718406681657565\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0 , val_loss : 0.28983110189437866,p 0.6006087618219371, r 0.8862688482515239, f 0.7159981857059547\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0 , val_loss : 0.33578619360923767,p 0.5527220630372492, r 0.9282964388835419, f 0.6928879310344828\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0 , val_loss : 0.2840662896633148,p 0.606448087431694, r 0.8901187038819378, f 0.7213988559542381\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0 , val_loss : 0.2860851585865021,p 0.6022727272727273, r 0.8926852743022137, f 0.7192710352849941\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0 , val_loss : 0.267964631319046,p 0.6213218650973291, r 0.8806544754571703, f 0.7285998672859987\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0 , val_loss : 0.30281704664230347,p 0.5846605196982397, r 0.8950914340712224, f 0.7073139814932184\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0 , val_loss : 0.28459471464157104,p 0.5976350271652285, r 0.8999037536092397, f 0.7182638755521414\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0 , val_loss : 0.28015199303627014,p 0.6054429144529979, r 0.8957330766762913, f 0.722520540855276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global weight_dir\n",
    "weight_dir= conf['dataset']['weight_path']##weight 저장\n",
    "model_epoch = conf['trn_args']['epoch']\n",
    "\n",
    "# dataset=weight_dir+'best'\n",
    "# checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(model_epoch):\n",
    "    if conf['trn_args']['adj_lr']:\n",
    "        lr = adjust_learning_rate(optimizer, epoch)\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out,_=model(inputs)\n",
    "        out=out.to(device)\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    \n",
    "    \n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                out,_=model(inputs)\n",
    "                out=out.to(device)\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                wr = csv.writer(csv_f)\n",
    "                wr.writerow([epoch,precision, recall,f1])\n",
    "                csv_f.close()\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                \n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                wr = csv.writer(csv_f)\n",
    "                wr.writerow([epoch,0, 0,0])\n",
    "                csv_f.close()\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6808035714285714, recall : 0.800524934383202, f1 : 0.735826296743064, accuracy : 0.9111201298701299\n",
      "102844341902586509\n",
      "precision : 0.5602678571428571, recall : 0.9920948616600791, f1 : 0.7161198288159771, accuracy : 0.9069223573433115\n",
      "102844401152267937\n",
      "precision : 0.5182926829268293, recall : 0.845771144278607, f1 : 0.6427221172022684, accuracy : 0.8348623853211009\n",
      "102844212430927059\n",
      "precision : 0.6842105263157895, recall : 0.8863636363636364, f1 : 0.7722772277227723, accuracy : 0.9092821456744675\n",
      "102844412708953395\n",
      "precision : 0.6786786786786787, recall : 0.8188405797101449, f1 : 0.7422003284072249, accuracy : 0.9236381322957199\n",
      "102844212429944013\n",
      "precision : 0.6467991169977925, recall : 0.7897574123989218, f1 : 0.7111650485436892, accuracy : 0.8836754643206256\n",
      "102844341912679064\n",
      "precision : 0.4584269662921348, recall : 0.9026548672566371, f1 : 0.6080476900149031, accuracy : 0.8644329896907217\n",
      "102844235753749959\n",
      "precision : 0.5250544662309368, recall : 0.6132315521628499, f1 : 0.5657276995305164, accuracy : 0.8330324909747292\n",
      "102844341908026005\n",
      "precision : 0.6650998824911868, recall : 0.858877086494689, f1 : 0.7496688741721854, accuracy : 0.8704148097360301\n",
      "102844283023206486\n",
      "precision : 0.6510204081632653, recall : 0.8935574229691877, f1 : 0.7532467532467534, accuracy : 0.8859170305676856\n",
      "102844224147717245\n",
      "precision : 0.6835443037974683, recall : 0.8709677419354839, f1 : 0.7659574468085106, accuracy : 0.9100327153762269\n",
      "102844412704890154\n",
      "precision : 0.6938271604938272, recall : 0.9153094462540716, f1 : 0.7893258426966292, accuracy : 0.927710843373494\n",
      "102844212430599377\n",
      "precision : 0.5698005698005698, recall : 0.847457627118644, f1 : 0.6814310051107325, accuracy : 0.9199143468950749\n",
      "102844412711443769\n",
      "precision : 0.6965065502183406, recall : 0.9410029498525073, f1 : 0.8005018820577163, accuracy : 0.875\n",
      "102844235747982779\n",
      "precision : 0.675392670157068, recall : 0.8896551724137931, f1 : 0.7678571428571428, accuracy : 0.8570381231671554\n",
      "==precision : 0.6258483607423544, recall : 0.8577377623501635, f1 : 0.720138345595339, accuracy : 0.8875329309737648\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label): ##measure def for test\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "\n",
    "\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "\n",
    "\n",
    "#evaluation\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output,_=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2500*70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
