{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레인함과 동시에 f1스코어 계산 & csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0f2b485e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv\n",
    "torch.manual_seed(712) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/batch_size.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=json.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=json.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=json.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio['102844412722519367'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:3\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=json.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=json.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=json.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = int(chat_size)+int(audio_size)+int(video_size)\n",
    "            \n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "                    s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=list(self.video[game_id][vframe+idx])\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "\n",
      "\n",
      "datset testing....\n",
      "('102844412722519367', array([[ 0.02620566,  0.0118512 , -0.02706682, ...,  0.20618153,\n",
      "        -0.02784772,  0.3355684 ],\n",
      "       [-0.06698951, -0.03389126, -0.00954571, ...,  0.20618153,\n",
      "        -0.02784772,  0.3355684 ],\n",
      "       [-0.06153676, -0.02784403, -0.01758359, ...,  0.20618153,\n",
      "        -0.02784772,  0.3355684 ],\n",
      "       ...,\n",
      "       [-0.08774932, -0.03491368, -0.01236366, ...,  0.20618153,\n",
      "        -0.02784772,  0.3355684 ],\n",
      "       [-0.0150439 , -0.00701944, -0.01754227, ...,  0.20618153,\n",
      "        -0.02784772,  0.3355684 ],\n",
      "       [ 0.01076563,  0.00668381, -0.01694852, ...,  0.20618153,\n",
      "        -0.02784772,  0.3355684 ]]), 0)\n",
      "23\n",
      "\n",
      "****************\n",
      "\n",
      "0\n",
      "epoch 0 train_loss : 0.44238564372062683 , val_loss : 0.30967089533805847,p 0.608296943231441, r 0.8938081488610844, f 0.7239184097700403\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0.2979944050312042 , val_loss : 0.41133731603622437,p 0.4966219034114605, r 0.9550850176451716, f 0.6534599132963838\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0.28808271884918213 , val_loss : 0.3171759247779846,p 0.56973058637084, r 0.9226820660891883, f 0.7044703000612369\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0.2767998278141022 , val_loss : 0.372789591550827,p 0.5342303845804164, r 0.9425729868463266, f 0.6819474264492543\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0.2797280251979828 , val_loss : 0.24813254177570343,p 0.637593984962406, r 0.8841835097850498, f 0.7409100073929701\n",
      "\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "hyper_parameter = [32,64,128,256,512]\n",
    "weight_directory = ['batch32/','batch64/','batch128/','batch256/','batch512/']\n",
    "\n",
    "global input_size,hidden_size,num_layers\n",
    "\n",
    "num_layers=conf['trn_args']['num_layer']\n",
    "\n",
    "for exp_index in range(0,5):\n",
    "\n",
    "  trn_bs = hyper_parameter[exp_index]\n",
    "\n",
    "  '''\n",
    "  dataset\n",
    "  '''\n",
    "  train=Mul_data('train')\n",
    "  val=Mul_data('test')## 그래프 그리기위해 val 없이 test로 바로진행\n",
    "\n",
    "  #test\n",
    "  print(\"\\n\\ndatset testing....\")\n",
    "  print(train[0])\n",
    "  print(len(train[100][1]))\n",
    "  print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "  #loader행\n",
    "  sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "  train_loader=torch.utils.data.DataLoader(train,batch_size=trn_bs,sampler=sampler1)\n",
    "  # train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "  val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])\n",
    "\n",
    "  '''\n",
    "  exp\n",
    "  '''\n",
    "  input_size=total_size\n",
    "\n",
    "\n",
    "\n",
    "  hidden_size=128\n",
    "  global weight_dir\n",
    "  weight_dir= conf['dataset']['weight_path'] + weight_directory[exp_index]\n",
    "\n",
    "  lr = conf['trn_args']['lr']\n",
    "\n",
    "  model=LSTM().to(device)\n",
    "  criterion = nn.CrossEntropyLoss().to(device)\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "  model_epoch = conf['trn_args']['epoch']\n",
    "\n",
    "  # dataset=weight_dir+'best'\n",
    "  # checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "  # model.load_state_dict(checkpoint)\n",
    "\n",
    "\n",
    "  if not os.path.exists(weight_dir):\n",
    "      os.makedirs(weight_dir)\n",
    "  with open(weight_dir+'train_result','a') as f:\n",
    "      f.write('=====result=======\\n')\n",
    "  f1_best=0\n",
    "  for epoch in range(model_epoch):\n",
    "      if conf['trn_args']['adj_lr']:\n",
    "          lr = adjust_learning_rate(optimizer, epoch)\n",
    "      losses = AverageMeter()\n",
    "      print(epoch)\n",
    "      model.train()\n",
    "      for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "          inputs=inputs.float()\n",
    "          inputs=inputs.to(device)\n",
    "          labels=labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          out,_=model(inputs)\n",
    "          out=out.to(device)\n",
    "          loss=criterion(out,labels)\n",
    "          loss.backward()\n",
    "          losses.update(loss,labels.size(0))\n",
    "          optimizer.step()\n",
    "          \n",
    "      model.eval()\n",
    "      val_losses=AverageMeter()\n",
    "      acc=0\n",
    "      gt_sum=0\n",
    "      tp_sum=0\n",
    "      fp_sum=0\n",
    "      fn_sum=0\n",
    "      acc=0\n",
    "      sum=0\n",
    "      pred_sum=0\n",
    "      \n",
    "      \n",
    "      with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "          with torch.no_grad():\n",
    "              for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                  inputs=inputs.float()\n",
    "                  inputs=inputs.to(device)\n",
    "                  labels=labels.to(device)\n",
    "                  out,_=model(inputs)\n",
    "                  out=out.to(device)\n",
    "                  loss=criterion(out,labels)\n",
    "                  val_losses.update(loss,labels.size(0))\n",
    "                  TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                  tp_sum += TP\n",
    "                  fp_sum += FP\n",
    "                  fn_sum += FN\n",
    "                  pred_sum += pred_len\n",
    "                  gt_sum += gt_len\n",
    "                  acc=acc+TP+TN\n",
    "                  sum+=len(out)\n",
    "              if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                  precision = tp_sum/(tp_sum+fp_sum)\n",
    "                  recall = tp_sum / (tp_sum+fn_sum)\n",
    "                  f1 = (2*precision*recall / (precision + recall))\n",
    "                  accuracy=acc/sum\n",
    "                  print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                  f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                  csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                  wr = csv.writer(csv_f)\n",
    "                  wr.writerow([epoch,precision, recall,f1])\n",
    "                  csv_f.close()\n",
    "                  torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                  \n",
    "                  if f1_best<f1:\n",
    "                      f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                      torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                      f1_best=f1\n",
    "\n",
    "              else:\n",
    "                  print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                  f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                  csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                  wr = csv.writer(csv_f)\n",
    "                  wr.writerow([epoch,0, 0,0])\n",
    "                  csv_f.close()\n",
    "                  torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "\n",
    "              \n",
    "  def fmeasure2(frames,label): ##measure def for test\n",
    "      average = [0,0,0,0,0]\n",
    "      for key in frames.keys():\n",
    "          TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "          FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "          TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "          FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "          precision = TP/(TP+FP)\n",
    "          recall = TP/(TP+FN)\n",
    "          accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "          if precision==0 and recall == 0:\n",
    "              print('!')\n",
    "          else:\n",
    "              f1 = (2*precision*recall / (precision + recall))\n",
    "              print(key)\n",
    "              print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "              average[0]+= precision\n",
    "              average[1]+= recall\n",
    "              average[2]+= f1\n",
    "              average[3]+= accuracy\n",
    "              average[4]+=1\n",
    "      print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "      csv_f = open(weight_dir+'eval.csv','a', newline='')\n",
    "      wr = csv.writer(csv_f)\n",
    "      wr.writerow(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4])\n",
    "      csv_f.close()\n",
    "\n",
    "\n",
    "  try:\n",
    "\n",
    "    test=Mul_data('test')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    pred_sum = 0#model output\n",
    "    gt_sum = 0#label\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    result={}\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output,_=model(inputs)\n",
    "            TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "            for idx,g in enumerate(game_id):\n",
    "                if g not in result.keys():\n",
    "                    result[g]=pred[idx].tolist()\n",
    "                else:\n",
    "                    result[g]+=pred[idx].tolist()\n",
    "    with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "        real_result=pickle.load(f4)\n",
    "    fmeasure2(result,real_result)\n",
    "  except:\n",
    "    print('no best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
