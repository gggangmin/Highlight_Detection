{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/config-video.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=pickle.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=pickle.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=pickle.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video['102844412722519367'])\n",
    "len(real_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        self.gt_range =  1-conf['trn_args']['hl_range']\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=pickle.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=pickle.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=pickle.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "        if d_type =='total':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654'] + ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630'] + ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "    \n",
    "        \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        begin_pos = 0 \n",
    "        hl_frames = []\n",
    "        for it, cur_pos in enumerate(pos_idx):\n",
    "            if it+1 < len(pos_idx): \n",
    "                if((pos_idx[it+1] - cur_pos) > 1):#cur_pos와 cur_pos+1 간격이 1보다 크면, 즉 다른 구간이면\n",
    "                    begin = int((it+1 - begin_pos) * self.gt_range) + begin_pos\n",
    "                    hl_frames.extend( pos_idx[begin: it] ) #한구간의 하이라이트 25%만 사용하겠다.\n",
    "                    begin_pos = it+1\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[hl_frames] = len(sampling) / float(len(hl_frames))\n",
    "        self.WeightedSampling = sampling\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = video_size\n",
    "            \n",
    "            #video_only\n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "                    #s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    #s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=[self.video[game_id][vframe+idx]]\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "\n",
      "\n",
      "datset testing....\n",
      "('102844412722519367', array([[0.01117067],\n",
      "       [0.02793789],\n",
      "       [0.03156882],\n",
      "       [0.03493765],\n",
      "       [0.03568352],\n",
      "       [0.03391392],\n",
      "       [0.03102885],\n",
      "       [0.02961443],\n",
      "       [0.0128472 ]]), 0)\n",
      "9\n",
      "\n",
      "****************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "\n",
    "#test\n",
    "print(\"\\n\\ndatset testing....\")\n",
    "print(train[100])\n",
    "print(len(train[100][1]))\n",
    "print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "#loader \n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0.6932711005210876 , val_loss : 0.6697173118591309,p 0, r 0, f 0\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0.6932976841926575 , val_loss : 0.6946302652359009,p 0, r 0, f 0\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0.6932814717292786 , val_loss : 0.6902717351913452,p 0, r 0, f 0\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0.6932412981987 , val_loss : 0.7023842334747314,p 0, r 0, f 0\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0.6931952238082886 , val_loss : 0.692505419254303,p 0.880901287553648, r 0.18123620309050772, f 0.3006224826071036\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0.6932240724563599 , val_loss : 0.6770738959312439,p 0, r 0, f 0\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0.6931896805763245 , val_loss : 0.710371196269989,p 0, r 0, f 0\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0.693122386932373 , val_loss : 0.6968269944190979,p 0, r 0, f 0\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0.69297194480896 , val_loss : 0.6996801495552063,p 0, r 0, f 0\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0.6929786801338196 , val_loss : 0.695795476436615,p 0, r 0, f 0\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0.6928136944770813 , val_loss : 0.6808854937553406,p 0, r 0, f 0\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0.6927046775817871 , val_loss : 0.6775872707366943,p 0, r 0, f 0\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0.6924962401390076 , val_loss : 0.7087346911430359,p 0, r 0, f 0\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0.6920098662376404 , val_loss : 0.6956936120986938,p 0, r 0, f 0\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0.6913391351699829 , val_loss : 0.683774471282959,p 0.7910146390711762, r 0.345916114790287, f 0.48133927200122867\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0.6875361800193787 , val_loss : 0.667996346950531,p 0.7615148413510747, r 0.49271523178807947, f 0.5983112183353437\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0.597263753414154 , val_loss : 0.5330072045326233,p 0.5109931766489765, r 0.7439293598233996, f 0.6058426966292135\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0.4944019317626953 , val_loss : 0.49944034218788147,p 0.5571776155717761, r 0.7077262693156733, f 0.6234928043562815\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0.4555899202823639 , val_loss : 0.4314473569393158,p 0.6353472371533003, r 0.652317880794702, f 0.6437207275895871\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0.4453977644443512 , val_loss : 0.4691070318222046,p 0.5795388490602597, r 0.6602649006622516, f 0.6172737591579815\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0.43999722599983215 , val_loss : 0.44673094153404236,p 0.6227098423519386, r 0.6452538631346578, f 0.6337814397224631\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0.4300742447376251 , val_loss : 0.4244844317436218,p 0.6530799175635448, r 0.6295805739514349, f 0.6411149825783972\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0.4392404556274414 , val_loss : 0.41831308603286743,p 0.6625263651277244, r 0.6240618101545253, f 0.6427191087870866\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0.4375738203525543 , val_loss : 0.4247017800807953,p 0.645452493793726, r 0.6313465783664459, f 0.6383216158910836\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0.43126511573791504 , val_loss : 0.4227029085159302,p 0.6544321329639889, r 0.6258278145695364, f 0.6398104265402843\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0.43459582328796387 , val_loss : 0.42504289746284485,p 0.6438418079096045, r 0.6289183222958057, f 0.6362925739810161\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0.4309845268726349 , val_loss : 0.43531545996665955,p 0.6236257814184092, r 0.6386313465783664, f 0.63103937179627\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0.4381585121154785 , val_loss : 0.42486533522605896,p 0.6559739655973965, r 0.6229580573951435, f 0.6390398550724637\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0.43408504128456116 , val_loss : 0.42714181542396545,p 0.6347864768683275, r 0.6300220750551876, f 0.6323953024595612\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0.43351349234580994 , val_loss : 0.41762760281562805,p 0.6560316721006055, r 0.6218543046357616, f 0.6384859474161378\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0.4276493489742279 , val_loss : 0.4375728964805603,p 0.6106677866442671, r 0.6419426048565121, f 0.6259147653895825\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0.43597331643104553 , val_loss : 0.42879754304885864,p 0.6335707925200356, r 0.6282560706401766, f 0.6309022389714032\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0.43875357508659363 , val_loss : 0.4131590723991394,p 0.6775300171526587, r 0.6103752759381899, f 0.6422018348623854\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0.4303831160068512 , val_loss : 0.4377727806568146,p 0.6191397849462366, r 0.6355408388520971, f 0.6272331154684095\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0.43395406007766724 , val_loss : 0.44391462206840515,p 0.6042747457978834, r 0.6428256070640177, f 0.6229543266659536\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0.43404340744018555 , val_loss : 0.434626966714859,p 0.6245353159851301, r 0.6304635761589404, f 0.6274854443590026\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0.4278217554092407 , val_loss : 0.41239750385284424,p 0.678007889546351, r 0.6070640176600441, f 0.6405776846028418\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0.42916983366012573 , val_loss : 0.4337276518344879,p 0.6274509803921569, r 0.6286975717439294, f 0.6280736575146102\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0.43405258655548096 , val_loss : 0.4332387149333954,p 0.6214689265536724, r 0.6313465783664459, f 0.6263688129653965\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0.43128350377082825 , val_loss : 0.409507691860199,p 0.6685203094777563, r 0.6103752759381899, f 0.6381260096930532\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0.4338400959968567 , val_loss : 0.42325079441070557,p 0.6429388876173038, r 0.6200883002207506, f 0.6313068884144286\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0.43181994557380676 , val_loss : 0.42896372079849243,p 0.6275724717857933, r 0.6260485651214128, f 0.6268095922201349\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0.43392306566238403 , val_loss : 0.42347007989883423,p 0.6400911161731208, r 0.6203090507726269, f 0.6300448430493274\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0.43115144968032837 , val_loss : 0.42695316672325134,p 0.637911464245176, r 0.6203090507726269, f 0.6289871292669279\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0.42379552125930786 , val_loss : 0.4287763833999634,p 0.6272727272727273, r 0.6245033112582782, f 0.6258849557522125\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0.4369056522846222 , val_loss : 0.4385646879673004,p 0.6167496212940922, r 0.6291390728476821, f 0.6228827450551853\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0.43057847023010254 , val_loss : 0.4337819516658783,p 0.6172705576046865, r 0.6280353200883002, f 0.6226064120800963\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0.4270474314689636 , val_loss : 0.4162961542606354,p 0.6563834836260085, r 0.6105960264900663, f 0.6326623970722782\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0.4238138198852539 , val_loss : 0.4349241852760315,p 0.6097456721521692, r 0.6298013245033113, f 0.6196112498642631\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0.4304138720035553 , val_loss : 0.41635242104530334,p 0.660436137071651, r 0.6083885209713025, f 0.6333448236240378\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0.43180423974990845 , val_loss : 0.4318639039993286,p 0.6233164053875028, r 0.6231788079470199, f 0.6232475990727454\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0.43337300419807434 , val_loss : 0.4174579381942749,p 0.6570474600524684, r 0.608167770419426, f 0.6316634185486645\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0.4277687966823578 , val_loss : 0.4251558184623718,p 0.6375685557586838, r 0.6158940397350994, f 0.6265439029867506\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0.4317721724510193 , val_loss : 0.4237024486064911,p 0.6450939457202505, r 0.6139072847682119, f 0.6291143535799116\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0.4296930730342865 , val_loss : 0.4231720268726349,p 0.6506591337099812, r 0.6101545253863134, f 0.6297562087035772\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0.4266548156738281 , val_loss : 0.4160415530204773,p 0.6660194174757281, r 0.6057395143487859, f 0.634450867052023\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0.4253295660018921 , val_loss : 0.42749693989753723,p 0.6433032616238723, r 0.6139072847682119, f 0.6282616062351745\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0.4366058111190796 , val_loss : 0.43874722719192505,p 0.6108831785791405, r 0.6245033112582782, f 0.6176181639559001\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0.4321815073490143 , val_loss : 0.4392424523830414,p 0.6176084099868594, r 0.6225165562913907, f 0.6200527704485488\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0.42768362164497375 , val_loss : 0.430370032787323,p 0.6288474500112334, r 0.6178807947019868, f 0.6233158890992094\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0.43213555216789246 , val_loss : 0.4351373314857483,p 0.6172217353198949, r 0.6218543046357616, f 0.6195293600175941\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0.43505197763442993 , val_loss : 0.42719313502311707,p 0.6250558284948637, r 0.6178807947019868, f 0.6214476021314388\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0.42873653769493103 , val_loss : 0.42419081926345825,p 0.6538187009279086, r 0.6066225165562914, f 0.629336997595328\n",
      "\n",
      "63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63 train_loss : 0.4258268177509308 , val_loss : 0.4343070089817047,p 0.6154014438853642, r 0.620971302428256, f 0.6181738270519723\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0.4357008934020996 , val_loss : 0.4395849108695984,p 0.6083584661783714, r 0.6233995584988963, f 0.615787178368949\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0.4278423488140106 , val_loss : 0.42961668968200684,p 0.6299052774018945, r 0.6165562913907284, f 0.6231593038821955\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0.4253182113170624 , val_loss : 0.4350091814994812,p 0.6048801369863014, r 0.623841059602649, f 0.6142143012388611\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0.4275551736354828 , val_loss : 0.4315909445285797,p 0.6233563628259416, r 0.617439293598234, f 0.6203837196406786\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0.4298626482486725 , val_loss : 0.4280446767807007,p 0.6269360269360269, r 0.6165562913907284, f 0.621702838063439\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0.43222784996032715 , val_loss : 0.4278542101383209,p 0.6352186855965194, r 0.6123620309050772, f 0.6235809823536024\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0.424480140209198 , val_loss : 0.4350152313709259,p 0.5978031263202366, r 0.6247240618101545, f 0.6109671848013816\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0.42839986085891724 , val_loss : 0.4336799085140228,p 0.6055460017196904, r 0.6218543046357616, f 0.6135918100631672\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0.43011659383773804 , val_loss : 0.43121251463890076,p 0.616350815337153, r 0.617439293598234, f 0.6168945743273049\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0.4242781698703766 , val_loss : 0.42106130719184875,p 0.6470311027332705, r 0.6061810154525387, f 0.6259402780943698\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0.42833220958709717 , val_loss : 0.4516673684120178,p 0.5626339372686538, r 0.6375275938189845, f 0.5977439718513919\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0.43355223536491394 , val_loss : 0.4231182634830475,p 0.6652003910068426, r 0.6008830022075056, f 0.631408025980051\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0.4324799180030823 , val_loss : 0.4284434914588928,p 0.6363008971704623, r 0.6105960264900663, f 0.6231835079418724\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0.42759963870048523 , val_loss : 0.42651069164276123,p 0.6301929625425653, r 0.61280353200883, f 0.621376608841634\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0.42606523633003235 , val_loss : 0.4336770474910736,p 0.6065005417118093, r 0.6178807947019868, f 0.6121377802077639\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0.42871594429016113 , val_loss : 0.417739599943161,p 0.6717196819085487, r 0.5966887417218543, f 0.6319850362403554\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0.43122828006744385 , val_loss : 0.42927655577659607,p 0.6351102941176471, r 0.6101545253863134, f 0.6223823463183967\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0.4294433891773224 , val_loss : 0.4316159188747406,p 0.6106620056805768, r 0.6169977924944813, f 0.6138135500164709\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0.425574392080307 , val_loss : 0.4213504195213318,p 0.644015988713849, r 0.604635761589404, f 0.623704884435842\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0.4298427104949951 , val_loss : 0.4259399473667145,p 0.6297475551512395, r 0.6112582781456953, f 0.6203651842724319\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0.4295489192008972 , val_loss : 0.42958933115005493,p 0.6324101625085832, r 0.6099337748344371, f 0.6209686481627149\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0.42748284339904785 , val_loss : 0.43384888768196106,p 0.6099585062240664, r 0.6165562913907284, f 0.6132396530903501\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0.42376136779785156 , val_loss : 0.43264245986938477,p 0.6078729882557634, r 0.6169977924944813, f 0.612401402278703\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0.4270913302898407 , val_loss : 0.4291583299636841,p 0.6246908027883967, r 0.6132450331125828, f 0.6189150050128105\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0.4254567623138428 , val_loss : 0.42959198355674744,p 0.6066782307025151, r 0.6176600441501103, f 0.6121198862393349\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0.42669543623924255 , val_loss : 0.42848342657089233,p 0.6378390911198701, r 0.6072847682119206, f 0.6221870405970825\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0.42658334970474243 , val_loss : 0.42410293221473694,p 0.642421398404505, r 0.6044150110375276, f 0.6228389444949954\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0.43312370777130127 , val_loss : 0.42685893177986145,p 0.6389858106536404, r 0.606401766004415, f 0.6222675274663042\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0.4307641088962555 , val_loss : 0.4282649755477905,p 0.6147902869757175, r 0.6147902869757175, f 0.6147902869757175\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0.4248605966567993 , val_loss : 0.4319385290145874,p 0.6032327586206897, r 0.6178807947019868, f 0.6104689203925845\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0.42620208859443665 , val_loss : 0.430134654045105,p 0.6097880707887262, r 0.6161147902869757, f 0.61293510486439\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0.42636168003082275 , val_loss : 0.4213355779647827,p 0.6350820429859024, r 0.6066225165562914, f 0.6205261375183471\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0.42791885137557983 , val_loss : 0.42889729142189026,p 0.6278699704478291, r 0.6097130242825607, f 0.6186583044013888\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0.43170860409736633 , val_loss : 0.43046385049819946,p 0.6064222174007377, r 0.6169977924944813, f 0.6116642958748222\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0.42818814516067505 , val_loss : 0.4318690299987793,p 0.6617754952311079, r 0.5973509933774834, f 0.6279150713539854\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0.4267864227294922 , val_loss : 0.43016690015792847,p 0.600686253484881, r 0.6183222958057395, f 0.6093766996627868\n",
      "\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6370967741935484, recall : 0.6220472440944882, f1 : 0.6294820717131475, accuracy : 0.8867694805194806\n",
      "102844341902586509\n",
      "precision : 0.6382252559726962, recall : 0.7391304347826086, f1 : 0.684981684981685, accuracy : 0.9195509822263798\n",
      "102844401152267937\n",
      "precision : 0.7382716049382716, recall : 0.7437810945273632, f1 : 0.7410161090458489, accuracy : 0.9086937527304499\n",
      "102844212430927059\n",
      "precision : 0.7521186440677966, recall : 0.5378787878787878, f1 : 0.627208480565371, accuracy : 0.8890349723902182\n",
      "102844412708953395\n",
      "precision : 0.5253623188405797, recall : 0.5253623188405797, f1 : 0.5253623188405797, accuracy : 0.872568093385214\n",
      "102844212429944013\n",
      "precision : 0.6793650793650794, recall : 0.5768194070080862, f1 : 0.6239067055393587, accuracy : 0.873900293255132\n",
      "102844341912679064\n",
      "precision : 0.5894308943089431, recall : 0.6415929203539823, f1 : 0.614406779661017, accuracy : 0.9061855670103093\n",
      "102844235753749959\n",
      "precision : 0.6912181303116147, recall : 0.6208651399491094, f1 : 0.6541554959785523, accuracy : 0.8835740072202166\n",
      "102844341908026005\n",
      "precision : 0.7558139534883721, recall : 0.5918057663125948, f1 : 0.6638297872340426, accuracy : 0.8645869043537882\n",
      "102844283023206486\n",
      "precision : 0.6727272727272727, recall : 0.6218487394957983, f1 : 0.6462882096069869, accuracy : 0.86735807860262\n",
      "102844224147717245\n",
      "precision : 0.7374517374517374, recall : 0.6161290322580645, f1 : 0.6713532513181019, accuracy : 0.8980370774263904\n",
      "102844412704890154\n",
      "precision : 0.6873065015479877, recall : 0.7231270358306189, f1 : 0.7047619047619048, accuracy : 0.9103614457831325\n",
      "102844212430599377\n",
      "precision : 0.5991379310344828, recall : 0.5889830508474576, f1 : 0.5940170940170941, accuracy : 0.9186295503211992\n",
      "102844412711443769\n",
      "precision : 0.8760162601626016, recall : 0.6356932153392331, f1 : 0.7367521367521368, accuracy : 0.8789308176100629\n",
      "102844235747982779\n",
      "precision : 0.7553956834532374, recall : 0.5793103448275863, f1 : 0.6557377049180328, accuracy : 0.8383431085043989\n",
      "==precision : 0.6889958694576147, recall : 0.6242916354897573, f1 : 0.6515506489955907, accuracy : 0.8877682754225997\n",
      "data load fin\n",
      "102844412722519367\n",
      "102844212429550795\n",
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n",
      "102844294671796427\n",
      "102844224145685626\n",
      "102844412717407552\n",
      "102844235751390657\n",
      "102844401156069033\n",
      "102904869420860038\n",
      "102910307641576395\n",
      "102844341905404560\n",
      "102844341906977427\n",
      "102844212430075086\n",
      "102844412711116088\n",
      "102844401153578660\n",
      "102844294667405508\n",
      "102844412706659630\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n"
     ]
    }
   ],
   "source": [
    "hyper_parameter = [128,256]\n",
    "weight_directory=['1/','_d256/',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for exp_index in range(0,1):\n",
    "\n",
    "    global weight_dir\n",
    "    weight_dir= conf['dataset']['weight_path']#+weight_directory[exp_index]##weight 저장\n",
    "    model_epoch = conf['trn_args']['epoch']\n",
    "\n",
    "    global input_size,hidden_size,num_layers\n",
    "    input_size=total_size\n",
    "    hidden_size=hyper_parameter[exp_index]\n",
    "    num_layers=conf['trn_args']['num_layer']\n",
    "\n",
    "\n",
    "    lr = conf['trn_args']['lr']\n",
    "\n",
    "    model=LSTM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "        f.write('=====result=======\\n')\n",
    "    f1_best=0\n",
    "    for epoch in range(model_epoch):\n",
    "        lr = adjust_learning_rate(optimizer,epoch)\n",
    "        #lr=0.01\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "            inputs=inputs.float()\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out,_=model(inputs)\n",
    "            out=out.to(device)\n",
    "            loss=criterion(out,labels)\n",
    "            losses.update(loss,labels.size(0))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_losses=AverageMeter()\n",
    "        acc=0\n",
    "        gt_sum=0\n",
    "        tp_sum=0\n",
    "        fp_sum=0\n",
    "        fn_sum=0\n",
    "        acc=0\n",
    "        sum=0\n",
    "        pred_sum=0\n",
    "\n",
    "\n",
    "        with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                    inputs=inputs.float()\n",
    "                    inputs=inputs.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    out,_=model(inputs)\n",
    "                    out=out.to(device)\n",
    "                    loss=criterion(out,labels)\n",
    "                    val_losses.update(loss,labels.size(0))\n",
    "                    TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                    tp_sum += TP\n",
    "                    fp_sum += FP\n",
    "                    fn_sum += FN\n",
    "                    pred_sum += pred_len\n",
    "                    gt_sum += gt_len\n",
    "                    acc=acc+TP+TN\n",
    "                    sum+=len(out)\n",
    "                if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                    precision = tp_sum/(tp_sum+fp_sum)\n",
    "                    recall = tp_sum / (tp_sum+fn_sum)\n",
    "                    f1 = (2*precision*recall / (precision + recall))\n",
    "                    accuracy=acc/sum\n",
    "                    print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                    wr = csv.writer(csv_f)\n",
    "                    wr.writerow([epoch,precision, recall,f1])\n",
    "                    csv_f.close()\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                    if f1_best<f1:\n",
    "                        f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                        torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                        f1_best=f1\n",
    "\n",
    "                else:\n",
    "                    print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                    f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                    csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                    wr = csv.writer(csv_f)\n",
    "                    wr.writerow([epoch,0, 0,0])\n",
    "                    csv_f.close()\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fmeasure2(frames,label): ##measure def for test\n",
    "        average = [0,0,0,0,0]\n",
    "        for key in frames.keys():\n",
    "            TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "            FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "            TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "            FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "            if precision==0 and recall == 0:\n",
    "                print('!')\n",
    "            else:\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                print(key)\n",
    "                print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "                average[0]+= precision\n",
    "                average[1]+= recall\n",
    "                average[2]+= f1\n",
    "                average[3]+= accuracy\n",
    "                average[4]+=1\n",
    "        print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "        with open(weight_dir+'/eval','a') as f:\n",
    "            f.writelines('prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "            f.close()\n",
    "    test=Mul_data('test')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    pred_sum = 0#model output\n",
    "    gt_sum = 0#label\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    result={}\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output,_=model(inputs)\n",
    "            TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "            for idx,g in enumerate(game_id):\n",
    "                if g not in result.keys():\n",
    "                    result[g]=pred[idx].tolist()\n",
    "                else:\n",
    "                    result[g]+=pred[idx].tolist()\n",
    "    with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "        real_result=pickle.load(f4)\n",
    "    fmeasure2(result,real_result)\n",
    "\n",
    "    #test\n",
    "\n",
    "\n",
    "\n",
    "    test=Mul_data('total')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=1)\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    result={}\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output_p,output_f=model(inputs)\n",
    "\n",
    "            if game_id[0] not in result.keys():\n",
    "                print(game_id[0])\n",
    "                result[game_id[0]]=[(output_f[0]).tolist()]\n",
    "\n",
    "            else:\n",
    "                result[game_id[0]]+=[(output_f[0]).tolist()]\n",
    "\n",
    "\n",
    "\n",
    "    with open(weight_dir+'video_feature.json','a') as f:\n",
    "        json.dump(result,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(weight_dir+'video_feature.json','r') as f:\n",
    "  temp = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2069\n"
     ]
    }
   ],
   "source": [
    "for i in temp.keys():\n",
    "    print(len(temp[i]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
