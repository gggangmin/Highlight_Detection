{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/config-audio.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:1\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9851/1028236825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chat_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mchat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=pickle.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=pickle.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=pickle.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio['102844412722519367'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        self.gt_range =  1-conf['trn_args']['hl_range']\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=pickle.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=pickle.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=pickle.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']     \n",
    "        if d_type =='total':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654'] + ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630'] + ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    " \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        begin_pos = 0 \n",
    "        hl_frames = []\n",
    "        for it, cur_pos in enumerate(pos_idx):\n",
    "            if it+1 < len(pos_idx): \n",
    "                if((pos_idx[it+1] - cur_pos) > 1):#cur_pos와 cur_pos+1 간격이 1보다 크면, 즉 다른 구간이면\n",
    "                    begin = int((it+1 - begin_pos) * self.gt_range) + begin_pos\n",
    "                    hl_frames.extend( pos_idx[begin: it] ) #한구간의 하이라이트 25%만 사용하겠다.\n",
    "                    begin_pos = it+1\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[hl_frames] = len(sampling) / float(len(hl_frames))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = audio_size\n",
    "            \n",
    "            #audio_only\n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "#                     s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "#                     s_window+=[self.video[game_id][vframe+idx]]\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "\n",
      "\n",
      "datset testing....\n",
      "('102844412722519367', array([[  2.2001882 ,  -9.80676619, -11.11639875, -10.09886806,\n",
      "         -8.47125593,  -8.55332796,  -6.12871893,  -3.17043442,\n",
      "         -1.71466267,  -5.19732286,  -3.77024903,  -2.99407219,\n",
      "         -3.54347805],\n",
      "       [  9.03103736, -16.15133849,  -8.33885897, -11.90960517,\n",
      "         -9.17977961,  -8.71532322,  -8.978371  ,  -4.22298997,\n",
      "         -2.58187328,  -1.39110923,  -3.36411837,  -2.54867552,\n",
      "         -3.03780565],\n",
      "       [-12.84284726, -10.12680368,  -3.45536908,  -8.45073936,\n",
      "         -5.32551442,  -4.50438865,  -3.29253053,  -0.82895848,\n",
      "         -4.93028257,   0.9279834 ,  -2.41448028,  -0.24941073,\n",
      "         -0.11264702],\n",
      "       [ 13.66766934, -10.43965238,  -8.73442498, -16.63221332,\n",
      "        -14.76351086, -11.13111863,  -6.67272178,  -4.48623026,\n",
      "         -1.55866536,  -5.3237014 ,  -3.29337875,  -1.98631856,\n",
      "         -3.2770396 ],\n",
      "       [  7.63164985, -12.54389611,  -5.59081995, -12.4211494 ,\n",
      "         -7.50846677,  -8.86606956,  -7.8751188 ,  -2.90691942,\n",
      "         -1.74786657,  -1.16879009,  -5.10016714,  -2.20282131,\n",
      "         -4.65549276],\n",
      "       [ 14.78246389, -11.54799445, -13.7914316 , -12.40608236,\n",
      "        -13.48969691,  -7.2748362 ,  -8.01191943,  -5.17265838,\n",
      "         -0.41768063,  -0.59223176,  -6.73758439,  -1.75827812,\n",
      "         -3.36015739],\n",
      "       [ 13.08406287,  -9.95989088,  -5.52074889,  -8.50255077,\n",
      "        -11.83915471, -12.35513808,  -7.04510514,  -1.56510567,\n",
      "         -0.38541831,  -1.41325522,  -2.90041248,  -6.83178039,\n",
      "         -6.76145244]]), 0)\n",
      "7\n",
      "\n",
      "****************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "\n",
    "#test\n",
    "print(\"\\n\\ndatset testing....\")\n",
    "print(train[100])\n",
    "print(len(train[100][1]))\n",
    "print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "#loader \n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0.6043209433555603 , val_loss : 0.4712793529033661,p 0.49224283305227656, r 0.6443708609271523, f 0.5581261950286807\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0.5403915047645569 , val_loss : 0.5023117661476135,p 0.4424217907227616, r 0.7242825607064017, f 0.5493052067637704\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0.5315335988998413 , val_loss : 0.5233840346336365,p 0.42466271592485183, r 0.7434878587196468, f 0.5405665676911965\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0.5210747122764587 , val_loss : 0.4199005663394928,p 0.5261996690568119, r 0.6317880794701987, f 0.5741799578693952\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0.5228690505027771 , val_loss : 0.46099135279655457,p 0.4736131934032983, r 0.6973509933774834, f 0.5641071428571428\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0.5120639801025391 , val_loss : 0.47516125440597534,p 0.4740376007162041, r 0.7013245033112583, f 0.5657051282051282\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0.5130370855331421 , val_loss : 0.48146533966064453,p 0.4678655660377358, r 0.7006622516556291, f 0.5610747746155207\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0.5082547664642334 , val_loss : 0.5033784508705139,p 0.4439182789879583, r 0.7242825607064017, f 0.5504571764113749\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0.5050269961357117 , val_loss : 0.5676285624504089,p 0.3934241639455016, r 0.7713024282560706, f 0.5210647975542465\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0.5055044889450073 , val_loss : 0.5717463493347168,p 0.38995926456016733, r 0.7818984547461368, f 0.5203849261735106\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0.49551165103912354 , val_loss : 0.46102839708328247,p 0.499500998003992, r 0.6629139072847682, f 0.5697211155378485\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0.49796155095100403 , val_loss : 0.40752196311950684,p 0.5735294117647058, r 0.5854304635761589, f 0.5794188332969193\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0.4990052580833435 , val_loss : 0.5959056615829468,p 0.37068875144145086, r 0.7805739514348786, f 0.5026654346435425\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0.49298804998397827 , val_loss : 0.5203906297683716,p 0.4175263988348101, r 0.7593818984547461, f 0.5388049181611716\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0.4910595118999481 , val_loss : 0.5044286847114563,p 0.4405244660719113, r 0.7194260485651214, f 0.5464453386988598\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0.4867900609970093 , val_loss : 0.47288861870765686,p 0.47788679245283017, r 0.698896247240618, f 0.5676378305692514\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0.48842957615852356 , val_loss : 0.5377151370048523,p 0.41004234724742894, r 0.7481236203090508, f 0.5297381789761626\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0.4846094846725464 , val_loss : 0.49048179388046265,p 0.44423155877925274, r 0.7165562913907285, f 0.5484497761257076\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0.47863471508026123 , val_loss : 0.5324123501777649,p 0.40743861338468945, r 0.7472406181015453, f 0.5273407072752765\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0.48306596279144287 , val_loss : 0.4890553057193756,p 0.4437294633077766, r 0.7154525386313466, f 0.5477437890823053\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0.4767313003540039 , val_loss : 0.5418281555175781,p 0.38637866431562706, r 0.7739514348785872, f 0.515436636283446\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0.4755961298942566 , val_loss : 0.581551730632782,p 0.3612624653027655, r 0.7757174392935983, f 0.492950831170653\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0.47588133811950684 , val_loss : 0.42534783482551575,p 0.4978688524590164, r 0.6704194260485651, f 0.5714016933207903\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0.47071847319602966 , val_loss : 0.429036408662796,p 0.4947246950214309, r 0.6624724061810154, f 0.5664401661004153\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0.46335846185684204 , val_loss : 0.5324302911758423,p 0.40396270396270395, r 0.765121412803532, f 0.5287566742944317\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0.46486225724220276 , val_loss : 0.49176549911499023,p 0.4343909126517822, r 0.7344370860927152, f 0.5459020428254984\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0.4634348750114441 , val_loss : 0.5801793932914734,p 0.3566834866923914, r 0.7958057395143487, f 0.49258727881396464\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0.4557129144668579 , val_loss : 0.513091504573822,p 0.4113098115031416, r 0.7514348785871965, f 0.5316258004060596\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0.4566589891910553 , val_loss : 0.40838971734046936,p 0.5217877094972067, r 0.6185430463576159, f 0.566060606060606\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0.45382705330848694 , val_loss : 0.4621960520744324,p 0.463211200476616, r 0.6865342163355408, f 0.5531839203130559\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0.45098453760147095 , val_loss : 0.49734973907470703,p 0.42896425297891844, r 0.7231788079470198, f 0.5385057943617984\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0.449905127286911 , val_loss : 0.5057108402252197,p 0.4077681577681578, r 0.7485651214128035, f 0.5279464424723649\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0.449079304933548 , val_loss : 0.44001123309135437,p 0.4608747396608152, r 0.6838852097130242, f 0.5506576608602914\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0.4428449273109436 , val_loss : 0.4632975161075592,p 0.4424110384894699, r 0.6724061810154526, f 0.5336837494524749\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0.4391326606273651 , val_loss : 0.42206358909606934,p 0.4965459140690817, r 0.6505518763796909, f 0.563210702341137\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0.43918654322624207 , val_loss : 0.37737753987312317,p 0.5592008412197687, r 0.5869757174392936, f 0.5727517501346258\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0.43195250630378723 , val_loss : 0.5876674652099609,p 0.34469057315982915, r 0.7660044150110376, f 0.4754401589367679\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0.43303292989730835 , val_loss : 0.5507039427757263,p 0.36823144104803496, r 0.7445916114790287, f 0.4927684441197955\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0.42829811573028564 , val_loss : 0.40587180852890015,p 0.5147985487874738, r 0.5951434878587196, f 0.5520630695198117\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0.4254286587238312 , val_loss : 0.518216609954834,p 0.4060276807657483, r 0.6929359823399559, f 0.5120300138651007\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0.4224424660205841 , val_loss : 0.5395478010177612,p 0.3699836867862969, r 0.7509933774834437, f 0.4957377049180328\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0.4189702868461609 , val_loss : 0.608668863773346,p 0.32767494356659144, r 0.801103752759382, f 0.4651073373918616\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0.41172707080841064 , val_loss : 0.4973321259021759,p 0.4058008884243533, r 0.6856512141280353, f 0.509848982271832\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0.41958534717559814 , val_loss : 0.42836475372314453,p 0.49123702569338096, r 0.6373068432671082, f 0.5548188719131353\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0.412382036447525 , val_loss : 0.511676549911499,p 0.38749407863571766, r 0.7222958057395144, f 0.5043934021889933\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0.4107356667518616 , val_loss : 0.523072361946106,p 0.392094279400933, r 0.7050772626931567, f 0.5039444619753866\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0.39718037843704224 , val_loss : 0.44335195422172546,p 0.483179419525066, r 0.6467991169977925, f 0.5531432886539551\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0.3981684446334839 , val_loss : 0.39467576146125793,p 0.5531256903026287, r 0.5527593818984547, f 0.5529424754333664\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0.40076205134391785 , val_loss : 0.51019287109375,p 0.4125926856855599, r 0.7247240618101545, f 0.5258268599343316\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0.39142045378685 , val_loss : 0.6220508217811584,p 0.34594966574911523, r 0.7768211920529802, f 0.4787103795401987\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0.3895878493785858 , val_loss : 0.5347356200218201,p 0.38719981071808823, r 0.7225165562913908, f 0.5041977971193098\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0.3811461329460144 , val_loss : 0.6212567090988159,p 0.33813768253366205, r 0.7871964679911699, f 0.47306977978243564\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0.38322514295578003 , val_loss : 0.5346431136131287,p 0.3729636048526863, r 0.7125827814569536, f 0.48964732650739473\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0.37968605756759644 , val_loss : 0.5192568302154541,p 0.3889354568315172, r 0.7169977924944813, f 0.5043086716869809\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0.37352147698402405 , val_loss : 0.5059374570846558,p 0.4260089686098655, r 0.6920529801324503, f 0.5273782488014132\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0.3721335530281067 , val_loss : 0.5026051998138428,p 0.4102010524895426, r 0.6710816777041942, f 0.5091700862574324\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0.36651793122291565 , val_loss : 0.5106953382492065,p 0.3940159070824391, r 0.688962472406181, f 0.5013251947634729\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0.36902862787246704 , val_loss : 0.45611220598220825,p 0.4534182305630027, r 0.5973509933774834, f 0.5155267670032387\n",
      "\n",
      "58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58 train_loss : 0.35968488454818726 , val_loss : 0.6024863123893738,p 0.3445455474900317, r 0.7439293598233996, f 0.47096638949060166\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0.3547710180282593 , val_loss : 0.46984872221946716,p 0.4587215955533758, r 0.6194260485651214, f 0.5270968347891425\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0.35799598693847656 , val_loss : 0.48117175698280334,p 0.433968012185834, r 0.6289183222958057, f 0.5135646687697161\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0.345816433429718 , val_loss : 0.4772789478302002,p 0.48415648787396, r 0.6037527593818984, f 0.5373808822084684\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0.346746563911438 , val_loss : 0.5445703268051147,p 0.38267419962335214, r 0.6728476821192053, f 0.4878751500600241\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0.3478676974773407 , val_loss : 0.5382485389709473,p 0.3831707317073171, r 0.693598233995585, f 0.49363707776904947\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0.3407798111438751 , val_loss : 0.5089538097381592,p 0.4112176692821854, r 0.6247240618101545, f 0.49596915527514895\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0.33902889490127563 , val_loss : 0.48294156789779663,p 0.41632109004739337, r 0.6205298013245033, f 0.49831590143591564\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0.33206796646118164 , val_loss : 0.5890836119651794,p 0.35543478260869565, r 0.7218543046357616, f 0.47632920611798973\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0.3258604109287262 , val_loss : 0.5332573056221008,p 0.395583681163323, r 0.6485651214128035, f 0.4914276156226478\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0.33063870668411255 , val_loss : 0.5714267492294312,p 0.3695007978117164, r 0.7156732891832229, f 0.48737221888153937\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0.319524884223938 , val_loss : 0.5638895630836487,p 0.4000264830508475, r 0.666887417218543, f 0.5000827677536832\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0.3194713592529297 , val_loss : 0.5872530937194824,p 0.3767744938329067, r 0.7147902869757174, f 0.49344711978055467\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0.3193022608757019 , val_loss : 0.4694487154483795,p 0.4818681318681319, r 0.580794701986755, f 0.5267267267267267\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0.30624616146087646 , val_loss : 0.5721087455749512,p 0.3923402075060843, r 0.676158940397351, f 0.4965550782199887\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0.30230236053466797 , val_loss : 0.5621770620346069,p 0.3992110453648915, r 0.6701986754966888, f 0.5003708281829419\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0.29947561025619507 , val_loss : 0.5992723107337952,p 0.36454038321610477, r 0.6635761589403973, f 0.47056981840951784\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0.30248337984085083 , val_loss : 0.5176391005516052,p 0.4490367199077886, r 0.6019867549668875, f 0.5143827218711685\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0.29439878463745117 , val_loss : 0.5033036470413208,p 0.46112886048988283, r 0.5735099337748344, f 0.511216056670602\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0.3013138175010681 , val_loss : 0.4857446551322937,p 0.47293023255813954, r 0.5611479028697571, f 0.5132761231701161\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0.2864329516887665 , val_loss : 0.5371032357215881,p 0.4391574480981967, r 0.6397350993377483, f 0.5208015095695929\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0.28543126583099365 , val_loss : 0.5739392638206482,p 0.3942926045016077, r 0.6496688741721854, f 0.4907453726863431\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0.2859199047088623 , val_loss : 0.597854733467102,p 0.3728620296465222, r 0.6496688741721854, f 0.47379859937213237\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0.2830279469490051 , val_loss : 0.563468873500824,p 0.4125179856115108, r 0.6328918322295806, f 0.4994773519163764\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0.2737199366092682 , val_loss : 0.5656323432922363,p 0.4008220429289085, r 0.5812362030905077, f 0.4744571583025497\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0.2752014398574829 , val_loss : 0.6303645968437195,p 0.36933839222195874, r 0.6876379690949227, f 0.4805615550755939\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0.275078147649765 , val_loss : 0.5413070917129517,p 0.47136481963555227, r 0.5596026490066225, f 0.5117077109406539\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0.2675535976886749 , val_loss : 0.5944021940231323,p 0.39870630333058077, r 0.639514348785872, f 0.4911834520176331\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0.2630036473274231 , val_loss : 0.5972347259521484,p 0.38845618915159946, r 0.6165562913907284, f 0.4766211604095563\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0.2630453407764435 , val_loss : 0.5573927164077759,p 0.4931452414067157, r 0.5479028697571744, f 0.5190839694656488\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0.252879798412323 , val_loss : 0.6004894375801086,p 0.41001228501228504, r 0.5894039735099338, f 0.483608042021373\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0.26040396094322205 , val_loss : 0.6307844519615173,p 0.37424547283702214, r 0.6980132450331126, f 0.4872486324061947\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0.2565367519855499 , val_loss : 0.5978643894195557,p 0.4121611502171634, r 0.6075055187637969, f 0.4911216204158115\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0.24828793108463287 , val_loss : 0.511650562286377,p 0.49097621000820346, r 0.528476821192053, f 0.5090367850308314\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0.25021275877952576 , val_loss : 0.5570701360702515,p 0.46232755571276973, r 0.5770419426048565, f 0.5133542812254517\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0.23418602347373962 , val_loss : 0.6022862792015076,p 0.45232067510548524, r 0.5916114790286976, f 0.5126733620277379\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0.24585720896720886 , val_loss : 0.6102246642112732,p 0.40951714485654306, r 0.645916114790287, f 0.5012419700214132\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0.23662146925926208 , val_loss : 0.5812343955039978,p 0.4341805148256761, r 0.5883002207505519, f 0.4996250468691414\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0.22836925089359283 , val_loss : 0.6081461906433105,p 0.4199188261005308, r 0.5938189845474614, f 0.49195318215069495\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0.22730287909507751 , val_loss : 0.5856415629386902,p 0.46390225842280636, r 0.5532008830022075, f 0.50463149416029\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0.2284090369939804 , val_loss : 0.7714329361915588,p 0.3411199650693156, r 0.6898454746136865, f 0.4565042728799941\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0.22160673141479492 , val_loss : 0.716177225112915,p 0.3583959899749373, r 0.6944812362030905, f 0.47279831680192363\n",
      "\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.8248175182481752, recall : 0.29658792650918636, f1 : 0.43629343629343625, accuracy : 0.8814935064935064\n",
      "102844341902586509\n",
      "precision : 0.5794871794871795, recall : 0.8932806324110671, f1 : 0.7029548989113532, accuracy : 0.9106641721234799\n",
      "102844401152267937\n",
      "precision : 0.2237442922374429, recall : 0.24378109452736318, f1 : 0.23333333333333334, accuracy : 0.7186544342507645\n",
      "102844212430927059\n",
      "precision : 0.6169154228855721, recall : 0.5636363636363636, f1 : 0.5890736342042755, accuracy : 0.863528793058112\n",
      "102844412708953395\n",
      "precision : 0.8284023668639053, recall : 0.5072463768115942, f1 : 0.6292134831460674, accuracy : 0.9197470817120622\n",
      "102844212429944013\n",
      "precision : 0.7028301886792453, recall : 0.40161725067385445, f1 : 0.5111492281303603, accuracy : 0.8607038123167156\n",
      "102844341912679064\n",
      "precision : 0.33969465648854963, recall : 0.7876106194690266, f1 : 0.4746666666666667, accuracy : 0.7969072164948454\n",
      "102844235753749959\n",
      "precision : 0.19863013698630136, recall : 0.22137404580152673, f1 : 0.20938628158844766, accuracy : 0.7035198555956679\n",
      "102844341908026005\n",
      "precision : 0.5752808988764045, recall : 0.7769347496206374, f1 : 0.6610716591349258, accuracy : 0.8200205690778197\n",
      "102844283023206486\n",
      "precision : 0.7652733118971061, recall : 0.6666666666666666, f1 : 0.7125748502994012, accuracy : 0.8951965065502183\n",
      "102844224147717245\n",
      "precision : 0.7389830508474576, recall : 0.7032258064516129, f1 : 0.7206611570247934, accuracy : 0.9078516902944384\n",
      "102844412704890154\n",
      "precision : 0.8268398268398268, recall : 0.6221498371335505, f1 : 0.7100371747211897, accuracy : 0.9248192771084337\n",
      "102844212430599377\n",
      "precision : 0.5950413223140496, recall : 0.6101694915254238, f1 : 0.6025104602510462, accuracy : 0.9186295503211992\n",
      "102844412711443769\n",
      "precision : 0.6269185360094451, recall : 0.7831858407079646, f1 : 0.6963934426229509, accuracy : 0.8180031446540881\n",
      "102844235747982779\n",
      "precision : 0.7067307692307693, recall : 0.6082758620689656, f1 : 0.653817642698295, accuracy : 0.8288123167155426\n",
      "==precision : 0.6099726318594286, recall : 0.5790495042676536, f1 : 0.5695424899351028, accuracy : 0.8512367951177928\n",
      "data load fin\n",
      "102844412722519367\n",
      "102844212429550795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n",
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n",
      "102844294671796427\n",
      "102844224145685626\n",
      "102844412717407552\n",
      "102844235751390657\n",
      "102844401156069033\n",
      "102904869420860038\n",
      "102910307641576395\n",
      "102844341905404560\n",
      "102844341906977427\n",
      "102844212430075086\n",
      "102844412711116088\n",
      "102844401153578660\n",
      "102844294667405508\n",
      "102844412706659630\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n"
     ]
    }
   ],
   "source": [
    "hyper_parameter = [128,256]\n",
    "weight_directory=['audio_1/','_d128/','_d256/',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for exp_index in range(0,1):\n",
    "\n",
    "    global weight_dir\n",
    "    weight_dir= conf['dataset']['weight_path']#+weight_directory[exp_index]##weight 저장\n",
    "    model_epoch = conf['trn_args']['epoch']\n",
    "    \n",
    "    global input_size,hidden_size,num_layers\n",
    "    input_size=total_size\n",
    "    hidden_size=hyper_parameter[exp_index]\n",
    "    num_layers=conf['trn_args']['num_layer']\n",
    "\n",
    "    lr = conf['trn_args']['lr']\n",
    "\n",
    "    model=LSTM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "        f.write('=====result=======\\n')\n",
    "    f1_best=0\n",
    "    for epoch in range(model_epoch):\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "            inputs=inputs.float()\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out,_=model(inputs)\n",
    "            out=out.to(device)\n",
    "            loss=criterion(out,labels)\n",
    "            losses.update(loss,labels.size(0))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_losses=AverageMeter()\n",
    "        acc=0\n",
    "        gt_sum=0\n",
    "        tp_sum=0\n",
    "        fp_sum=0\n",
    "        fn_sum=0\n",
    "        acc=0\n",
    "        sum=0\n",
    "        pred_sum=0\n",
    "\n",
    "\n",
    "        with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                    inputs=inputs.float()\n",
    "                    inputs=inputs.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    out,_=model(inputs)\n",
    "                    out=out.to(device)\n",
    "                    loss=criterion(out,labels)\n",
    "                    val_losses.update(loss,labels.size(0))\n",
    "                    TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                    tp_sum += TP\n",
    "                    fp_sum += FP\n",
    "                    fn_sum += FN\n",
    "                    pred_sum += pred_len\n",
    "                    gt_sum += gt_len\n",
    "                    acc=acc+TP+TN\n",
    "                    sum+=len(out)\n",
    "                if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                    precision = tp_sum/(tp_sum+fp_sum)\n",
    "                    recall = tp_sum / (tp_sum+fn_sum)\n",
    "                    f1 = (2*precision*recall / (precision + recall))\n",
    "                    accuracy=acc/sum\n",
    "                    print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                    wr = csv.writer(csv_f)\n",
    "                    wr.writerow([epoch,precision, recall,f1])\n",
    "                    csv_f.close()\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                    if f1_best<f1:\n",
    "                        f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                        torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                        f1_best=f1\n",
    "\n",
    "                else:\n",
    "                    print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                    f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                    csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                    wr = csv.writer(csv_f)\n",
    "                    wr.writerow([epoch,0, 0,0])\n",
    "                    csv_f.close()\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "    def fmeasure2(frames,label): ##measure def for test\n",
    "        average = [0,0,0,0,0]\n",
    "        for key in frames.keys():\n",
    "            TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "            FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "            TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "            FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "            if precision==0 and recall == 0:\n",
    "                print('!')\n",
    "            else:\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                print(key)\n",
    "                print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "                average[0]+= precision\n",
    "                average[1]+= recall\n",
    "                average[2]+= f1\n",
    "                average[3]+= accuracy\n",
    "                average[4]+=1\n",
    "        print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "        with open(weight_dir+'eval','a') as f:\n",
    "            f.write(\"precision : {}, recall : {}, f1 : {}, accuracy : {}\".format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "                    \n",
    "\n",
    "    test=Mul_data('test')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    pred_sum = 0#model output\n",
    "    gt_sum = 0#label\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    result={}\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output,_=model(inputs)\n",
    "            TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "            for idx,g in enumerate(game_id):\n",
    "                if g not in result.keys():\n",
    "                    result[g]=pred[idx].tolist()\n",
    "                else:\n",
    "                    result[g]+=pred[idx].tolist()\n",
    "    with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "        real_result=pickle.load(f4)\n",
    "    fmeasure2(result,real_result)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #test\n",
    "\n",
    "\n",
    "\n",
    "    test=Mul_data('total')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=1)\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    result={}\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output_p,output_f=model(inputs)\n",
    "\n",
    "            if game_id[0] not in result.keys():\n",
    "                print(game_id[0])\n",
    "                result[game_id[0]]=[(output_f[0]).tolist()]\n",
    "\n",
    "            else:\n",
    "                result[game_id[0]]+=[(output_f[0]).tolist()]\n",
    "\n",
    "\n",
    "\n",
    "    with open(weight_dir+'audio_feature.json','a') as f:\n",
    "        json.dump(result,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1609c5d6daf415add5fd1f90da23d5406f9079b60a4e5640100862a3157a35d6"
  },
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
