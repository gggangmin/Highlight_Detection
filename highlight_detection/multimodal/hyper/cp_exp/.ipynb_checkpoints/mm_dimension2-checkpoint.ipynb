{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레인함과 동시에 f1스코어 계산 & csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffb280ae190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv\n",
    "torch.manual_seed(712) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config/mm_dimension2.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=json.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=json.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=json.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio['102844412722519367'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:1\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=json.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=json.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=json.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = int(chat_size)+int(audio_size)+int(video_size)\n",
    "            \n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "                    s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=list(self.video[game_id][vframe+idx])\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('test')## 그래프 그리기위해 val 없이 test로 바로진행\n",
    "\n",
    "#test\n",
    "print(\"\\n\\ndatset testing....\")\n",
    "print(train[0])\n",
    "print(len(train[100][1]))\n",
    "print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "#loader행\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hyper_parameter = [32,64,128,256,512]\n",
    "weight_directory = ['mm_window9/']\n",
    "\n",
    "global input_size,hidden_size,num_layers\n",
    "input_size=total_size\n",
    "num_layers=conf['trn_args']['num_layer']\n",
    "print(input_size)\n",
    "\n",
    "for exp_index in range(0,1):\n",
    "\n",
    "  hidden_size=conf['trn_args']['hidden_size']\n",
    "  global weight_dir\n",
    "  weight_dir= conf['dataset']['weight_path']+weight_directory[exp_index]\n",
    "\n",
    "  lr = conf['trn_args']['lr']\n",
    "\n",
    "  model=LSTM().to(device)\n",
    "  criterion = nn.CrossEntropyLoss().to(device)\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "  model_epoch = conf['trn_args']['epoch']\n",
    "\n",
    "  # dataset=weight_dir+'best'\n",
    "  # checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "  # model.load_state_dict(checkpoint)\n",
    "\n",
    "\n",
    "  if not os.path.exists(weight_dir):\n",
    "      os.makedirs(weight_dir)\n",
    "  with open(weight_dir+'train_result','a') as f:\n",
    "      f.write('=====result=======\\n')\n",
    "  f1_best=0\n",
    "  for epoch in range(model_epoch):\n",
    "      if conf['trn_args']['adj_lr']:\n",
    "          lr = adjust_learning_rate(optimizer, epoch)\n",
    "      losses = AverageMeter()\n",
    "      print(epoch)\n",
    "      model.train()\n",
    "      for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "          inputs=inputs.float()\n",
    "          inputs=inputs.to(device)\n",
    "          labels=labels.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          out,_=model(inputs)\n",
    "          out=out.to(device)\n",
    "          loss=criterion(out,labels)\n",
    "          loss.backward()\n",
    "          losses.update(loss,labels.size(0))\n",
    "          optimizer.step()\n",
    "          \n",
    "      model.eval()\n",
    "      val_losses=AverageMeter()\n",
    "      acc=0\n",
    "      gt_sum=0\n",
    "      tp_sum=0\n",
    "      fp_sum=0\n",
    "      fn_sum=0\n",
    "      acc=0\n",
    "      sum=0\n",
    "      pred_sum=0\n",
    "      \n",
    "      \n",
    "      with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "          with torch.no_grad():\n",
    "              for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                  inputs=inputs.float()\n",
    "                  inputs=inputs.to(device)\n",
    "                  labels=labels.to(device)\n",
    "                  out,_=model(inputs)\n",
    "                  out=out.to(device)\n",
    "                  loss=criterion(out,labels)\n",
    "                  val_losses.update(loss,labels.size(0))\n",
    "                  TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                  tp_sum += TP\n",
    "                  fp_sum += FP\n",
    "                  fn_sum += FN\n",
    "                  pred_sum += pred_len\n",
    "                  gt_sum += gt_len\n",
    "                  acc=acc+TP+TN\n",
    "                  sum+=len(out)\n",
    "              if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                  precision = tp_sum/(tp_sum+fp_sum)\n",
    "                  recall = tp_sum / (tp_sum+fn_sum)\n",
    "                  f1 = (2*precision*recall / (precision + recall))\n",
    "                  accuracy=acc/sum\n",
    "                  print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                  f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                  csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                  wr = csv.writer(csv_f)\n",
    "                  wr.writerow([epoch,precision, recall,f1])\n",
    "                  csv_f.close()\n",
    "                  torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                  \n",
    "                  if f1_best<f1:\n",
    "                      f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                      torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                      f1_best=f1\n",
    "\n",
    "              else:\n",
    "                  print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                  f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                  csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                  wr = csv.writer(csv_f)\n",
    "                  wr.writerow([epoch,0, 0,0])\n",
    "                  csv_f.close()\n",
    "                  torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "\n",
    "              \n",
    "  def fmeasure2(frames,label): ##measure def for test\n",
    "      average = [0,0,0,0,0]\n",
    "      for key in frames.keys():\n",
    "          TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "          FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "          TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "          FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "          precision = TP/(TP+FP)\n",
    "          recall = TP/(TP+FN)\n",
    "          accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "          if precision==0 and recall == 0:\n",
    "              print('!')\n",
    "          else:\n",
    "              f1 = (2*precision*recall / (precision + recall))\n",
    "              print(key)\n",
    "              print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "              average[0]+= precision\n",
    "              average[1]+= recall\n",
    "              average[2]+= f1\n",
    "              average[3]+= accuracy\n",
    "              average[4]+=1\n",
    "      print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "      \n",
    "      csv_f = open(weight_dir+'eval.csv','a', newline='')\n",
    "      wr = csv.writer(csv_f)\n",
    "      wr.writerow('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "      csv_f.close()\n",
    "\n",
    "  try: \n",
    "    test=Mul_data('test')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    pred_sum = 0#model output\n",
    "    gt_sum = 0#label\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    result={}\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output,_=model(inputs)\n",
    "            TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "            for idx,g in enumerate(game_id):\n",
    "                if g not in result.keys():\n",
    "                    result[g]=pred[idx].tolist()\n",
    "                else:\n",
    "                    result[g]+=pred[idx].tolist()\n",
    "    with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "        real_result=pickle.load(f4)\n",
    "    fmeasure2(result,real_result)\n",
    "  except:\n",
    "    print('no best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.54545454545455"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1750/22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.7028301886792453, recall : 0.7821522309711286, f1 : 0.7403726708074534, accuracy : 0.9151785714285714\n",
      "102844341902586509\n",
      "precision : 0.5851851851851851, recall : 0.9367588932806324, f1 : 0.7203647416413375, accuracy : 0.9139382600561272\n",
      "102844401152267937\n",
      "precision : 0.6183206106870229, recall : 0.8059701492537313, f1 : 0.6997840172786176, accuracy : 0.8785495849716033\n",
      "102844212430927059\n",
      "precision : 0.744475138121547, recall : 0.8166666666666667, f1 : 0.7789017341040463, accuracy : 0.9195372074677886\n",
      "102844412708953395\n",
      "precision : 0.678125, recall : 0.7862318840579711, f1 : 0.7281879194630873, accuracy : 0.9212062256809338\n",
      "102844212429944013\n",
      "precision : 0.6915887850467289, recall : 0.7978436657681941, f1 : 0.7409261576971213, accuracy : 0.8988269794721407\n",
      "102844341912679064\n",
      "precision : 0.5637982195845698, recall : 0.8407079646017699, f1 : 0.674955595026643, accuracy : 0.9056701030927835\n",
      "102844235753749959\n",
      "precision : 0.5587583148558758, recall : 0.6412213740458015, f1 : 0.5971563981042654, accuracy : 0.8465703971119134\n",
      "102844341908026005\n",
      "precision : 0.6915544675642595, recall : 0.8573596358118362, f1 : 0.7655826558265584, accuracy : 0.8813849845731916\n",
      "102844283023206486\n",
      "precision : 0.6494845360824743, recall : 0.8823529411764706, f1 : 0.7482185273159145, accuracy : 0.8842794759825328\n",
      "102844224147717245\n",
      "precision : 0.736, recall : 0.8903225806451613, f1 : 0.8058394160583942, accuracy : 0.9274809160305344\n",
      "102844412704890154\n",
      "precision : 0.6894865525672371, recall : 0.9185667752442996, f1 : 0.7877094972067039, accuracy : 0.9267469879518072\n",
      "102844212430599377\n",
      "precision : 0.579250720461095, recall : 0.8516949152542372, f1 : 0.6895368782161234, accuracy : 0.9224839400428265\n",
      "102844412711443769\n",
      "precision : 0.7627329192546584, recall : 0.9056047197640118, f1 : 0.8280512474713418, accuracy : 0.8997641509433962\n",
      "102844235747982779\n",
      "precision : 0.7192393736017897, recall : 0.886896551724138, f1 : 0.7943174799258803, accuracy : 0.8779325513196481\n",
      "==precision : 0.6647220007794458, recall : 0.84002339655107, f1 : 0.7399936624095658, accuracy : 0.9013033557417199\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6835748792270532, recall : 0.7427821522309711, f1 : 0.7119496855345913, accuracy : 0.9070616883116883\n",
      "102844341902586509\n",
      "precision : 0.5594405594405595, recall : 0.9486166007905138, f1 : 0.7038123167155426, accuracy : 0.9055191768007483\n",
      "102844401152267937\n",
      "precision : 0.6447876447876448, recall : 0.8308457711442786, f1 : 0.7260869565217392, accuracy : 0.8899082568807339\n",
      "102844212430927059\n",
      "precision : 0.7327249022164276, recall : 0.8515151515151516, f1 : 0.7876664330763842, accuracy : 0.9203260583749672\n",
      "102844412708953395\n",
      "precision : 0.6612377850162866, recall : 0.7355072463768116, f1 : 0.6963979416809606, accuracy : 0.9139105058365758\n",
      "102844212429944013\n",
      "precision : 0.6980676328502415, recall : 0.7789757412398922, f1 : 0.7363057324840765, accuracy : 0.8988269794721407\n",
      "102844341912679064\n",
      "precision : 0.5307262569832403, recall : 0.8407079646017699, f1 : 0.6506849315068494, accuracy : 0.8948453608247423\n",
      "102844235753749959\n",
      "precision : 0.592436974789916, recall : 0.7175572519083969, f1 : 0.6490218642117377, accuracy : 0.8623646209386282\n",
      "102844341908026005\n",
      "precision : 0.660217654171705, recall : 0.8285280728376327, f1 : 0.7348586810228801, accuracy : 0.8649297223174495\n",
      "102844283023206486\n",
      "precision : 0.6509635974304069, recall : 0.8515406162464986, f1 : 0.7378640776699029, accuracy : 0.8820960698689956\n",
      "102844224147717245\n",
      "precision : 0.7127937336814621, recall : 0.8806451612903226, f1 : 0.787878787878788, accuracy : 0.9198473282442748\n",
      "102844412704890154\n",
      "precision : 0.7275064267352185, recall : 0.9218241042345277, f1 : 0.8132183908045977, accuracy : 0.9373493975903614\n",
      "102844212430599377\n",
      "precision : 0.616822429906542, recall : 0.8389830508474576, f1 : 0.7109515260323159, accuracy : 0.9310492505353319\n",
      "102844412711443769\n",
      "precision : 0.7613776137761378, recall : 0.9129793510324484, f1 : 0.8303152246814218, accuracy : 0.9005503144654088\n",
      "102844235747982779\n",
      "precision : 0.746730083234245, recall : 0.8662068965517241, f1 : 0.8020434227330778, accuracy : 0.8863636363636364\n",
      "==precision : 0.665293878283139, recall : 0.8364810088565597, f1 : 0.7386037315036578, accuracy : 0.900996557788379\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6638830897703549, recall : 0.8346456692913385, f1 : 0.7395348837209303, accuracy : 0.9090909090909091\n",
      "102844341902586509\n",
      "precision : 0.5123456790123457, recall : 0.9841897233201581, f1 : 0.6738836265223275, accuracy : 0.8872778297474275\n",
      "102844401152267937\n",
      "precision : 0.571658615136876, recall : 0.8830845771144279, f1 : 0.6940371456500488, accuracy : 0.8632590650939275\n",
      "102844212430927059\n",
      "precision : 0.6594594594594595, recall : 0.9242424242424242, f1 : 0.7697160883280757, accuracy : 0.9040231396266105\n",
      "102844412708953395\n",
      "precision : 0.6005221932114883, recall : 0.8333333333333334, f1 : 0.6980273141122914, accuracy : 0.9032101167315175\n",
      "102844212429944013\n",
      "precision : 0.6722689075630253, recall : 0.862533692722372, f1 : 0.755608028335301, accuracy : 0.8988269794721407\n",
      "102844341912679064\n",
      "precision : 0.5012468827930174, recall : 0.8893805309734514, f1 : 0.6411483253588517, accuracy : 0.884020618556701\n",
      "102844235753749959\n",
      "precision : 0.5462794918330308, recall : 0.7659033078880407, f1 : 0.6377118644067796, accuracy : 0.8456678700361011\n",
      "102844341908026005\n",
      "precision : 0.6270096463022508, recall : 0.8877086494688923, f1 : 0.7349246231155779, accuracy : 0.8553308193349332\n",
      "102844283023206486\n",
      "precision : 0.6252354048964218, recall : 0.9299719887955182, f1 : 0.7477477477477477, accuracy : 0.8777292576419214\n",
      "102844224147717245\n",
      "precision : 0.6713947990543735, recall : 0.9161290322580645, f1 : 0.7748976807639837, accuracy : 0.9100327153762269\n",
      "102844412704890154\n",
      "precision : 0.6268656716417911, recall : 0.9576547231270358, f1 : 0.7577319587628867, accuracy : 0.9093975903614457\n",
      "102844212430599377\n",
      "precision : 0.527363184079602, recall : 0.8983050847457628, f1 : 0.664576802507837, accuracy : 0.9083511777301927\n",
      "102844412711443769\n",
      "precision : 0.7273755656108597, recall : 0.948377581120944, f1 : 0.823303457106274, accuracy : 0.8915094339622641\n",
      "102844235747982779\n",
      "precision : 0.6910229645093946, recall : 0.9131034482758621, f1 : 0.7866904337492573, accuracy : 0.8684017595307918\n",
      "==precision : 0.6149287703249529, recall : 0.895237584445175, f1 : 0.7266359986792114, accuracy : 0.887741952152874\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6388349514563106, recall : 0.863517060367454, f1 : 0.7343749999999998, accuracy : 0.9034090909090909\n",
      "102844341902586509\n",
      "precision : 0.5124481327800829, recall : 0.9762845849802372, f1 : 0.672108843537415, accuracy : 0.8872778297474275\n",
      "102844401152267937\n",
      "precision : 0.5889763779527559, recall : 0.9303482587064676, f1 : 0.7213114754098361, accuracy : 0.873743993010048\n",
      "102844212430927059\n",
      "precision : 0.6331967213114754, recall : 0.9363636363636364, f1 : 0.7555012224938875, accuracy : 0.8948198790428609\n",
      "102844412708953395\n",
      "precision : 0.5984251968503937, recall : 0.8260869565217391, f1 : 0.6940639269406393, accuracy : 0.9022373540856031\n",
      "102844212429944013\n",
      "precision : 0.6515463917525773, recall : 0.8517520215633423, f1 : 0.7383177570093458, accuracy : 0.8905180840664711\n",
      "102844341912679064\n",
      "precision : 0.4707259953161593, recall : 0.8893805309734514, f1 : 0.6156202143950996, accuracy : 0.8706185567010309\n",
      "102844235753749959\n",
      "precision : 0.5456140350877193, recall : 0.7913486005089059, f1 : 0.6458982346832813, accuracy : 0.8461191335740073\n",
      "102844341908026005\n",
      "precision : 0.6138509968520461, recall : 0.8877086494688923, f1 : 0.7258064516129032, accuracy : 0.8484744600617072\n",
      "102844283023206486\n",
      "precision : 0.5952813067150635, recall : 0.9187675070028011, f1 : 0.7224669603524229, accuracy : 0.8624454148471615\n",
      "102844224147717245\n",
      "precision : 0.6457399103139013, recall : 0.9290322580645162, f1 : 0.7619047619047619, accuracy : 0.9018538713195202\n",
      "102844412704890154\n",
      "precision : 0.620253164556962, recall : 0.9576547231270358, f1 : 0.7528809218950063, accuracy : 0.9069879518072289\n",
      "102844212430599377\n",
      "precision : 0.5221674876847291, recall : 0.8983050847457628, f1 : 0.660436137071651, accuracy : 0.9066381156316916\n",
      "102844412711443769\n",
      "precision : 0.727683615819209, recall : 0.9498525073746312, f1 : 0.8240563019833653, accuracy : 0.8919025157232704\n",
      "102844235747982779\n",
      "precision : 0.6882168925964547, recall : 0.9103448275862069, f1 : 0.7838479809976248, accuracy : 0.8665689149560117\n",
      "==precision : 0.6035307451363894, recall : 0.9011164804903388, f1 : 0.7205730793524825, accuracy : 0.8835743443655422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6509240246406571, recall : 0.8320209973753281, f1 : 0.7304147465437789, accuracy : 0.9050324675324676\n",
      "102844341902586509\n",
      "precision : 0.5268817204301075, recall : 0.9683794466403162, f1 : 0.6824512534818942, accuracy : 0.8933582787652011\n",
      "102844401152267937\n",
      "precision : 0.6331569664902998, recall : 0.8930348258706468, f1 : 0.7409700722394221, accuracy : 0.8903451288772389\n",
      "102844212430927059\n",
      "precision : 0.6644219977553311, recall : 0.896969696969697, f1 : 0.763378465506125, accuracy : 0.9034972390218249\n",
      "102844412708953395\n",
      "precision : 0.6202185792349727, recall : 0.822463768115942, f1 : 0.7071651090342679, accuracy : 0.9085603112840467\n",
      "102844212429944013\n",
      "precision : 0.6560509554140127, recall : 0.8328840970350404, f1 : 0.7339667458432303, accuracy : 0.8905180840664711\n",
      "102844341912679064\n",
      "precision : 0.5, recall : 0.8805309734513275, f1 : 0.6378205128205129, accuracy : 0.8835051546391752\n",
      "102844235753749959\n",
      "precision : 0.5533807829181495, recall : 0.7913486005089059, f1 : 0.6513089005235602, accuracy : 0.8497292418772563\n",
      "102844341908026005\n",
      "precision : 0.6258134490238612, recall : 0.8755690440060698, f1 : 0.7299177735610374, accuracy : 0.8536167295166267\n",
      "102844283023206486\n",
      "precision : 0.6150943396226415, recall : 0.9131652661064426, f1 : 0.7350620067643742, accuracy : 0.8717248908296943\n",
      "102844224147717245\n",
      "precision : 0.6574074074074074, recall : 0.9161290322580645, f1 : 0.7654986522911053, accuracy : 0.9051254089422028\n",
      "102844412704890154\n",
      "precision : 0.6413043478260869, recall : 0.9609120521172638, f1 : 0.7692307692307692, accuracy : 0.914698795180723\n",
      "102844212430599377\n",
      "precision : 0.5380710659898477, recall : 0.8983050847457628, f1 : 0.6730158730158731, accuracy : 0.9117773019271949\n",
      "102844412711443769\n",
      "precision : 0.7485172004744959, recall : 0.9306784660766961, f1 : 0.8297172912557528, accuracy : 0.898191823899371\n",
      "102844235747982779\n",
      "precision : 0.7116430903155604, recall : 0.9020689655172414, f1 : 0.7956204379562043, accuracy : 0.8768328445747801\n",
      "==precision : 0.6228590618362287, recall : 0.8876306877863163, f1 : 0.7297025740045271, accuracy : 0.8904342467289516\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "\n",
    "\n",
    "hyper_parameter = [32,64,128,256,512]\n",
    "weight_directory = ['dimension32/','dimension64/','dimension128/','dimension256/','dimension512/']\n",
    "\n",
    "global input_size,hidden_size,num_layers\n",
    "input_size=total_size\n",
    "num_layers=conf['trn_args']['num_layer']\n",
    "print(input_size)\n",
    "\n",
    "for exp_index in range(0,5):\n",
    "    \n",
    "    \n",
    "    hidden_size=hyper_parameter[exp_index]\n",
    "    global weight_dir\n",
    "    weight_dir= conf['dataset']['weight_path']+weight_directory[exp_index]\n",
    "\n",
    "    lr = conf['trn_args']['lr']\n",
    "\n",
    "    model=LSTM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)\n",
    "    \n",
    "    \n",
    "    def fmeasure2(frames,label): ##measure def for test\n",
    "        average = [0,0,0,0,0]\n",
    "        for key in frames.keys():\n",
    "            TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "            FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "            TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "            FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "            if precision==0 and recall == 0:\n",
    "                print('!')\n",
    "            else:\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                print(key)\n",
    "                print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "                average[0]+= precision\n",
    "                average[1]+= recall\n",
    "                average[2]+= f1\n",
    "                average[3]+= accuracy\n",
    "                average[4]+=1\n",
    "        print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "        csv_f = open(weight_dir+'eval.csv','a', newline='')\n",
    "        wr = csv.writer(csv_f)\n",
    "        wr.writerow('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "        csv_f.close()\n",
    "\n",
    "    try: \n",
    "        test=Mul_data('test')\n",
    "        test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "        dataset=weight_dir+'best'\n",
    "        checkpoint=torch.load(dataset,map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        pred_sum = 0#model output\n",
    "        gt_sum = 0#label\n",
    "        tp_sum=0\n",
    "        fp_sum=0\n",
    "        fn_sum=0\n",
    "        acc=0\n",
    "        sum=0\n",
    "        result={}\n",
    "\n",
    "\n",
    "        #evaluation\n",
    "        with torch.no_grad():\n",
    "            for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "                inputs=inputs.float()\n",
    "                labels=labels\n",
    "                output,_=model(inputs)\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "                for idx,g in enumerate(game_id):\n",
    "                    if g not in result.keys():\n",
    "                        result[g]=pred[idx].tolist()\n",
    "                    else:\n",
    "                        result[g]+=pred[idx].tolist()\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            real_result=pickle.load(f4)\n",
    "        fmeasure2(result,real_result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
