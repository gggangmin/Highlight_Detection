{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        if d_type=='train':\n",
    "            with open('./data/chat_feature_train.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='val':\n",
    "            with open('./data/chat_feature_val.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='test':\n",
    "            with open('./data/chat_feature_test.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        \n",
    "        with open('./LSTM_feature_extractor_Audio_13_ver2/features',\"rb\") as f2:  \n",
    "            self.audio=json.load(f2)\n",
    "        with open('./video_raw_feature_sum_moving_average/video_feature.pickle',\"rb\") as f2:  \n",
    "            self.video=pickle.load(f2)\n",
    "        with open('./label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.chat_result[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "#             window=[]#batch*7(window size)*3(highlight result)\n",
    "#             for idx in range(23): #7 : window size\n",
    "#                 s_window=[]\n",
    "#                 if vframe+idx<len(self.chat_result[game_id]):\n",
    "#                     s_window+=((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "#                     s_window+=(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "#                     s_window+=self.video[game_id][vframe+idx]\n",
    "#                 else:\n",
    "#                     #s_window=[0,0,0]#padding value\n",
    "#                     s_window=[0]*384\n",
    "#                 window.append(s_window)\n",
    "            window=[]\n",
    "            window+=((self.chat_result[game_id][vframe]))#vframe의 chat\n",
    "            window+=(self.audio[game_id][vframe])#vframe의 image\n",
    "            window+=self.video[game_id][vframe]\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([-0.00423759,  0.00849383,  0.01448581, -0.02064631, -0.02426758,\n",
      "       -0.04851549, -0.04433784, -0.05150938,  0.00209742, -0.00882506,\n",
      "        0.0166546 , -0.00428606,  0.00834568,  0.00139693, -0.02677757,\n",
      "        0.02952239, -0.04051007, -0.02685948, -0.043068  , -0.04851913,\n",
      "        0.02603475, -0.04868141,  0.00577841,  0.01025331,  0.00876541,\n",
      "        0.00091602, -0.02073224,  0.00888079, -0.06355605, -0.02835641,\n",
      "        0.01462168,  0.04098507,  0.02122012, -0.02321672, -0.04046787,\n",
      "        0.03296892, -0.05834012,  0.00234394,  0.00557813, -0.04183179,\n",
      "        0.03197912,  0.02549705, -0.00770896,  0.01083043, -0.02578666,\n",
      "       -0.01174926,  0.07748816,  0.01857281,  0.0019242 , -0.01787918,\n",
      "        0.02091477,  0.02265098,  0.02061003,  0.01535978, -0.02401214,\n",
      "        0.0086167 ,  0.03011051, -0.00084795, -0.00454742,  0.02914281,\n",
      "        0.00860303,  0.01394488,  0.01334044,  0.00997945, -0.00854318,\n",
      "        0.01136737,  0.02267394, -0.03460012, -0.01433924,  0.0228637 ,\n",
      "       -0.0340223 ,  0.02850833, -0.02268256,  0.0425337 ,  0.00592723,\n",
      "       -0.00351851,  0.00793658, -0.03411606, -0.03378449,  0.05903791,\n",
      "        0.05903886,  0.02824106,  0.05598727,  0.03847382, -0.01159923,\n",
      "        0.01300435, -0.01729391,  0.01464747,  0.01135301,  0.00214254,\n",
      "       -0.0094836 ,  0.03571215, -0.0182606 , -0.04962388, -0.01688433,\n",
      "        0.04447569,  0.00207857, -0.02795657,  0.01894708,  0.02774719,\n",
      "       -0.01782852, -0.02993042,  0.00087503,  0.01663705,  0.00092965,\n",
      "       -0.02997122,  0.01652689,  0.00167571,  0.00420156,  0.01017738,\n",
      "       -0.03143992, -0.06415148,  0.00951121, -0.03235073,  0.06809465,\n",
      "       -0.03239367,  0.02572946, -0.02044827, -0.01205325,  0.01855051,\n",
      "       -0.01546504,  0.0053102 , -0.04027211, -0.00544653,  0.01666185,\n",
      "       -0.04917248, -0.01069116,  0.00868443, -0.00321083,  0.01688604,\n",
      "       -0.02411138, -0.06332476,  0.04677523, -0.1042209 , -0.12977125,\n",
      "       -0.01226355, -0.04125182,  0.08607858, -0.20394768, -0.16718839,\n",
      "        0.11407649,  0.06896513,  0.21322462, -0.01170871, -0.07508038,\n",
      "       -0.04952446,  0.10139412, -0.08189006,  0.01734557,  0.25808293,\n",
      "        0.04034879,  0.0794773 , -0.04156448,  0.0203698 , -0.12225534,\n",
      "       -0.06403977,  0.02614173, -0.0669687 , -0.22740789, -0.00255594,\n",
      "        0.01425609, -0.01237656,  0.07231387,  0.13373476,  0.05161721,\n",
      "        0.18574236,  0.06093132,  0.00654395, -0.02403588,  0.00353628,\n",
      "        0.13054122,  0.08532817,  0.09079485, -0.11733081, -0.06664789,\n",
      "        0.11108349, -0.01390412,  0.08491404, -0.0488205 ,  0.01390235,\n",
      "       -0.06490958,  0.0893768 , -0.01593505,  0.06636016, -0.01873533,\n",
      "        0.09110208,  0.01593809,  0.01333248,  0.06536678, -0.00412748,\n",
      "        0.00603703, -0.03862072, -0.03665489,  0.1119459 , -0.03833228,\n",
      "       -0.17402923,  0.10114622, -0.10061534, -0.0506582 ,  0.17872171,\n",
      "        0.02287278, -0.0488887 , -0.08041359, -0.06399649, -0.02590658,\n",
      "        0.01846547, -0.14933936, -0.0649014 , -0.08000361,  0.16511238,\n",
      "       -0.0645802 ,  0.08134558, -0.04306416, -0.010225  ,  0.01148469,\n",
      "        0.02395131, -0.07492236,  0.04527309,  0.10293831, -0.14646545,\n",
      "       -0.01607058,  0.02560602, -0.063067  ,  0.02249781,  0.05765743,\n",
      "       -0.16857286,  0.13777968, -0.15584354, -0.13646835, -0.03316641,\n",
      "        0.05978786,  0.1077757 , -0.11265121, -0.0625103 , -0.17482048,\n",
      "       -0.08614201, -0.04717254, -0.07979184, -0.25723043,  0.14336187,\n",
      "       -0.10629284, -0.03056571,  0.01737296, -0.03885562,  0.06868539,\n",
      "        0.12232152, -0.01740821,  0.0585099 , -0.15328881,  0.0977983 ,\n",
      "       -0.06801379, -0.01495608,  0.08503202,  0.07754833, -0.02197156,\n",
      "        0.14336322, -0.08037048, -0.02835998,  0.14703284,  0.16597989,\n",
      "        0.07253802, -0.29562277, -0.04746353,  0.12121437,  0.09611428,\n",
      "       -0.25385192, -0.14527988,  0.18363787, -0.17246427, -0.06887119,\n",
      "       -0.17364977,  0.28725788,  0.05457603, -0.12035149,  0.12133119,\n",
      "        0.03029247,  0.08032678, -0.0331514 , -0.12127057, -0.01067044,\n",
      "        0.11334357, -0.15095748,  0.36248055, -0.03066078,  0.11671127,\n",
      "       -0.01896255, -0.09051798,  0.13383199, -0.04316915,  0.08944235,\n",
      "       -0.02867202,  0.10579842, -0.01382216, -0.0836892 , -0.08812483,\n",
      "       -0.04194183,  0.007939  ,  0.21542275,  0.0599596 , -0.06780411,\n",
      "        0.05733142, -0.07005605,  0.06664763,  0.20403224, -0.36988148,\n",
      "       -0.06330825,  0.11463822,  0.24981768, -0.27545214, -0.04106139,\n",
      "        0.20281067, -0.07066826, -0.18754296, -0.00412638, -0.15226106,\n",
      "       -0.2511768 , -0.01065536, -0.03442205, -0.1693086 , -0.11666626,\n",
      "       -0.06387381, -0.03246514,  0.11180814, -0.04573866, -0.21873425,\n",
      "        0.07952957, -0.12565216,  0.06428578,  0.02067969,  0.15354265,\n",
      "       -0.19208889,  0.02158789,  0.1377499 , -0.09273136,  0.01658209,\n",
      "        0.07054731, -0.12177195,  0.02630843,  0.23520793, -0.01564592,\n",
      "        0.01716286,  0.01615622,  0.00463013, -0.38439396, -0.00359925,\n",
      "        0.01810313,  0.15161343,  0.05069429, -0.01942117, -0.06920781,\n",
      "        0.01892149, -0.22295858,  0.0341589 , -0.19204168,  0.00956301,\n",
      "       -0.09823818,  0.00328717,  0.11978188,  0.28633416,  0.32947657,\n",
      "       -0.11427591, -0.01945237,  0.0369379 , -0.08364455,  0.01509192,\n",
      "        0.05671266, -0.01573475,  0.25289658, -0.15340275,  0.07650125,\n",
      "        0.07117711, -0.27796182, -0.06208805, -0.01536666,  0.16557427,\n",
      "        0.16946609, -0.04498453,  0.31506401, -0.29875013, -0.12425118,\n",
      "       -0.02044689, -0.04624566, -0.14462242, -0.06322261]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "\n",
    "print(train[100])\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[100][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=384\n",
    "hidden_size=128\n",
    "length=7\n",
    "num_layers=3\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._lin = nn.Sequential(nn.Linear(in_features=input_size, out_features=hidden_size*2,bias=True),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.7),\n",
    "                                  nn.Linear(in_features=hidden_size*2, out_features=hidden_size,bias=True),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.7),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        out = self._lin(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=MLP().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_dir='./C_raw+A_raw+V_mov_mlp/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.5593744516372681,p 0.5506719941881584, r 0.6693156732891832, f 0.604224790753288\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.48930564522743225,p 0.5884218873909596, r 0.655187637969095, f 0.6200125339461041\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.5147227644920349,p 0.6143572621035058, r 0.6498896247240619, f 0.6316241149967818\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.49274152517318726,p 0.6308623298033282, r 0.6443708609271523, f 0.6375450475046412\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.45681899785995483,p 0.6694175901909927, r 0.626710816777042, f 0.6473606202257439\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.4567948579788208,p 0.6625724217844727, r 0.6311258278145695, f 0.6464669304691916\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.4881395697593689,p 0.6304770127347291, r 0.6448123620309051, f 0.6375641165557132\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.49714037775993347,p 0.6607635694572217, r 0.6342163355408389, f 0.647217841856274\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.47362735867500305,p 0.6528626386060195, r 0.6368653421633554, f 0.644764778187507\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.46013227105140686,p 0.6233821345215361, r 0.6485651214128035, f 0.6357243319268636\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.4606953263282776,p 0.6580453192950332, r 0.6346578366445916, f 0.6461400157321048\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.49876639246940613,p 0.6463251670378619, r 0.6406181015452539, f 0.643458980044346\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.4631894528865814,p 0.6508078994614004, r 0.6401766004415012, f 0.6454484754061874\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.48673784732818604,p 0.5939116593712694, r 0.6589403973509934, f 0.6247383842611972\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0 , val_loss : 0.5093043446540833,p 0.6280213903743316, r 0.6481236203090508, f 0.6379141770776753\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0 , val_loss : 0.4696981608867645,p 0.6456623030840914, r 0.6423841059602649, f 0.6440190328648888\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0 , val_loss : 0.4865315854549408,p 0.6333333333333333, r 0.645916114790287, f 0.6395628415300547\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0 , val_loss : 0.497488796710968,p 0.6098765432098765, r 0.6543046357615894, f 0.6313099041533545\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0 , val_loss : 0.47466760873794556,p 0.5861463414634146, r 0.6631346578366446, f 0.622268254790264\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0 , val_loss : 0.4649318754673004,p 0.6506618801884676, r 0.6401766004415012, f 0.6453766551685769\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0 , val_loss : 0.5227875709533691,p 0.6116384647131655, r 0.6543046357615894, f 0.6322525597269625\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0 , val_loss : 0.5122258067131042,p 0.6094808126410836, r 0.6556291390728477, f 0.6317132829947889\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.4453529119491577,p 0.6717611098048436, r 0.6306843267108168, f 0.6505749743823295\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.48238319158554077,p 0.609981515711645, r 0.6556291390728477, f 0.6319821257580593\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.5086026191711426,p 0.6241525423728813, r 0.6503311258278146, f 0.636972972972973\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.48175305128097534,p 0.6517736865738661, r 0.6408388520971302, f 0.646260017809439\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.4810433089733124,p 0.6373530692207227, r 0.6463576158940397, f 0.6418237615081105\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.4545134902000427,p 0.6768205616373155, r 0.6278145695364239, f 0.6513971598717362\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.4513421654701233,p 0.6585421412300684, r 0.6381898454746137, f 0.6482062780269059\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.4786670506000519,p 0.6498881431767338, r 0.6412803532008831, f 0.6455555555555555\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.45146769285202026,p 0.6416923754958131, r 0.6428256070640177, f 0.6422584913983237\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.4733520746231079,p 0.6393083825782447, r 0.6448123620309051, f 0.6420485767666777\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.485056608915329,p 0.6121775025799794, r 0.6547461368653421, f 0.6327466666666667\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.47694775462150574,p 0.6656633479972216, r 0.6346578366445916, f 0.6497909368290202\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.47310325503349304,p 0.6594483701846364, r 0.6386313465783664, f 0.648872939329371\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.4435550570487976,p 0.6565840345690244, r 0.6373068432671082, f 0.6468018371233337\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.47014936804771423,p 0.655593220338983, r 0.6403973509933775, f 0.6479061976549414\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.46569424867630005,p 0.6552113949807823, r 0.6397350993377483, f 0.6473807662236122\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.46753954887390137,p 0.6490953763681037, r 0.6415011037527594, f 0.6452758965249251\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.47253119945526123,p 0.6527403414195867, r 0.6415011037527594, f 0.6470719216210199\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.48393139243125916,p 0.6294470638662666, r 0.6483443708609271, f 0.6387559808612441\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.4849083423614502,p 0.659375712007291, r 0.6388520971302428, f 0.6489516761968831\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.48077264428138733,p 0.6353196099674973, r 0.6472406181015452, f 0.6412247129579005\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.4643300175666809,p 0.6631458094144661, r 0.6375275938189845, f 0.6500844119302195\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.4855600893497467,p 0.6093814010651373, r 0.6567328918322296, f 0.6321716957076075\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.43269291520118713,p 0.6389496717724289, r 0.6445916114790287, f 0.6417582417582418\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.4276668429374695,p 0.6803827751196172, r 0.6278145695364239, f 0.6530424799081516\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.4726405143737793,p 0.6379686137750654, r 0.6461368653421633, f 0.6420267602544417\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.507175624370575,p 0.6316580756013745, r 0.6492273730684327, f 0.640322229479643\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.4732400178909302,p 0.6473075211392968, r 0.6421633554083885, f 0.6447251773049646\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.44217449426651,p 0.6422621657167908, r 0.6467991169977925, f 0.6445226572811262\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.47701898217201233,p 0.6611834589901759, r 0.6388520971302428, f 0.6498259795666329\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.49687305092811584,p 0.6592980856882407, r 0.6386313465783664, f 0.6488001794124243\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.46671509742736816,p 0.6505484665323483, r 0.6415011037527594, f 0.6459931088140491\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.47412174940109253,p 0.6410706450197455, r 0.6450331125827815, f 0.6430457746478873\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.4552623927593231,p 0.6376496191512514, r 0.6467991169977925, f 0.6421917808219179\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.48723331093788147,p 0.653318335208099, r 0.6410596026490066, f 0.6471309192200557\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0 , val_loss : 0.49749234318733215,p 0.636087616569074, r 0.6474613686534216, f 0.6417241002078546\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0 , val_loss : 0.49260014295578003,p 0.6572919029258335, r 0.6397350993377483, f 0.6483946750195771\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0 , val_loss : 0.46142280101776123,p 0.6497326203208557, r 0.6437086092715232, f 0.6467065868263473\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0 , val_loss : 0.46550726890563965,p 0.626031746031746, r 0.6529801324503312, f 0.6392220421393842\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0 , val_loss : 0.5507338643074036,p 0.614495147635763, r 0.6569536423841059, f 0.6350154699669263\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0 , val_loss : 0.46362802386283875,p 0.6756183745583039, r 0.633112582781457, f 0.6536752136752136\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0 , val_loss : 0.46171268820762634,p 0.6396769969445657, r 0.6470198675496689, f 0.6433274802458298\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0 , val_loss : 0.49587613344192505,p 0.6829209704539995, r 0.6275938189845475, f 0.6540894972966755\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0 , val_loss : 0.48095473647117615,p 0.6252373918548217, r 0.6540838852097131, f 0.6393354191390658\n",
      "\n",
      "66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66 train_loss : 0 , val_loss : 0.4500238597393036,p 0.6955008699975143, r 0.6176600441501103, f 0.6542733543785806\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0 , val_loss : 0.539023756980896,p 0.5417690417690417, r 0.6814569536423841, f 0.6036370746969104\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0 , val_loss : 0.48652973771095276,p 0.6324382384532761, r 0.6498896247240619, f 0.6410451823625476\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0 , val_loss : 0.4354514479637146,p 0.6703806870937791, r 0.6375275938189845, f 0.653541525231953\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0 , val_loss : 0.48325490951538086,p 0.6450828729281768, r 0.6443708609271523, f 0.6447266703478741\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0 , val_loss : 0.47031453251838684,p 0.6157349896480331, r 0.6565121412803532, f 0.6354700854700854\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0 , val_loss : 0.48945483565330505,p 0.6323245331616226, r 0.6503311258278146, f 0.6412014365001633\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0 , val_loss : 0.4765717387199402,p 0.6285106382978723, r 0.6520971302428256, f 0.6400866738894908\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0 , val_loss : 0.45095741748809814,p 0.6222268731686899, r 0.6562913907284769, f 0.6388053287494628\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0 , val_loss : 0.4504320025444031,p 0.647450110864745, r 0.6445916114790287, f 0.6460176991150443\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0 , val_loss : 0.492926687002182,p 0.5862135922330097, r 0.6664459161147903, f 0.6237603305785124\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0 , val_loss : 0.46235013008117676,p 0.6288813270948532, r 0.6527593818984547, f 0.6405979202772963\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0 , val_loss : 0.5256691575050354,p 0.5766451122099657, r 0.6693156732891832, f 0.6195341234164282\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0 , val_loss : 0.515481173992157,p 0.5820493066255779, r 0.6671081677704195, f 0.621682781320716\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0 , val_loss : 0.4499462842941284,p 0.6764705882352942, r 0.6346578366445916, f 0.6548974943052392\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0 , val_loss : 0.48963651061058044,p 0.6620973269362577, r 0.6397350993377483, f 0.6507241495453013\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0 , val_loss : 0.4749443829059601,p 0.6410815525512429, r 0.6490066225165563, f 0.6450197455024133\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0 , val_loss : 0.4764445424079895,p 0.6192651027610546, r 0.6584988962472407, f 0.6382796619236119\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0 , val_loss : 0.488016277551651,p 0.6110429447852761, r 0.6596026490066225, f 0.6343949044585987\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0 , val_loss : 0.4794744849205017,p 0.625263601855757, r 0.6545253863134658, f 0.6395599654874892\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0 , val_loss : 0.4637359082698822,p 0.6425448185395715, r 0.64878587196468, f 0.6456502636203867\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0 , val_loss : 0.47965705394744873,p 0.628668651637601, r 0.6525386313465784, f 0.6403812824956673\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0 , val_loss : 0.5051791071891785,p 0.6561371841155235, r 0.6419426048565121, f 0.6489622852041954\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0 , val_loss : 0.43962201476097107,p 0.6645264847512039, r 0.6397350993377483, f 0.6518951748959623\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0 , val_loss : 0.4962973892688751,p 0.6389797253106606, r 0.6470198675496689, f 0.6429746627179993\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0 , val_loss : 0.4361288845539093,p 0.6596906278434941, r 0.6401766004415012, f 0.6497871386959445\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0 , val_loss : 0.5100947618484497,p 0.6097411860607296, r 0.6604856512141281, f 0.6340998198580058\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0 , val_loss : 0.46012577414512634,p 0.6318822023047375, r 0.6536423841059603, f 0.6425781249999999\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0 , val_loss : 0.447164922952652,p 0.6658227848101266, r 0.6386313465783664, f 0.651943661971831\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0 , val_loss : 0.48374050855636597,p 0.6486366659277322, r 0.645916114790287, f 0.6472735316889725\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0 , val_loss : 0.4548546075820923,p 0.6732742537313433, r 0.6373068432671082, f 0.6547970061238376\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0 , val_loss : 0.4607197046279907,p 0.6800475059382423, r 0.6320088300220751, f 0.6551487414187642\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0 , val_loss : 0.4312078654766083,p 0.6598593147265713, r 0.6419426048565121, f 0.650777665883406\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0 , val_loss : 0.49103984236717224,p 0.6146562371346233, r 0.6591611479028697, f 0.6361312313591819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(100):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "8 1 119 0 tensor(9) tensor(8)\n",
      "10 0 114 4 tensor(10) tensor(14)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "7 1 120 0 tensor(8) tensor(7)\n",
      "22 18 72 16 tensor(40) tensor(38)\n",
      "7 11 109 1 tensor(18) tensor(8)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "21 7 88 12 tensor(28) tensor(33)\n",
      "4 11 108 5 tensor(15) tensor(9)\n",
      "30 10 66 22 tensor(40) tensor(52)\n",
      "36 17 71 4 tensor(53) tensor(40)\n",
      "29 6 81 12 tensor(35) tensor(41)\n",
      "39 2 51 36 tensor(41) tensor(75)\n",
      "1 0 124 3 tensor(1) tensor(4)\n",
      "10 0 106 12 tensor(10) tensor(22)\n",
      "10 2 108 8 tensor(12) tensor(18)\n",
      "21 4 81 22 tensor(25) tensor(43)\n",
      "8 11 106 3 tensor(19) tensor(11)\n",
      "25 18 78 7 tensor(43) tensor(32)\n",
      "14 8 99 7 tensor(22) tensor(21)\n",
      "10 21 86 11 tensor(31) tensor(21)\n",
      "0 13 115 0 tensor(13) tensor(0)\n",
      "16 10 97 5 tensor(26) tensor(21)\n",
      "27 6 80 15 tensor(33) tensor(42)\n",
      "22 13 78 15 tensor(35) tensor(37)\n",
      "30 18 74 6 tensor(48) tensor(36)\n",
      "27 0 99 2 tensor(27) tensor(29)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "9 0 106 13 tensor(9) tensor(22)\n",
      "14 2 104 8 tensor(16) tensor(22)\n",
      "1 0 124 3 tensor(1) tensor(4)\n",
      "20 0 100 8 tensor(20) tensor(28)\n",
      "6 1 115 6 tensor(7) tensor(12)\n",
      "1 0 119 8 tensor(1) tensor(9)\n",
      "25 16 85 2 tensor(41) tensor(27)\n",
      "31 0 89 8 tensor(31) tensor(39)\n",
      "12 6 102 8 tensor(18) tensor(20)\n",
      "0 15 113 0 tensor(15) tensor(0)\n",
      "46 1 60 21 tensor(47) tensor(67)\n",
      "13 21 89 5 tensor(34) tensor(18)\n",
      "33 8 67 20 tensor(41) tensor(53)\n",
      "16 0 109 3 tensor(16) tensor(19)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "17 0 90 21 tensor(17) tensor(38)\n",
      "10 1 113 4 tensor(11) tensor(14)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 121 7 tensor(0) tensor(7)\n",
      "12 21 82 13 tensor(33) tensor(25)\n",
      "7 19 95 7 tensor(26) tensor(14)\n",
      "5 4 119 0 tensor(9) tensor(5)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "12 5 97 14 tensor(17) tensor(26)\n",
      "32 5 85 6 tensor(37) tensor(38)\n",
      "0 28 100 0 tensor(28) tensor(0)\n",
      "6 6 116 0 tensor(12) tensor(6)\n",
      "36 0 73 19 tensor(36) tensor(55)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "13 2 91 22 tensor(15) tensor(35)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "30 0 85 13 tensor(30) tensor(43)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 6 122 0 tensor(6) tensor(0)\n",
      "6 17 101 4 tensor(23) tensor(10)\n",
      "20 0 91 17 tensor(20) tensor(37)\n",
      "20 7 98 3 tensor(27) tensor(23)\n",
      "0 1 127 0 tensor(1) tensor(0)\n",
      "0 9 119 0 tensor(9) tensor(0)\n",
      "18 7 80 23 tensor(25) tensor(41)\n",
      "36 22 58 12 tensor(58) tensor(48)\n",
      "50 14 38 26 tensor(64) tensor(76)\n",
      "0 0 121 7 tensor(0) tensor(7)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "8 5 115 0 tensor(13) tensor(8)\n",
      "20 3 96 9 tensor(23) tensor(29)\n",
      "21 5 87 15 tensor(26) tensor(36)\n",
      "7 14 106 1 tensor(21) tensor(8)\n",
      "0 34 94 0 tensor(34) tensor(0)\n",
      "37 32 30 29 tensor(69) tensor(66)\n",
      "8 14 105 1 tensor(22) tensor(9)\n",
      "23 11 83 11 tensor(34) tensor(34)\n",
      "6 15 105 2 tensor(21) tensor(8)\n",
      "9 20 88 11 tensor(29) tensor(20)\n",
      "13 19 81 15 tensor(32) tensor(28)\n",
      "42 0 85 1 tensor(42) tensor(43)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "15 9 85 19 tensor(24) tensor(34)\n",
      "20 0 99 9 tensor(20) tensor(29)\n",
      "6 5 116 1 tensor(11) tensor(7)\n",
      "0 17 111 0 tensor(17) tensor(0)\n",
      "6 12 110 0 tensor(18) tensor(6)\n",
      "15 18 81 14 tensor(33) tensor(29)\n",
      "22 27 54 25 tensor(49) tensor(47)\n",
      "7 18 97 6 tensor(25) tensor(13)\n",
      "30 10 63 25 tensor(40) tensor(55)\n",
      "27 6 66 29 tensor(33) tensor(56)\n",
      "31 0 93 4 tensor(31) tensor(35)\n",
      "7 0 110 11 tensor(7) tensor(18)\n",
      "3 0 124 1 tensor(3) tensor(4)\n",
      "19 0 105 4 tensor(19) tensor(23)\n",
      "8 1 119 0 tensor(9) tensor(8)\n",
      "19 0 105 4 tensor(19) tensor(23)\n",
      "0 13 115 0 tensor(13) tensor(0)\n",
      "25 2 98 3 tensor(27) tensor(28)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 10 118 0 tensor(10) tensor(0)\n",
      "5 15 108 0 tensor(20) tensor(5)\n",
      "18 0 97 13 tensor(18) tensor(31)\n",
      "17 4 100 7 tensor(21) tensor(24)\n",
      "45 5 73 5 tensor(50) tensor(50)\n",
      "31 9 79 9 tensor(40) tensor(40)\n",
      "6 0 119 3 tensor(6) tensor(9)\n",
      "0 1 125 2 tensor(1) tensor(2)\n",
      "11 1 112 4 tensor(12) tensor(15)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "40 2 75 11 tensor(42) tensor(51)\n",
      "0 10 118 0 tensor(10) tensor(0)\n",
      "7 36 84 1 tensor(43) tensor(8)\n",
      "12 9 104 3 tensor(21) tensor(15)\n",
      "0 10 118 0 tensor(10) tensor(0)\n",
      "24 3 85 16 tensor(27) tensor(40)\n",
      "21 3 94 10 tensor(24) tensor(31)\n",
      "17 9 85 17 tensor(26) tensor(34)\n",
      "45 6 62 15 tensor(51) tensor(60)\n",
      "50 37 40 1 tensor(87) tensor(51)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "22 0 96 10 tensor(22) tensor(32)\n",
      "9 4 89 26 tensor(13) tensor(35)\n",
      "0 0 122 6 tensor(0) tensor(6)\n",
      "9 7 96 16 tensor(16) tensor(25)\n",
      "32 3 79 14 tensor(35) tensor(46)\n",
      "0 20 108 0 tensor(20) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "30 3 85 10 tensor(33) tensor(40)\n",
      "0 43 85 0 tensor(43) tensor(0)\n",
      "14 4 97 13 tensor(18) tensor(27)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "16 7 83 22 tensor(23) tensor(38)\n",
      "11 5 88 24 tensor(16) tensor(35)\n",
      "41 0 73 14 tensor(41) tensor(55)\n",
      "27 0 74 27 tensor(27) tensor(54)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "20 0 96 12 tensor(20) tensor(32)\n",
      "24 6 81 17 tensor(30) tensor(41)\n",
      "34 3 74 17 tensor(37) tensor(51)\n",
      "22 9 88 9 tensor(31) tensor(31)\n",
      "14 20 88 6 tensor(34) tensor(20)\n",
      "26 0 79 23 tensor(26) tensor(49)\n",
      "0 10 118 0 tensor(10) tensor(0)\n",
      "2 3 123 0 tensor(5) tensor(2)\n",
      "14 1 109 4 tensor(15) tensor(18)\n",
      "26 22 71 9 tensor(48) tensor(35)\n",
      "3 0 123 2 tensor(3) tensor(5)\n",
      "16 0 91 21 tensor(16) tensor(37)\n",
      "9 0 112 7 tensor(9) tensor(16)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "17 0 77 34 tensor(17) tensor(51)\n",
      "38 0 76 14 tensor(38) tensor(52)\n",
      "31 5 64 28 tensor(36) tensor(59)\n",
      "12 3 98 15 tensor(15) tensor(27)\n",
      "0 0 124 4 tensor(0) tensor(4)\n",
      "7 9 106 6 tensor(16) tensor(13)\n",
      "27 4 63 34 tensor(31) tensor(61)\n",
      "7 14 93 14 tensor(21) tensor(21)\n",
      "5 12 106 5 tensor(17) tensor(10)\n",
      "20 0 95 13 tensor(20) tensor(33)\n",
      "21 2 98 7 tensor(23) tensor(28)\n",
      "16 11 84 17 tensor(27) tensor(33)\n",
      "0 9 115 4 tensor(9) tensor(4)\n",
      "40 8 68 12 tensor(48) tensor(52)\n",
      "9 18 99 2 tensor(27) tensor(11)\n",
      "41 4 62 21 tensor(45) tensor(62)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "7 1 119 1 tensor(8) tensor(8)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "8 1 117 2 tensor(9) tensor(10)\n",
      "6 2 119 1 tensor(8) tensor(7)\n",
      "9 0 114 5 tensor(9) tensor(14)\n",
      "9 8 103 8 tensor(17) tensor(17)\n",
      "16 4 96 12 tensor(20) tensor(28)\n",
      "0 22 106 0 tensor(22) tensor(0)\n",
      "16 11 93 8 tensor(27) tensor(24)\n",
      "19 0 93 16 tensor(19) tensor(35)\n",
      "9 27 85 7 tensor(36) tensor(16)\n",
      "49 9 46 24 tensor(58) tensor(73)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "27 0 87 14 tensor(27) tensor(41)\n",
      "0 0 128 0 tensor(0) tensor(0)\n",
      "16 2 95 15 tensor(18) tensor(31)\n",
      "10 0 114 4 tensor(10) tensor(14)\n",
      "8 0 111 9 tensor(8) tensor(17)\n",
      "20 7 100 1 tensor(27) tensor(21)\n",
      "25 12 77 14 tensor(37) tensor(39)\n",
      "25 11 73 19 tensor(36) tensor(44)\n",
      "14 3 94 17 tensor(17) tensor(31)\n",
      "20 16 82 10 tensor(36) tensor(30)\n",
      "26 10 82 10 tensor(36) tensor(36)\n",
      "18 0 0 5 tensor(18) tensor(23)\n",
      "2863 1347 1667\n",
      "[206/1101], prec:0.6800475059382423, recall:0.6320088300220751, f1:65.51487414187642, acc: 0.8857943996059262\n"
     ]
    }
   ],
   "source": [
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        output=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,game in enumerate(g):\n",
    "            if game not in result.keys():\n",
    "                result[game]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[game]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844294671796427\n",
      "precision : 0.7181208053691275, recall : 0.6504559270516718, f1 : 0.6826156299840511, accuracy : 0.9030214424951267\n",
      "102844224145685626\n",
      "precision : 0.6395348837209303, recall : 0.6606606606606606, f1 : 0.6499261447562777, accuracy : 0.8596802841918295\n",
      "102844412717407552\n",
      "precision : 0.7643097643097643, recall : 0.6676470588235294, f1 : 0.7127158555729985, accuracy : 0.9041884816753927\n",
      "102844235751390657\n",
      "precision : 0.6061946902654868, recall : 0.6008771929824561, f1 : 0.60352422907489, accuracy : 0.9089068825910931\n",
      "102844401156069033\n",
      "precision : 0.6942446043165468, recall : 0.603125, f1 : 0.6454849498327759, accuracy : 0.8855291576673866\n",
      "102904869420860038\n",
      "precision : 0.5300546448087432, recall : 0.671280276816609, f1 : 0.5923664122137404, accuracy : 0.8429411764705882\n",
      "102910307641576395\n",
      "precision : 0.5946843853820598, recall : 0.5755627009646302, f1 : 0.5849673202614379, accuracy : 0.8479041916167664\n",
      "102844341905404560\n",
      "precision : 0.7748091603053435, recall : 0.7718631178707225, f1 : 0.7733333333333334, accuracy : 0.9367021276595745\n",
      "102844341906977427\n",
      "precision : 0.6412429378531074, recall : 0.739413680781759, f1 : 0.686838124054463, accuracy : 0.8834459459459459\n",
      "102844212430075086\n",
      "precision : 0.6872964169381107, recall : 0.5368956743002544, f1 : 0.6028571428571428, accuracy : 0.8780166739798158\n",
      "102844412711116088\n",
      "precision : 0.7142857142857143, recall : 0.6514084507042254, f1 : 0.6813996316758748, accuracy : 0.8982951205173427\n",
      "102844401153578660\n",
      "precision : 0.7614457831325301, recall : 0.5505226480836237, f1 : 0.6390293225480284, accuracy : 0.8582770940849543\n",
      "102844294667405508\n",
      "precision : 0.6351931330472103, recall : 0.6379310344827587, f1 : 0.6365591397849462, accuracy : 0.9072956664838179\n",
      "102844412706659630\n",
      "precision : 0.774074074074074, recall : 0.6391437308868502, f1 : 0.7001675041876048, accuracy : 0.8855498721227621\n",
      "==precision : 0.681106499843482, recall : 0.639770511029268, f1 : 0.6565560528669688, accuracy : 0.8856967226787427\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('./label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
