{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config-audio.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20747/1028236825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chat_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mchat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=pickle.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=pickle.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=pickle.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio['102844412722519367'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        self.gt_range =  1-conf['trn_args']['hl_range']\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=pickle.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=pickle.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=pickle.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']     \n",
    "        if d_type =='total':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654'] + ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630'] + ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    " \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        begin_pos = 0 \n",
    "        hl_frames = []\n",
    "        for it, cur_pos in enumerate(pos_idx):\n",
    "            if it+1 < len(pos_idx): \n",
    "                if((pos_idx[it+1] - cur_pos) > 1):#cur_pos와 cur_pos+1 간격이 1보다 크면, 즉 다른 구간이면\n",
    "                    begin = int((it+1 - begin_pos) * self.gt_range) + begin_pos\n",
    "                    hl_frames.extend( pos_idx[begin: it] ) #한구간의 하이라이트 25%만 사용하겠다.\n",
    "                    begin_pos = it+1\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[hl_frames] = len(sampling) / float(len(hl_frames))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = audio_size\n",
    "            \n",
    "            #audio_only\n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "#                     s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "#                     s_window+=[self.video[game_id][vframe+idx]]\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "\n",
      "\n",
      "datset testing....\n",
      "('102844412722519367', array([[  2.2001882 ,  -9.80676619, -11.11639875, -10.09886806,\n",
      "         -8.47125593,  -8.55332796,  -6.12871893,  -3.17043442,\n",
      "         -1.71466267,  -5.19732286,  -3.77024903,  -2.99407219,\n",
      "         -3.54347805],\n",
      "       [  9.03103736, -16.15133849,  -8.33885897, -11.90960517,\n",
      "         -9.17977961,  -8.71532322,  -8.978371  ,  -4.22298997,\n",
      "         -2.58187328,  -1.39110923,  -3.36411837,  -2.54867552,\n",
      "         -3.03780565],\n",
      "       [-12.84284726, -10.12680368,  -3.45536908,  -8.45073936,\n",
      "         -5.32551442,  -4.50438865,  -3.29253053,  -0.82895848,\n",
      "         -4.93028257,   0.9279834 ,  -2.41448028,  -0.24941073,\n",
      "         -0.11264702],\n",
      "       [ 13.66766934, -10.43965238,  -8.73442498, -16.63221332,\n",
      "        -14.76351086, -11.13111863,  -6.67272178,  -4.48623026,\n",
      "         -1.55866536,  -5.3237014 ,  -3.29337875,  -1.98631856,\n",
      "         -3.2770396 ],\n",
      "       [  7.63164985, -12.54389611,  -5.59081995, -12.4211494 ,\n",
      "         -7.50846677,  -8.86606956,  -7.8751188 ,  -2.90691942,\n",
      "         -1.74786657,  -1.16879009,  -5.10016714,  -2.20282131,\n",
      "         -4.65549276],\n",
      "       [ 14.78246389, -11.54799445, -13.7914316 , -12.40608236,\n",
      "        -13.48969691,  -7.2748362 ,  -8.01191943,  -5.17265838,\n",
      "         -0.41768063,  -0.59223176,  -6.73758439,  -1.75827812,\n",
      "         -3.36015739],\n",
      "       [ 13.08406287,  -9.95989088,  -5.52074889,  -8.50255077,\n",
      "        -11.83915471, -12.35513808,  -7.04510514,  -1.56510567,\n",
      "         -0.38541831,  -1.41325522,  -2.90041248,  -6.83178039,\n",
      "         -6.76145244]]), 0)\n",
      "7\n",
      "\n",
      "****************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "\n",
    "#test\n",
    "print(\"\\n\\ndatset testing....\")\n",
    "print(train[100])\n",
    "print(len(train[100][1]))\n",
    "print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "#loader \n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0.5625737309455872 , val_loss : 0.4764273762702942,p 0.4560669456066946, r 0.6496688741721854, f 0.5359191477738323\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0.4570872187614441 , val_loss : 0.45709654688835144,p 0.4713258652399264, r 0.6222958057395144, f 0.5363904481019883\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0.4467945694923401 , val_loss : 0.5033316612243652,p 0.4163854771224187, r 0.6810154525386314, f 0.516793701315018\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0.43000999093055725 , val_loss : 0.4928644597530365,p 0.4280502043199066, r 0.6474613686534216, f 0.5153751537515375\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0.42448529601097107 , val_loss : 0.45010340213775635,p 0.4697364139277579, r 0.6373068432671082, f 0.5408392656425628\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0.41748499870300293 , val_loss : 0.47559553384780884,p 0.4234503360716953, r 0.6258278145695364, f 0.5051224944320714\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0.4067234396934509 , val_loss : 0.4801293611526489,p 0.432729905865315, r 0.6596026490066225, f 0.5226060341058155\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0.3938843905925751 , val_loss : 0.48757678270339966,p 0.41178024300052823, r 0.6883002207505519, f 0.5152867294662039\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0.38876277208328247 , val_loss : 0.5103557705879211,p 0.4086519891850135, r 0.7006622516556291, f 0.5162234691388143\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0.37886783480644226 , val_loss : 0.42891979217529297,p 0.4900812393727565, r 0.5726269315673289, f 0.5281482235569582\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0.36450740694999695 , val_loss : 0.46323710680007935,p 0.4576353092783505, r 0.6271523178807947, f 0.5291488172844105\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0.35643941164016724 , val_loss : 0.39595475792884827,p 0.539291217257319, r 0.5408388520971302, f 0.5400639259340901\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0.3483041524887085 , val_loss : 0.5340614914894104,p 0.3793557657765537, r 0.6993377483443709, f 0.4918872758326217\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0.3435573875904083 , val_loss : 0.4455276131629944,p 0.5439774696707106, r 0.5543046357615894, f 0.549092499453313\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0.3390620946884155 , val_loss : 0.5508848428726196,p 0.36342935215757716, r 0.704635761589404, f 0.4795312852099451\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0.32753944396972656 , val_loss : 0.45949921011924744,p 0.4836110602453763, r 0.5830022075055188, f 0.5286758082274048\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0.31724992394447327 , val_loss : 0.45519891381263733,p 0.47786932362521556, r 0.5505518763796909, f 0.5116422197148426\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0.3093871772289276 , val_loss : 0.43963423371315,p 0.5042071197411003, r 0.5158940397350993, f 0.5099836333878887\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0.3102031946182251 , val_loss : 0.49872490763664246,p 0.48652141802067944, r 0.5816777041942605, f 0.529861250754072\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0.2992527186870575 , val_loss : 0.5102022290229797,p 0.4207159177456207, r 0.6097130242825607, f 0.49788192879675536\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0.28939950466156006 , val_loss : 0.48709532618522644,p 0.46680716543730244, r 0.5867549668874172, f 0.5199530516431925\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0.27781009674072266 , val_loss : 0.4839915335178375,p 0.49524895477004943, r 0.5752759381898455, f 0.5322712418300654\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0.27509045600891113 , val_loss : 0.5076310634613037,p 0.5271836007130125, r 0.5222958057395144, f 0.5247283211355067\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0.27020126581192017 , val_loss : 0.5308391451835632,p 0.4382123575284943, r 0.6450331125827815, f 0.5218789069476691\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0.2619914710521698 , val_loss : 0.5469408631324768,p 0.39683603700227915, r 0.6534216335540839, f 0.49378597047293354\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0.2582012414932251 , val_loss : 0.4954877495765686,p 0.47238805970149256, r 0.5589403973509933, f 0.5120323559150657\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0.2526226341724396 , val_loss : 0.5064676403999329,p 0.46948628814213983, r 0.536644591611479, f 0.5008240626287599\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0.25376951694488525 , val_loss : 0.48644477128982544,p 0.47383609080415545, r 0.5437086092715232, f 0.5063733552631579\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0.23510581254959106 , val_loss : 0.5487703680992126,p 0.49273504273504276, r 0.5090507726269315, f 0.5007600434310532\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0.23652684688568115 , val_loss : 0.5400421023368835,p 0.45916158236567606, r 0.5150110375275938, f 0.48548538133388824\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0.23220333456993103 , val_loss : 0.5531651377677917,p 0.5235378031383737, r 0.4860927152317881, f 0.5041208791208791\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0.22793889045715332 , val_loss : 0.5575729012489319,p 0.4296565389696169, r 0.57439293598234, f 0.49159266956357456\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0.21365438401699066 , val_loss : 0.5727444887161255,p 0.5377049180327869, r 0.5068432671081677, f 0.5218181818181818\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0.21634343266487122 , val_loss : 0.5785017013549805,p 0.44686648501362397, r 0.5792494481236203, f 0.5045183618534897\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0.21907463669776917 , val_loss : 0.5604295134544373,p 0.4539219134716848, r 0.5697571743929359, f 0.5052858261550509\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0.20427727699279785 , val_loss : 0.5693920254707336,p 0.45718872636460933, r 0.5657836644591612, f 0.5057221783741122\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0.20170773565769196 , val_loss : 0.5944891571998596,p 0.4310077519379845, r 0.6136865342163356, f 0.5063752276867031\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0.19368818402290344 , val_loss : 0.5985206365585327,p 0.4681498383723141, r 0.5434878587196468, f 0.5030135866789254\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0.19248293340206146 , val_loss : 0.5997924208641052,p 0.4847312703583062, r 0.52560706401766, f 0.5043423003600932\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0.18461500108242035 , val_loss : 0.6312339901924133,p 0.48013054329045884, r 0.5520971302428256, f 0.5136050929253517\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0.18381349742412567 , val_loss : 0.6543304324150085,p 0.42981260647359454, r 0.5569536423841059, f 0.4851923076923077\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0.17303484678268433 , val_loss : 0.6766659021377563,p 0.5110957004160888, r 0.4880794701986755, f 0.4993224932249322\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0.18324284255504608 , val_loss : 0.6330745816230774,p 0.4614834673815907, r 0.5699779249448124, f 0.5100246913580246\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0.16617971658706665 , val_loss : 0.6748933792114258,p 0.4564586357039187, r 0.5554083885209713, f 0.501095399322844\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0.17169734835624695 , val_loss : 0.6394733786582947,p 0.4749536178107607, r 0.5086092715231788, f 0.49120562839782544\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0.16962236166000366 , val_loss : 0.6801904439926147,p 0.40719613865730586, r 0.614569536423841, f 0.4898390076537346\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0.16290844976902008 , val_loss : 0.7029798030853271,p 0.5133183968135424, r 0.45518763796909495, f 0.48250848250848255\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0.15457625687122345 , val_loss : 0.7034797072410583,p 0.496844762305427, r 0.5214128035320088, f 0.5088323998276606\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0.1592170000076294 , val_loss : 0.6994001865386963,p 0.4871365823049571, r 0.5141280353200883, f 0.5002684996241005\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0.15153193473815918 , val_loss : 0.6900044083595276,p 0.5049988891357476, r 0.5017660044150111, f 0.5033772561178165\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0.14957676827907562 , val_loss : 0.7543769478797913,p 0.5683690280065898, r 0.45695364238410596, f 0.5066079295154186\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0.14536818861961365 , val_loss : 0.7881825566291809,p 0.565470417070805, r 0.38609271523178806, f 0.4588744588744589\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0.1464579850435257 , val_loss : 0.7097077369689941,p 0.5174003226549896, r 0.4955849889624724, f 0.5062577517194722\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0.13806064426898956 , val_loss : 0.7964120507240295,p 0.42179319371727747, r 0.5690949227373069, f 0.4844953956023304\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0.14175307750701904 , val_loss : 0.7514244318008423,p 0.4421515561569689, r 0.5770419426048565, f 0.5006703696609845\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0.13615038990974426 , val_loss : 0.8118629455566406,p 0.5491915593313237, r 0.4423841059602649, f 0.4900354566572931\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0.1393873393535614 , val_loss : 0.7753322720527649,p 0.5497410738620878, r 0.4452538631346578, f 0.4920112208805952\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0.1335352063179016 , val_loss : 0.8041188716888428,p 0.5406674907292954, r 0.4827814569536424, f 0.5100874635568513\n",
      "\n",
      "58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58 train_loss : 0.1293604075908661 , val_loss : 0.765525758266449,p 0.5182604517059106, r 0.476158940397351, f 0.49631845375057526\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0.12106488645076752 , val_loss : 0.8508105278015137,p 0.46242367308595583, r 0.4346578366445916, f 0.44811106053709604\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0.12268334627151489 , val_loss : 0.7801370024681091,p 0.5109732824427481, r 0.4728476821192053, f 0.4911717495987159\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0.12284824252128601 , val_loss : 0.8190937638282776,p 0.5363682604272635, r 0.46556291390728477, f 0.49846372016071855\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0.11357399076223373 , val_loss : 0.9428120255470276,p 0.5605975197294251, r 0.4390728476821192, f 0.4924486258974994\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0.12468322366476059 , val_loss : 0.7556920647621155,p 0.48025732031943213, r 0.47792494481236203, f 0.4790882938703253\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0.11240273714065552 , val_loss : 0.8654309511184692,p 0.5318670332416896, r 0.46975717439293596, f 0.49888641425389757\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0.11657239496707916 , val_loss : 0.8720155954360962,p 0.5563739376770538, r 0.4335540838852097, f 0.4873449131513648\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0.1105639711022377 , val_loss : 0.8495718240737915,p 0.4799575821845175, r 0.49955849889624726, f 0.48956192536506216\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0.10694386810064316 , val_loss : 0.9036867022514343,p 0.5578129668359725, r 0.41214128035320086, f 0.4740383394693411\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0.10629436373710632 , val_loss : 0.9121019244194031,p 0.514873574615766, r 0.4584988962472406, f 0.48505371321812235\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0.1042947992682457 , val_loss : 0.8571074604988098,p 0.5010457820125493, r 0.4759381898454746, f 0.4881693648816936\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0.10341646522283554 , val_loss : 0.9746009111404419,p 0.5501580914055764, r 0.42251655629139073, f 0.4779622924210264\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0.10647909343242645 , val_loss : 0.8525326251983643,p 0.5052976791120081, r 0.4421633554083885, f 0.47162703084530255\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0.09958089888095856 , val_loss : 0.9725591540336609,p 0.5646950092421442, r 0.40463576158940395, f 0.4714506172839506\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0.09707866609096527 , val_loss : 0.9066388010978699,p 0.5001245950660353, r 0.44304635761589406, f 0.4698583635725155\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0.0979691594839096 , val_loss : 0.9091975688934326,p 0.5130164795796514, r 0.4741721854304636, f 0.49283010209934613\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0.09498481452465057 , val_loss : 0.99996018409729,p 0.581150159744409, r 0.40154525386313467, f 0.47493472584856394\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0.10202006995677948 , val_loss : 0.8716461062431335,p 0.47787998247919405, r 0.4816777041942605, f 0.47977132805628847\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0.09639142453670502 , val_loss : 1.014062762260437,p 0.5668144395186827, r 0.39514348785871967, f 0.46566077003121753\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0.09286703914403915 , val_loss : 0.933957576751709,p 0.5205330432417732, r 0.42251655629139073, f 0.46643109540636046\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0.09005609154701233 , val_loss : 0.9089437127113342,p 0.47489082969432317, r 0.48013245033112584, f 0.4774972557628979\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0.08887773007154465 , val_loss : 0.9376097917556763,p 0.5313098167897183, r 0.42891832229580573, f 0.474654940759741\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0.08752167224884033 , val_loss : 0.9710133075714111,p 0.506155303030303, r 0.47196467991169977, f 0.48846241718071737\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0.09287739545106888 , val_loss : 0.9733728766441345,p 0.5640495867768595, r 0.42185430463576157, f 0.48269765092194994\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0.08941327035427094 , val_loss : 0.9883914589881897,p 0.5637562814070352, r 0.39624724061810157, f 0.4653876069484055\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0.08915441483259201 , val_loss : 1.0084513425827026,p 0.6054343666283964, r 0.34922737306843266, f 0.44295114097718047\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0.08189648389816284 , val_loss : 1.0990043878555298,p 0.6195652173913043, r 0.352317880794702, f 0.44919786096256686\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0.07335808873176575 , val_loss : 0.9628181457519531,p 0.5011191245958717, r 0.4448123620309051, f 0.4712899076131447\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0.08185968548059464 , val_loss : 0.9420222640037537,p 0.49868954014772454, r 0.4620309050772627, f 0.47966082273404376\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0.07811325788497925 , val_loss : 0.9808807969093323,p 0.527672273467173, r 0.42935982339955847, f 0.47346640701071074\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0.07939138263463974 , val_loss : 0.9767632484436035,p 0.5700440528634361, r 0.428476821192053, f 0.4892249527410208\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0.07599007338285446 , val_loss : 1.0560115575790405,p 0.516100957354221, r 0.3927152317880795, f 0.44603234298608496\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0.07433631271123886 , val_loss : 1.011579990386963,p 0.5593620791494389, r 0.4181015452538631, f 0.4785245073269328\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0.07303270697593689 , val_loss : 0.9818984270095825,p 0.49613811903680144, r 0.4821192052980132, f 0.48902821316614414\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0.07538943737745285 , val_loss : 1.0292445421218872,p 0.5422259507829977, r 0.4280353200883002, f 0.4784110535405872\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0.07953228801488876 , val_loss : 1.0041862726211548,p 0.5517134918184625, r 0.3944812362030905, f 0.4600334663405844\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0.06830819696187973 , val_loss : 1.043086051940918,p 0.5736607142857143, r 0.39713024282560705, f 0.46934516044873464\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0.07041574269533157 , val_loss : 1.0129255056381226,p 0.5026288117770767, r 0.422075055187638, f 0.45884329253659706\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0.07448926568031311 , val_loss : 1.0059387683868408,p 0.5555893999390801, r 0.40264900662251657, f 0.46691411749648026\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0.07064643502235413 , val_loss : 1.084641695022583,p 0.5854086285513854, r 0.3684326710816777, f 0.45224224359842835\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0.06752151250839233 , val_loss : 1.0875613689422607,p 0.5638126009693053, r 0.3852097130242826, f 0.45770491803278696\n",
      "\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.6993464052287581, recall : 0.28083989501312334, f1 : 0.40074906367041196, accuracy : 0.8701298701298701\n",
      "102844341902586509\n",
      "precision : 0.5011820330969267, recall : 0.8379446640316206, f1 : 0.6272189349112426, accuracy : 0.882132834424696\n",
      "102844401152267937\n",
      "precision : 0.18552875695732837, recall : 0.24875621890547264, f1 : 0.21253985122210411, accuracy : 0.6762778505897772\n",
      "102844212430927059\n",
      "precision : 0.5675182481751825, recall : 0.4712121212121212, f1 : 0.5149006622516556, accuracy : 0.8459111227977912\n",
      "102844412708953395\n",
      "precision : 0.524904214559387, recall : 0.4963768115942029, f1 : 0.5102420856610801, accuracy : 0.8720817120622568\n",
      "102844212429944013\n",
      "precision : 0.7224669603524229, recall : 0.4420485175202156, f1 : 0.5484949832775919, accuracy : 0.8680351906158358\n",
      "102844341912679064\n",
      "precision : 0.32514177693761814, recall : 0.7610619469026548, f1 : 0.4556291390728477, accuracy : 0.7881443298969072\n",
      "102844235753749959\n",
      "precision : 0.23705722070844687, recall : 0.22137404580152673, f1 : 0.22894736842105265, accuracy : 0.7355595667870036\n",
      "102844341908026005\n",
      "precision : 0.6265432098765432, recall : 0.6160849772382397, f1 : 0.6212700841622034, accuracy : 0.8303051079876586\n",
      "102844283023206486\n",
      "precision : 0.7150837988826816, recall : 0.7170868347338936, f1 : 0.716083916083916, accuracy : 0.8891921397379913\n",
      "102844224147717245\n",
      "precision : 0.7104247104247104, recall : 0.5935483870967742, f1 : 0.6467486818980668, accuracy : 0.8904034896401308\n",
      "102844412704890154\n",
      "precision : 0.7510204081632653, recall : 0.5993485342019544, f1 : 0.6666666666666667, accuracy : 0.9113253012048192\n",
      "102844212430599377\n",
      "precision : 0.5478260869565217, recall : 0.5338983050847458, f1 : 0.5407725321888412, accuracy : 0.9083511777301927\n",
      "102844412711443769\n",
      "precision : 0.6091549295774648, recall : 0.7654867256637168, f1 : 0.6784313725490195, accuracy : 0.8066037735849056\n",
      "102844235747982779\n",
      "precision : 0.6858054226475279, recall : 0.593103448275862, f1 : 0.6360946745562129, accuracy : 0.8196480938416423\n",
      "==precision : 0.560600278836319, recall : 0.545211428885075, f1 : 0.5336526677728609, accuracy : 0.8396067707354319\n",
      "data load fin\n",
      "102844412722519367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212429550795\n",
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n",
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n",
      "102844294671796427\n",
      "102844224145685626\n",
      "102844412717407552\n",
      "102844235751390657\n",
      "102844401156069033\n",
      "102904869420860038\n",
      "102910307641576395\n",
      "102844341905404560\n",
      "102844341906977427\n",
      "102844212430075086\n",
      "102844412711116088\n",
      "102844401153578660\n",
      "102844294667405508\n",
      "102844412706659630\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n",
      "0\n",
      "epoch 0 train_loss : 0.5415064692497253 , val_loss : 0.4968582093715668,p 0.4404099560761347, r 0.6640176600441501, f 0.5295774647887324\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0.4539589285850525 , val_loss : 0.48737096786499023,p 0.42796848621271805, r 0.671523178807947, f 0.5227702354356418\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0.439199298620224 , val_loss : 0.5014393925666809,p 0.41975982532751094, r 0.6790286975717439, f 0.51880586945522\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0.4313333034515381 , val_loss : 0.3681146502494812,p 0.5929786066922655, r 0.47726269315673286, f 0.5288649706457926\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0.4221409559249878 , val_loss : 0.5226790308952332,p 0.39723096286972936, r 0.6966887417218544, f 0.5059719438877754\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0.4093398451805115 , val_loss : 0.47791004180908203,p 0.42652280797596287, r 0.6894039735099338, f 0.5269996625042187\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0.4033966064453125 , val_loss : 0.42902863025665283,p 0.47987616099071206, r 0.6158940397350994, f 0.5394431554524363\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0.39101290702819824 , val_loss : 0.47197598218917847,p 0.4202098288238542, r 0.6719646799116997, f 0.5170715135043316\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0.3804149925708771 , val_loss : 0.3970285654067993,p 0.5261633919338159, r 0.56158940397351, f 0.5432995194874534\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0.37116479873657227 , val_loss : 0.42145904898643494,p 0.4805628847845207, r 0.6030905077262693, f 0.5348996573666177\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0.3575741946697235 , val_loss : 0.43732231855392456,p 0.4565473188771222, r 0.5995584988962472, f 0.5183700734802938\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0.3572552800178528 , val_loss : 0.4646080434322357,p 0.4277638190954774, r 0.6013245033112583, f 0.4999082400440448\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0.34158504009246826 , val_loss : 0.4178982675075531,p 0.536488740617181, r 0.567991169977925, f 0.5517906926871113\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0.33420324325561523 , val_loss : 0.4286095201969147,p 0.48217671596511186, r 0.5613686534216336, f 0.5187678498572013\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0.3225843608379364 , val_loss : 0.45252957940101624,p 0.4834263782274948, r 0.6116997792494481, f 0.540050672383551\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0.308314710855484 , val_loss : 0.5138095617294312,p 0.39092315626611657, r 0.6693156732891832, f 0.4935699169786749\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0.2927842140197754 , val_loss : 0.4901154637336731,p 0.4113052123277943, r 0.6392935982339956, f 0.5005617492005876\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0.28595733642578125 , val_loss : 0.4665829837322235,p 0.5293330359134508, r 0.523841059602649, f 0.5265727282813715\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0.2806433141231537 , val_loss : 0.5100162625312805,p 0.4300965194501316, r 0.6492273730684327, f 0.5174173117522871\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0.2762708365917206 , val_loss : 0.4715518653392792,p 0.5155187074829932, r 0.5353200883002207, f 0.5252328351743556\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0.27004262804985046 , val_loss : 0.5200024843215942,p 0.48976172747580043, r 0.580794701986755, f 0.5314077964047668\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0.25173088908195496 , val_loss : 0.49575820565223694,p 0.47638081395348836, r 0.5788079470198676, f 0.5226230815228224\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0.242017924785614 , val_loss : 0.5452571511268616,p 0.5172185430463576, r 0.5172185430463576, f 0.5172185430463576\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0.23117855191230774 , val_loss : 0.5292552709579468,p 0.4624956186470382, r 0.582560706401766, f 0.5156311059007425\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0.22191356122493744 , val_loss : 0.5975090861320496,p 0.4641803989592368, r 0.590728476821192, f 0.5198640116561438\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0.21555326879024506 , val_loss : 0.5959794521331787,p 0.459924009408359, r 0.5611479028697571, f 0.5055185442975042\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0.2066746950149536 , val_loss : 0.6444709300994873,p 0.43670295489891137, r 0.6198675496688741, f 0.5124087591240876\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0.20464536547660828 , val_loss : 0.6573726534843445,p 0.5631670389674858, r 0.5008830022075055, f 0.5302021264166374\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0.196028470993042 , val_loss : 0.6522731781005859,p 0.5257883158152041, r 0.47483443708609274, f 0.4990140354947223\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0.19181667268276215 , val_loss : 0.6593162417411804,p 0.544878794496615, r 0.5507726269315674, f 0.5478098583818203\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0.18315854668617249 , val_loss : 0.6236188411712646,p 0.5043765804318227, r 0.5724061810154525, f 0.5362423741081583\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0.1844732016324997 , val_loss : 0.5594540238380432,p 0.507546356188012, r 0.5196467991169977, f 0.5135253054101221\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0.1745028793811798 , val_loss : 0.6583758592605591,p 0.5171111111111111, r 0.5136865342163356, f 0.5153931339977851\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0.17104709148406982 , val_loss : 0.7153034806251526,p 0.5282028858766944, r 0.5333333333333333, f 0.530755711775044\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0.1559724509716034 , val_loss : 0.6970089077949524,p 0.47400897531787584, r 0.5596026490066225, f 0.5132617938854019\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0.1637762039899826 , val_loss : 0.6786451935768127,p 0.5063959390862944, r 0.5505518763796909, f 0.5275515600211528\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0.15340770781040192 , val_loss : 0.6874406933784485,p 0.5400542272615233, r 0.4836644591611479, f 0.5103062769302434\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0.1453571915626526 , val_loss : 0.7965690493583679,p 0.5355204736063147, r 0.4792494481236203, f 0.5058247903075489\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0.1324647068977356 , val_loss : 0.7767409086227417,p 0.5153374233128835, r 0.519205298013245, f 0.5172641301957335\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0.14243930578231812 , val_loss : 0.7163830399513245,p 0.5514372163388804, r 0.4827814569536424, f 0.5148305084745763\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0.1314336061477661 , val_loss : 0.8188121914863586,p 0.5688425671969282, r 0.4578366445916115, f 0.5073385518590998\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0.12962062656879425 , val_loss : 0.8227750658988953,p 0.5277425893083354, r 0.4598233995584989, f 0.4914474460304353\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0.12552510201931 , val_loss : 0.8444886207580566,p 0.539957378795951, r 0.4474613686534216, f 0.48937711250603577\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0.12603121995925903 , val_loss : 0.9156785607337952,p 0.5599072404019583, r 0.47969094922737304, f 0.5167043157769586\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0.12024012207984924 , val_loss : 0.8007124662399292,p 0.47333333333333333, r 0.5328918322295806, f 0.50134994807892\n",
      "\n",
      "45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 train_loss : 0.11887314170598984 , val_loss : 0.9119873642921448,p 0.6221116246000711, r 0.38631346578366443, f 0.47664442326024786\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0.10611742734909058 , val_loss : 1.0016728639602661,p 0.6233671988388969, r 0.3792494481236203, f 0.471589349437277\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0.11828382313251495 , val_loss : 0.8408536911010742,p 0.5553047404063205, r 0.43443708609271525, f 0.4874907109239534\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0.1032753512263298 , val_loss : 0.9492854475975037,p 0.6049072035231204, r 0.42450331125827817, f 0.4988973926579323\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0.09682738780975342 , val_loss : 0.9631116390228271,p 0.547153024911032, r 0.40728476821192056, f 0.46697038724373574\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0.09724310785531998 , val_loss : 0.9572896361351013,p 0.49645736623503545, r 0.4485651214128035, f 0.47129769221848544\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0.09929996728897095 , val_loss : 1.0146270990371704,p 0.5978527607361963, r 0.430242825607064, f 0.5003851091142489\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0.09067777544260025 , val_loss : 1.011749029159546,p 0.5659437280187574, r 0.4262693156732892, f 0.4862754973558298\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0.08623074740171432 , val_loss : 1.094743013381958,p 0.5642837727643382, r 0.45827814569536424, f 0.5057863320745524\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0.08955445140600204 , val_loss : 1.087402582168579,p 0.6222723852520692, r 0.365121412803532, f 0.46021146355036174\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0.08891551941633224 , val_loss : 0.9708960056304932,p 0.5834614202274824, r 0.41898454746136865, f 0.4877296672234357\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0.08357204496860504 , val_loss : 1.0911935567855835,p 0.5862646566164154, r 0.38631346578366443, f 0.4657351962741184\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0.07535753399133682 , val_loss : 1.0563833713531494,p 0.5622171945701357, r 0.4388520971302428, f 0.49293330027274984\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0.07605089247226715 , val_loss : 1.1922268867492676,p 0.6090744101633394, r 0.37041942604856515, f 0.46067261496225126\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0.07642091810703278 , val_loss : 1.2291278839111328,p 0.6427958833619211, r 0.33090507726269314, f 0.4368988633051588\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0.06994284689426422 , val_loss : 1.1777334213256836,p 0.5667067307692307, r 0.4163355408388521, f 0.48002036141511834\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0.06737608462572098 , val_loss : 1.3234236240386963,p 0.6768211920529801, r 0.33841059602649004, f 0.4512141280353201\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0.07198244333267212 , val_loss : 1.2100046873092651,p 0.5834716229671424, r 0.3880794701986755, f 0.4661275354633435\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0.0672183409333229 , val_loss : 1.3935068845748901,p 0.6409455842997324, r 0.3172185430463576, f 0.42439456585942115\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0.07402452826499939 , val_loss : 1.113978624343872,p 0.5375232033943251, r 0.4474613686534216, f 0.48837489459101313\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0.06663928925991058 , val_loss : 1.1987814903259277,p 0.6320495185694636, r 0.40573951434878586, f 0.4942188760419467\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0.06251813471317291 , val_loss : 1.2256966829299927,p 0.5735080058224163, r 0.434878587196468, f 0.4946641556811048\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0.06462080031633377 , val_loss : 1.3354212045669556,p 0.6614206720544449, r 0.3432671081677704, f 0.45196919052463297\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0.06106261536478996 , val_loss : 1.2213233709335327,p 0.6123511904761905, r 0.363355408388521, f 0.45608201717927405\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0.05248430743813515 , val_loss : 1.188969373703003,p 0.5524497487437185, r 0.38830022075055187, f 0.45605392792325633\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0.05865250155329704 , val_loss : 1.1120426654815674,p 0.5122883670125614, r 0.4141280353200883, f 0.45800781249999994\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0.05906074121594429 , val_loss : 1.121023416519165,p 0.5367749097973911, r 0.42693156732891835, f 0.47559326201893526\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0.050257548689842224 , val_loss : 1.262827754020691,p 0.5848423876592891, r 0.38498896247240616, f 0.46432374866879655\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0.05600643903017044 , val_loss : 1.223669171333313,p 0.6083701939435182, r 0.39470198675496687, f 0.4787789530057571\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0.05202154815196991 , val_loss : 1.2905606031417847,p 0.6146629603891591, r 0.3905077262693157, f 0.47759179265658747\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0.04348890855908394 , val_loss : 1.4351297616958618,p 0.629277566539924, r 0.36534216335540837, f 0.4622905027932961\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0.04982076212763786 , val_loss : 1.2404552698135376,p 0.592245153220763, r 0.4181015452538631, f 0.49016563146997927\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0.05433078855276108 , val_loss : 1.2170807123184204,p 0.5805150480918398, r 0.4130242825607064, f 0.48265187669289306\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0.04862634092569351 , val_loss : 1.1532472372055054,p 0.5304640912626394, r 0.45165562913907287, f 0.48789793728389175\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0.047155193984508514 , val_loss : 1.5541077852249146,p 0.6547497446373851, r 0.28300220750551874, f 0.3951911220715166\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0.04501789063215256 , val_loss : 1.3375531435012817,p 0.6299329858525688, r 0.37350993377483444, f 0.46895787139689576\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0.049136534333229065 , val_loss : 1.1602221727371216,p 0.5370747310264612, r 0.4077262693156733, f 0.4635462416865353\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0.04222644120454788 , val_loss : 1.1272425651550293,p 0.47719215315528246, r 0.4456953642384106, f 0.4609062892363886\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0.04543893411755562 , val_loss : 1.5480092763900757,p 0.65775950668037, r 0.282560706401766, f 0.3953057442865967\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0.04600317403674126 , val_loss : 1.3207262754440308,p 0.5757180156657964, r 0.3894039735099338, f 0.46457729786673696\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0.041017062962055206 , val_loss : 1.3639333248138428,p 0.6012404232032105, r 0.3637969094922737, f 0.4533076605693852\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0.04153664410114288 , val_loss : 1.3358734846115112,p 0.5966907962771458, r 0.38211920529801324, f 0.4658861526039564\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0.0359620675444603 , val_loss : 1.3993793725967407,p 0.5722108145106092, r 0.3690949227373068, f 0.4487385936661299\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0.03657720983028412 , val_loss : 1.3749051094055176,p 0.6007539410555175, r 0.3869757174392936, f 0.47073039742212675\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0.044949207454919815 , val_loss : 1.4139574766159058,p 0.6278766825879288, r 0.31920529801324504, f 0.42324015805649057\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0.03248845413327217 , val_loss : 1.4148014783859253,p 0.6068376068376068, r 0.3291390728476821, f 0.4267926148561615\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0.033599432557821274 , val_loss : 1.4456281661987305,p 0.6298449612403101, r 0.358719646799117, f 0.45710267229254575\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0.0353240966796875 , val_loss : 1.4074994325637817,p 0.5847711927981996, r 0.34415011037527593, f 0.43329627570872703\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0.03791044279932976 , val_loss : 1.4287618398666382,p 0.615819209039548, r 0.3368653421633554, f 0.4355022831050228\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0.03061429038643837 , val_loss : 1.4221240282058716,p 0.6037735849056604, r 0.35320088300220753, f 0.4456824512534819\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0.03734860196709633 , val_loss : 1.5841212272644043,p 0.6467831273966766, r 0.3350993377483444, f 0.4414715719063545\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0.032696403563022614 , val_loss : 1.390152096748352,p 0.634090909090909, r 0.3695364238410596, f 0.46694560669456064\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0.028946474194526672 , val_loss : 1.3685535192489624,p 0.5762890213960014, r 0.3626931567328918, f 0.44519712776046605\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0.031185366213321686 , val_loss : 1.4489264488220215,p 0.6002358490566038, r 0.33708609271523177, f 0.43172179813401185\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0.034658461809158325 , val_loss : 1.5098905563354492,p 0.6356833398975975, r 0.3562913907284768, f 0.4566416749186589\n",
      "\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.7821229050279329, recall : 0.3674540682414698, f1 : 0.5, accuracy : 0.8863636363636364\n",
      "102844341902586509\n",
      "precision : 0.5135802469135803, recall : 0.8221343873517787, f1 : 0.6322188449848024, accuracy : 0.8868101028999065\n",
      "102844401152267937\n",
      "precision : 0.1830708661417323, recall : 0.23134328358208955, f1 : 0.20439560439560442, accuracy : 0.6837046745303627\n",
      "102844212430927059\n",
      "precision : 0.5702479338842975, recall : 0.5227272727272727, f1 : 0.5454545454545454, accuracy : 0.8488035761241125\n",
      "102844412708953395\n",
      "precision : 0.5078125, recall : 0.47101449275362317, f1 : 0.4887218045112782, accuracy : 0.867704280155642\n",
      "102844212429944013\n",
      "precision : 0.6293436293436293, recall : 0.4393530997304582, f1 : 0.5174603174603175, accuracy : 0.8514173998044966\n",
      "102844341912679064\n",
      "precision : 0.3193916349809886, recall : 0.7433628318584071, f1 : 0.44680851063829785, accuracy : 0.7855670103092783\n",
      "102844235753749959\n",
      "precision : 0.2642857142857143, recall : 0.2824427480916031, f1 : 0.2730627306273063, accuracy : 0.7333032490974729\n",
      "102844341908026005\n",
      "precision : 0.6168384879725086, recall : 0.5447647951441578, f1 : 0.5785656728444802, accuracy : 0.8207062050051422\n",
      "102844283023206486\n",
      "precision : 0.645, recall : 0.7226890756302521, f1 : 0.6816380449141347, accuracy : 0.8684497816593887\n",
      "102844224147717245\n",
      "precision : 0.7230769230769231, recall : 0.6064516129032258, f1 : 0.6596491228070175, accuracy : 0.8942202835332607\n",
      "102844412704890154\n",
      "precision : 0.6654804270462633, recall : 0.6091205211726385, f1 : 0.6360544217687075, accuracy : 0.896867469879518\n",
      "102844212430599377\n",
      "precision : 0.49174917491749176, recall : 0.6313559322033898, f1 : 0.5528756957328386, accuracy : 0.8967880085653105\n",
      "102844412711443769\n",
      "precision : 0.5776805251641138, recall : 0.7787610619469026, f1 : 0.6633165829145728, accuracy : 0.789308176100629\n",
      "102844235747982779\n",
      "precision : 0.6287519747235387, recall : 0.5489655172413793, f1 : 0.5861561119293078, accuracy : 0.7939882697947214\n",
      "==precision : 0.541228862898581, recall : 0.5547960467052433, f1 : 0.5310918673988808, accuracy : 0.833600141588192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844412722519367\n",
      "102844212429550795\n",
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n",
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n",
      "102844294671796427\n",
      "102844224145685626\n",
      "102844412717407552\n",
      "102844235751390657\n",
      "102844401156069033\n",
      "102904869420860038\n",
      "102910307641576395\n",
      "102844341905404560\n",
      "102844341906977427\n",
      "102844212430075086\n",
      "102844412711116088\n",
      "102844401153578660\n",
      "102844294667405508\n",
      "102844412706659630\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n",
      "0\n",
      "epoch 0 train_loss : 0.5384032726287842 , val_loss : 0.44882577657699585,p 0.4821056289089646, r 0.6125827814569537, f 0.5395683453237411\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0.4564460217952728 , val_loss : 0.42225921154022217,p 0.5123162495033771, r 0.5693156732891832, f 0.5393140945211209\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0.44806918501853943 , val_loss : 0.4272032082080841,p 0.4996292176492399, r 0.5949227373068433, f 0.5431277710600565\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0.4409678876399994 , val_loss : 0.5609176158905029,p 0.37419845668949026, r 0.7600441501103753, f 0.5014929721069115\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0.42679962515830994 , val_loss : 0.46944937109947205,p 0.46895661990001614, r 0.6419426048565121, f 0.5419811760320566\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0.4198540449142456 , val_loss : 0.44775086641311646,p 0.46651821218387146, r 0.6474613686534216, f 0.5422945363779237\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0.40633681416511536 , val_loss : 0.410472571849823,p 0.5179127725856698, r 0.58719646799117, f 0.5503827850196565\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0.4016774892807007 , val_loss : 0.4160172641277313,p 0.5114333519241495, r 0.6072847682119206, f 0.5552528004844082\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0.38917696475982666 , val_loss : 0.47515588998794556,p 0.42830830263530745, r 0.6673289183222958, f 0.5217466344494305\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0.3783734440803528 , val_loss : 0.4638521671295166,p 0.4357598607888631, r 0.6633554083885209, f 0.5259933485034133\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0.36504265666007996 , val_loss : 0.511690616607666,p 0.40065351263038834, r 0.7037527593818984, f 0.510611035476896\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0.35954853892326355 , val_loss : 0.44378602504730225,p 0.45101916641314266, r 0.6545253863134658, f 0.5340417867435158\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0.3516656160354614 , val_loss : 0.3794359564781189,p 0.5995705850778315, r 0.4931567328918322, f 0.5411821705426356\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0.333194762468338 , val_loss : 0.49589404463768005,p 0.4027538726333907, r 0.671523178807947, f 0.5035173384093353\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0.32355180382728577 , val_loss : 0.4403436779975891,p 0.5430611334225792, r 0.5373068432671082, f 0.5401686640035509\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0.3189091384410858 , val_loss : 0.605105996131897,p 0.33861584754262786, r 0.7452538631346578, f 0.46565517241379306\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0.3074256181716919 , val_loss : 0.45744338631629944,p 0.5786473179580202, r 0.49293598233995584, f 0.5323638097508642\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0.2947278916835785 , val_loss : 0.45920702815055847,p 0.5498554913294798, r 0.5039735099337749, f 0.5259156876295784\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0.28240907192230225 , val_loss : 0.5245556831359863,p 0.43891678076981594, r 0.6368653421633554, f 0.519679365937134\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0.27198970317840576 , val_loss : 0.5364856719970703,p 0.41690917445244297, r 0.6008830022075056, f 0.4922687403924407\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0.26120302081108093 , val_loss : 0.4986824691295624,p 0.47118208516886934, r 0.5666666666666667, f 0.5145319703347365\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0.24926024675369263 , val_loss : 0.49452775716781616,p 0.5494454713493531, r 0.5249448123620309, f 0.5369157823436442\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0.24184484779834747 , val_loss : 0.5232320427894592,p 0.4529982503578813, r 0.6286975717439294, f 0.5265785337894056\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0.23067685961723328 , val_loss : 0.6034736633300781,p 0.39242773087746224, r 0.6772626931567329, f 0.4969225785552316\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0.22373585402965546 , val_loss : 0.5287624597549438,p 0.4774428484725875, r 0.5209713024282561, f 0.498258207537211\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0.2168181985616684 , val_loss : 0.5465534329414368,p 0.5716431360769, r 0.42008830022075055, f 0.4842855325104975\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0.20450769364833832 , val_loss : 0.5797936320304871,p 0.5029548332629802, r 0.5260485651214128, f 0.5142425550280536\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0.2003903090953827 , val_loss : 0.5992815494537354,p 0.5034793286942284, r 0.543046357615894, f 0.5225148683092609\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0.1837235689163208 , val_loss : 0.6438056230545044,p 0.5867507886435331, r 0.3695364238410596, f 0.4534741974806989\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0.17975851893424988 , val_loss : 0.624651312828064,p 0.4900999803960008, r 0.5518763796909493, f 0.5191568892119198\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0.1766829937696457 , val_loss : 0.7104738354682922,p 0.5924975953831356, r 0.40794701986754967, f 0.4832004183553405\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0.15646211802959442 , val_loss : 0.7083806395530701,p 0.5286777057835373, r 0.48631346578366447, f 0.5066114752213408\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0.16107261180877686 , val_loss : 0.795266330242157,p 0.652064631956912, r 0.4008830022075055, f 0.4965140123034859\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0.15761443972587585 , val_loss : 0.7086049318313599,p 0.540340488527017, r 0.48344370860927155, f 0.5103110800419433\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0.14445944130420685 , val_loss : 0.7386911511421204,p 0.5645680819912152, r 0.42560706401766, f 0.485336689741976\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0.1472218781709671 , val_loss : 0.7861526608467102,p 0.5838825644098262, r 0.430242825607064, f 0.4954245043213014\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0.1358717978000641 , val_loss : 0.8218634724617004,p 0.5785204412719014, r 0.39359823399558497, f 0.4684708355228586\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0.1250430941581726 , val_loss : 0.8312011957168579,p 0.5417680454176804, r 0.4423841059602649, f 0.4870579657309515\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0.13338260352611542 , val_loss : 0.8245077133178711,p 0.5526452282157677, r 0.4704194260485651, f 0.5082279990460291\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0.11546571552753448 , val_loss : 0.8438721895217896,p 0.5652306752215093, r 0.4083885209713024, f 0.47417659874407275\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0.11980344355106354 , val_loss : 0.7567030787467957,p 0.43564663872069553, r 0.6194260485651214, f 0.5115303983228511\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0.10809680074453354 , val_loss : 0.8785288333892822,p 0.5399048625792812, r 0.4509933774834437, f 0.4914601876353139\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0.10641974955797195 , val_loss : 0.8641246557235718,p 0.5486935866983373, r 0.4589403973509934, f 0.4998196898665705\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0.09617849439382553 , val_loss : 0.9362740516662598,p 0.5505296306899513, r 0.42450331125827817, f 0.47937180605758445\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0.09486954659223557 , val_loss : 0.931927502155304,p 0.5752080856123662, r 0.4271523178807947, f 0.4902457562705852\n",
      "\n",
      "45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 train_loss : 0.09328746050596237 , val_loss : 0.8880277276039124,p 0.498376974680805, r 0.5083885209713024, f 0.503332969074418\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0.09096294641494751 , val_loss : 1.03103506565094,p 0.5988599928749555, r 0.37108167770419426, f 0.4582254327381764\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0.08696145564317703 , val_loss : 0.8966977000236511,p 0.5368289637952559, r 0.4746136865342163, f 0.5038078500292911\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0.07807927578687668 , val_loss : 0.990546464920044,p 0.5537649347040845, r 0.4399558498896247, f 0.49034321564768113\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0.08061576634645462 , val_loss : 1.0209027528762817,p 0.5596669750231268, r 0.40066225165562913, f 0.46700115785411034\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0.08027570694684982 , val_loss : 0.9739859104156494,p 0.5687285223367697, r 0.36534216335540837, f 0.4448924731182795\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0.07929722964763641 , val_loss : 0.9697014689445496,p 0.5213183363850379, r 0.4399558498896247, f 0.47719382257871423\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0.06807901710271835 , val_loss : 1.0368390083312988,p 0.5672955974842767, r 0.39823399558498895, f 0.46796368352788587\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0.07379857450723648 , val_loss : 0.9966715574264526,p 0.5835616438356165, r 0.376158940397351, f 0.4574496644295302\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0.06535930186510086 , val_loss : 1.0440220832824707,p 0.5981436919903746, r 0.3841059602649007, f 0.467804812474795\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0.057510506361722946 , val_loss : 1.1820634603500366,p 0.5847647498132935, r 0.3456953642384106, f 0.4345172031076581\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0.058985527604818344 , val_loss : 1.1498804092407227,p 0.5592878736983541, r 0.3675496688741722, f 0.4435859864126815\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0.055707599967718124 , val_loss : 1.2517755031585693,p 0.6112283663993247, r 0.3196467991169978, f 0.4197709813016379\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0.053284693509340286 , val_loss : 1.0804991722106934,p 0.5489860039988574, r 0.42428256070640175, f 0.4786452496575768\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0.05271035432815552 , val_loss : 1.3746672868728638,p 0.6615605552896122, r 0.3050772626931567, f 0.41758573802689225\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0.05191237851977348 , val_loss : 1.2648427486419678,p 0.6009079653322328, r 0.32141280353200885, f 0.41881202358694086\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0.05377162620425224 , val_loss : 1.2459772825241089,p 0.6099616858237548, r 0.35143487858719646, f 0.44593837535014\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0.04821065440773964 , val_loss : 1.0646414756774902,p 0.5102694051747133, r 0.42229580573951436, f 0.4621331078632685\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0.050549086183309555 , val_loss : 1.116321086883545,p 0.556953179594689, r 0.3518763796909492, f 0.43127705627705626\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0.046482596546411514 , val_loss : 1.1482938528060913,p 0.5747904577691811, r 0.39359823399558497, f 0.46724318658280917\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0.040668848901987076 , val_loss : 1.3480224609375,p 0.622356495468278, r 0.3183222958057395, f 0.42120636775230025\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0.04372028633952141 , val_loss : 1.2810723781585693,p 0.6019455252918288, r 0.3415011037527594, f 0.4357746478873239\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0.04105851426720619 , val_loss : 1.4394538402557373,p 0.6352201257861635, r 0.2675496688741722, f 0.3765144454799627\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0.034634970128536224 , val_loss : 1.3460651636123657,p 0.6174908050674295, r 0.33355408388520974, f 0.4331374516267737\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0.037664856761693954 , val_loss : 1.356048822402954,p 0.6370123691722169, r 0.29558498896247243, f 0.40379975874547647\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0.03925550356507301 , val_loss : 1.2820030450820923,p 0.6093808630393996, r 0.35849889624724063, f 0.4514246004169562\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0.03785336762666702 , val_loss : 1.337022304534912,p 0.629843363561418, r 0.3373068432671082, f 0.43933294997124783\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0.04509477689862251 , val_loss : 1.0896390676498413,p 0.5321229050279329, r 0.4205298013245033, f 0.46979038224414305\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0.031193817034363747 , val_loss : 1.3111802339553833,p 0.6156542056074766, r 0.3490066225165563, f 0.44547759932375314\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0.027073055505752563 , val_loss : 1.3045762777328491,p 0.6144440198700802, r 0.35496688741721855, f 0.44997901217293973\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0.03624190762639046 , val_loss : 1.2988718748092651,p 0.6130284728213977, r 0.3136865342163355, f 0.4150116822429906\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0.028563708066940308 , val_loss : 1.3941291570663452,p 0.5908379013312451, r 0.33311258278145695, f 0.42603049124788256\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0.03466857224702835 , val_loss : 1.2530351877212524,p 0.5603098487642936, r 0.33532008830022075, f 0.4195553100400497\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0.028319895267486572 , val_loss : 1.4754663705825806,p 0.6640355204736064, r 0.29713024282560707, f 0.4105536068323929\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0.02664063312113285 , val_loss : 1.300174593925476,p 0.5552781740370899, r 0.3437086092715232, f 0.424597763839651\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0.03381461277604103 , val_loss : 1.2105666399002075,p 0.5530807058142898, r 0.422075055187638, f 0.47877801427319394\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0.025248747318983078 , val_loss : 1.3760900497436523,p 0.5888594164456233, r 0.343046357615894, f 0.433533268238248\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0.02116650715470314 , val_loss : 1.5342193841934204,p 0.6277113767153608, r 0.3130242825607064, f 0.4177345706289587\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0.033087290823459625 , val_loss : 1.2157564163208008,p 0.5747980613893376, r 0.3927152317880795, f 0.4666229508196722\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0.020015109330415726 , val_loss : 1.4118503332138062,p 0.5993227990970654, r 0.35165562913907283, f 0.44323873121869783\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0.017247984185814857 , val_loss : 1.5618996620178223,p 0.6731054977711739, r 0.3, f 0.41502519468621163\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0.027001868933439255 , val_loss : 1.4965382814407349,p 0.6425359712230215, r 0.3154525386313466, f 0.42315664791234825\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0.026004694402217865 , val_loss : 1.3918449878692627,p 0.6062734082397003, r 0.2858719646799117, f 0.38853885388538856\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0.026431426405906677 , val_loss : 1.5432381629943848,p 0.6806311207834603, r 0.276158940397351, f 0.39290201005025127\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0.019994067028164864 , val_loss : 1.4484498500823975,p 0.613841918993315, r 0.34459161147902867, f 0.44139686130354866\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0.01679391972720623 , val_loss : 1.6707128286361694,p 0.6625882352941177, r 0.3108167770419426, f 0.42314049586776864\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0.02973121777176857 , val_loss : 1.4896676540374756,p 0.5825385179750551, r 0.35055187637969093, f 0.43770672546857775\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0.015206030569970608 , val_loss : 1.6043106317520142,p 0.657080846446012, r 0.2673289183222958, f 0.38004079711281974\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0.0153650538995862 , val_loss : 1.3480684757232666,p 0.546148738379814, r 0.3631346578366446, f 0.43622381331211885\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0.022087285295128822 , val_loss : 1.5582932233810425,p 0.6268801552644347, r 0.28520971302428255, f 0.3920497648308299\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0.028226623311638832 , val_loss : 1.4494937658309937,p 0.6323132313231323, r 0.31015452538631344, f 0.4161729857819905\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0.010286564938724041 , val_loss : 1.4030876159667969,p 0.5638455827765405, r 0.33532008830022075, f 0.42054263565891475\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0.023114603012800217 , val_loss : 1.6421798467636108,p 0.6774193548387096, r 0.2781456953642384, f 0.39436619718309857\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0.016506431624293327 , val_loss : 1.4697235822677612,p 0.603836530442035, r 0.3196467991169978, f 0.418013856812933\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0.021541373804211617 , val_loss : 1.5549952983856201,p 0.6373259052924791, r 0.2525386313465784, f 0.3617391304347826\n",
      "\n",
      "data load fin\n",
      "102844212431058132\n",
      "precision : 0.7291666666666666, recall : 0.3674540682414698, f1 : 0.4886561954624781, accuracy : 0.8810876623376623\n",
      "102844341902586509\n",
      "precision : 0.5114678899082569, recall : 0.8814229249011858, f1 : 0.6473149492017417, accuracy : 0.8863423760523854\n",
      "102844401152267937\n",
      "precision : 0.20240137221269297, recall : 0.2935323383084577, f1 : 0.23959390862944163, accuracy : 0.672782874617737\n",
      "102844212430927059\n",
      "precision : 0.4465691788526434, recall : 0.6015151515151516, f1 : 0.5125887669464171, accuracy : 0.8014725216934\n",
      "102844412708953395\n",
      "precision : 0.516245487364621, recall : 0.5181159420289855, f1 : 0.5171790235081374, accuracy : 0.870136186770428\n",
      "102844212429944013\n",
      "precision : 0.6271186440677966, recall : 0.49865229110512127, f1 : 0.5555555555555555, accuracy : 0.855327468230694\n",
      "102844341912679064\n",
      "precision : 0.2987910189982729, recall : 0.7654867256637168, f1 : 0.4298136645962733, accuracy : 0.76340206185567\n",
      "102844235753749959\n",
      "precision : 0.20898100172711573, recall : 0.30788804071246817, f1 : 0.2489711934156379, accuracy : 0.6705776173285198\n",
      "102844341908026005\n",
      "precision : 0.5708860759493671, recall : 0.6843702579666161, f1 : 0.6224982746721878, accuracy : 0.8124785738772712\n",
      "102844283023206486\n",
      "precision : 0.6041189931350115, recall : 0.7394957983193278, f1 : 0.6649874055415618, accuracy : 0.8548034934497817\n",
      "102844224147717245\n",
      "precision : 0.6363636363636364, recall : 0.6548387096774193, f1 : 0.6454689984101749, accuracy : 0.8784078516902945\n",
      "102844412704890154\n",
      "precision : 0.6295081967213115, recall : 0.6254071661237784, f1 : 0.6274509803921569, accuracy : 0.8901204819277109\n",
      "102844212430599377\n",
      "precision : 0.476038338658147, recall : 0.6313559322033898, f1 : 0.5428051001821494, accuracy : 0.8925053533190578\n",
      "102844412711443769\n",
      "precision : 0.5912162162162162, recall : 0.7743362831858407, f1 : 0.6704980842911877, accuracy : 0.7971698113207547\n",
      "102844235747982779\n",
      "precision : 0.6380697050938338, recall : 0.6565517241379311, f1 : 0.6471787899388172, accuracy : 0.8097507331378299\n",
      "==precision : 0.5124628281290394, recall : 0.6000282236060573, f1 : 0.5373707260495946, accuracy : 0.8224243378406133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844412722519367\n",
      "102844212429550795\n",
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n",
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n",
      "102844294671796427\n",
      "102844224145685626\n",
      "102844412717407552\n",
      "102844235751390657\n",
      "102844401156069033\n",
      "102904869420860038\n",
      "102910307641576395\n",
      "102844341905404560\n",
      "102844341906977427\n",
      "102844212430075086\n",
      "102844412711116088\n",
      "102844401153578660\n",
      "102844294667405508\n",
      "102844412706659630\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n"
     ]
    }
   ],
   "source": [
    "hyper_parameter = [64,128,256]\n",
    "weight_directory=['_d64/','_d128/','_d256/',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for exp_index in range(0,3):\n",
    "\n",
    "    global weight_dir\n",
    "    weight_dir= conf['dataset']['weight_path']+weight_directory[exp_index]##weight 저장\n",
    "    model_epoch = conf['trn_args']['epoch']\n",
    "    \n",
    "    global input_size,hidden_size,num_layers\n",
    "    input_size=total_size\n",
    "    hidden_size=hyper_parameter[exp_index]\n",
    "    num_layers=conf['trn_args']['num_layer']\n",
    "\n",
    "    lr = conf['trn_args']['lr']\n",
    "\n",
    "    model=LSTM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "        f.write('=====result=======\\n')\n",
    "    f1_best=0\n",
    "    for epoch in range(model_epoch):\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "            inputs=inputs.float()\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out,_=model(inputs)\n",
    "            out=out.to(device)\n",
    "            loss=criterion(out,labels)\n",
    "            losses.update(loss,labels.size(0))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_losses=AverageMeter()\n",
    "        acc=0\n",
    "        gt_sum=0\n",
    "        tp_sum=0\n",
    "        fp_sum=0\n",
    "        fn_sum=0\n",
    "        acc=0\n",
    "        sum=0\n",
    "        pred_sum=0\n",
    "\n",
    "\n",
    "        with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                    inputs=inputs.float()\n",
    "                    inputs=inputs.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    out,_=model(inputs)\n",
    "                    out=out.to(device)\n",
    "                    loss=criterion(out,labels)\n",
    "                    val_losses.update(loss,labels.size(0))\n",
    "                    TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                    tp_sum += TP\n",
    "                    fp_sum += FP\n",
    "                    fn_sum += FN\n",
    "                    pred_sum += pred_len\n",
    "                    gt_sum += gt_len\n",
    "                    acc=acc+TP+TN\n",
    "                    sum+=len(out)\n",
    "                if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                    precision = tp_sum/(tp_sum+fp_sum)\n",
    "                    recall = tp_sum / (tp_sum+fn_sum)\n",
    "                    f1 = (2*precision*recall / (precision + recall))\n",
    "                    accuracy=acc/sum\n",
    "                    print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                    wr = csv.writer(csv_f)\n",
    "                    wr.writerow([epoch,precision, recall,f1])\n",
    "                    csv_f.close()\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                    if f1_best<f1:\n",
    "                        f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                        torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                        f1_best=f1\n",
    "\n",
    "                else:\n",
    "                    print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                    f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                    csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                    wr = csv.writer(csv_f)\n",
    "                    wr.writerow([epoch,0, 0,0])\n",
    "                    csv_f.close()\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "    def fmeasure2(frames,label): ##measure def for test\n",
    "        average = [0,0,0,0,0]\n",
    "        for key in frames.keys():\n",
    "            TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "            FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "            TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "            FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "            if precision==0 and recall == 0:\n",
    "                print('!')\n",
    "            else:\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                print(key)\n",
    "                print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "                average[0]+= precision\n",
    "                average[1]+= recall\n",
    "                average[2]+= f1\n",
    "                average[3]+= accuracy\n",
    "                average[4]+=1\n",
    "        print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "        with open(weight_dir+'eval','a') as f:\n",
    "            f.write(\"precision : {}, recall : {}, f1 : {}, accuracy : {}\".format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "                    \n",
    "\n",
    "    test=Mul_data('test')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    pred_sum = 0#model output\n",
    "    gt_sum = 0#label\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    result={}\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output,_=model(inputs)\n",
    "            TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "            for idx,g in enumerate(game_id):\n",
    "                if g not in result.keys():\n",
    "                    result[g]=pred[idx].tolist()\n",
    "                else:\n",
    "                    result[g]+=pred[idx].tolist()\n",
    "    with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "        real_result=pickle.load(f4)\n",
    "    fmeasure2(result,real_result)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #test\n",
    "\n",
    "\n",
    "\n",
    "    test=Mul_data('total')\n",
    "    test_loader=torch.utils.data.DataLoader(test,batch_size=1)\n",
    "    dataset=weight_dir+'best'\n",
    "    checkpoint=torch.load(dataset,map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    result={}\n",
    "    with torch.no_grad():\n",
    "        for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "            inputs=inputs.float()\n",
    "            labels=labels\n",
    "            output_p,output_f=model(inputs)\n",
    "\n",
    "            if game_id[0] not in result.keys():\n",
    "                print(game_id[0])\n",
    "                result[game_id[0]]=[(output_f[0]).tolist()]\n",
    "\n",
    "            else:\n",
    "                result[game_id[0]]+=[(output_f[0]).tolist()]\n",
    "\n",
    "\n",
    "\n",
    "    with open(weight_dir+'audio_feature.json','a') as f:\n",
    "        json.dump(result,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1609c5d6daf415add5fd1f90da23d5406f9079b60a4e5640100862a3157a35d6"
  },
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
