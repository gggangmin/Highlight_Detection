{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('./data/chat_raw.pkl',\"rb\") as f1:  \n",
    "            chat_result=pickle.load(f1)\n",
    "        \n",
    "        with open('./data/audio_raw_feature_13.pickle',\"rb\") as f2:  \n",
    "            audio=pickle.load(f2)\n",
    "        with open('./data/video_raw_feature_sum_moving_average.pickle',\"rb\") as f2:  \n",
    "            video=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654','102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630','102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==\n",
      "102844412722519367\n",
      "2073\n",
      "2069\n",
      "2072\n",
      "==\n",
      "102844212429550795\n",
      "1476\n",
      "1472\n",
      "1475\n",
      "==\n",
      "102844401151219358\n",
      "1938\n",
      "1934\n",
      "1938\n",
      "==\n",
      "102844401154430631\n",
      "1656\n",
      "1652\n",
      "1656\n",
      "==\n",
      "102844412717014335\n",
      "1909\n",
      "1906\n",
      "1909\n",
      "==\n",
      "102844401153971877\n",
      "1780\n",
      "1777\n",
      "1779\n",
      "==\n",
      "102844224148503678\n",
      "2078\n",
      "2074\n",
      "2077\n",
      "==\n",
      "102844412722847048\n",
      "2159\n",
      "2158\n",
      "2158\n",
      "==\n",
      "102844401152857762\n",
      "1447\n",
      "1443\n",
      "1446\n",
      "==\n",
      "102844412707380528\n",
      "1617\n",
      "1611\n",
      "1617\n",
      "==\n",
      "102844212431516886\n",
      "1822\n",
      "1818\n",
      "1821\n",
      "==\n",
      "102844283027925085\n",
      "2271\n",
      "2267\n",
      "2270\n",
      "==\n",
      "102844412716227901\n",
      "1749\n",
      "1745\n",
      "1749\n",
      "==\n",
      "102844412710001974\n",
      "1822\n",
      "1818\n",
      "1822\n",
      "==\n",
      "102844294670878922\n",
      "2200\n",
      "2196\n",
      "2199\n",
      "==\n",
      "102844294670551241\n",
      "2346\n",
      "2343\n",
      "2346\n",
      "==\n",
      "102844283023599703\n",
      "1477\n",
      "1473\n",
      "1477\n",
      "==\n",
      "102844412704496937\n",
      "2633\n",
      "2630\n",
      "2633\n",
      "==\n",
      "102844235751783874\n",
      "2421\n",
      "2416\n",
      "2420\n",
      "==\n",
      "102844401152071328\n",
      "1865\n",
      "1860\n",
      "1864\n",
      "==\n",
      "102844412709674293\n",
      "1864\n",
      "1860\n",
      "1863\n",
      "==\n",
      "102844401153447587\n",
      "1770\n",
      "1767\n",
      "1770\n",
      "==\n",
      "102844224148896895\n",
      "1808\n",
      "1805\n",
      "1808\n",
      "==\n",
      "102844235746868664\n",
      "1987\n",
      "1982\n",
      "1986\n",
      "==\n",
      "102979081290790284\n",
      "2336\n",
      "2331\n",
      "2335\n",
      "==\n",
      "102844283027531868\n",
      "1788\n",
      "1784\n",
      "1788\n",
      "==\n",
      "102844212431975640\n",
      "2365\n",
      "2361\n",
      "2364\n",
      "==\n",
      "102844401155937960\n",
      "2027\n",
      "2023\n",
      "2026\n",
      "==\n",
      "102844212429092040\n",
      "2255\n",
      "2251\n",
      "2255\n",
      "==\n",
      "102844341906649746\n",
      "2181\n",
      "2177\n",
      "2180\n",
      "==\n",
      "102844412706987311\n",
      "1469\n",
      "1466\n",
      "1469\n",
      "==\n",
      "102844412721339716\n",
      "1822\n",
      "1816\n",
      "1822\n",
      "==\n",
      "102844212430402768\n",
      "2369\n",
      "2365\n",
      "2368\n",
      "==\n",
      "102844341905011343\n",
      "1617\n",
      "1612\n",
      "1616\n",
      "==\n",
      "102844235753356742\n",
      "1658\n",
      "1654\n",
      "1658\n",
      "==\n",
      "102844235750997440\n",
      "1676\n",
      "1672\n",
      "1676\n",
      "==\n",
      "102844412709346612\n",
      "2662\n",
      "2658\n",
      "2662\n",
      "==\n",
      "102844412705217835\n",
      "2193\n",
      "2190\n",
      "2192\n",
      "==\n",
      "102844235752963525\n",
      "1799\n",
      "1795\n",
      "1798\n",
      "==\n",
      "102844412712164667\n",
      "2089\n",
      "2083\n",
      "2088\n",
      "==\n",
      "102844412705545516\n",
      "1542\n",
      "1537\n",
      "1541\n",
      "==\n",
      "102844341912220311\n",
      "1986\n",
      "1981\n",
      "1985\n",
      "==\n",
      "102844341907370644\n",
      "2564\n",
      "2560\n",
      "2563\n",
      "==\n",
      "102844235749424575\n",
      "2271\n",
      "2267\n",
      "2271\n",
      "==\n",
      "102844212429419722\n",
      "1801\n",
      "1797\n",
      "1801\n",
      "==\n",
      "102844294669568199\n",
      "2093\n",
      "2089\n",
      "2093\n",
      "==\n",
      "102844212431779031\n",
      "2019\n",
      "2016\n",
      "2019\n",
      "==\n",
      "102844294666422466\n",
      "1989\n",
      "1984\n",
      "1989\n",
      "==\n",
      "102844224146472059\n",
      "1458\n",
      "1453\n",
      "1457\n",
      "==\n",
      "102844212428895431\n",
      "2055\n",
      "2051\n",
      "2054\n",
      "==\n",
      "102844212429747404\n",
      "1809\n",
      "1805\n",
      "1809\n",
      "==\n",
      "102844235748703677\n",
      "1830\n",
      "1826\n",
      "1829\n",
      "==\n",
      "102844224146930812\n",
      "2435\n",
      "2430\n",
      "2434\n",
      "==\n",
      "102844212430730450\n",
      "2403\n",
      "2398\n",
      "2402\n",
      "==\n",
      "102844294674876621\n",
      "1719\n",
      "1716\n",
      "1719\n",
      "==\n",
      "102844341909598870\n",
      "2344\n",
      "2340\n",
      "2344\n",
      "==\n",
      "102844283020453971\n",
      "2822\n",
      "2819\n",
      "2821\n",
      "==\n",
      "102844294670026952\n",
      "1709\n",
      "1705\n",
      "1708\n",
      "==\n",
      "102844412723174729\n",
      "2020\n",
      "2017\n",
      "2020\n",
      "==\n",
      "102844341904683662\n",
      "2130\n",
      "2125\n",
      "2129\n",
      "==\n",
      "102844283025696858\n",
      "2608\n",
      "2604\n",
      "2607\n",
      "==\n",
      "102844235747261881\n",
      "1363\n",
      "1358\n",
      "1362\n",
      "==\n",
      "102844401154168486\n",
      "1925\n",
      "1920\n",
      "1924\n",
      "==\n",
      "102844235748310460\n",
      "1895\n",
      "1890\n",
      "1894\n",
      "==\n",
      "102844412711836986\n",
      "1549\n",
      "1545\n",
      "1548\n",
      "==\n",
      "102844412723567946\n",
      "2160\n",
      "2155\n",
      "2160\n",
      "==\n",
      "102844235749031358\n",
      "2531\n",
      "2526\n",
      "2530\n",
      "==\n",
      "102844294674286796\n",
      "2681\n",
      "2676\n",
      "2680\n",
      "==\n",
      "102844294666881219\n",
      "1609\n",
      "1604\n",
      "1609\n",
      "==\n",
      "102844412716686654\n",
      "1648\n",
      "1643\n",
      "1648\n",
      "==\n",
      "102844294671796427\n",
      "2056\n",
      "2052\n",
      "2055\n",
      "==\n",
      "102844224145685626\n",
      "1693\n",
      "1689\n",
      "1692\n",
      "==\n",
      "102844412717407552\n",
      "1915\n",
      "1910\n",
      "1914\n",
      "==\n",
      "102844235751390657\n",
      "1981\n",
      "1976\n",
      "1980\n",
      "==\n",
      "102844401156069033\n",
      "1857\n",
      "1852\n",
      "1856\n",
      "==\n",
      "102904869420860038\n",
      "1703\n",
      "1700\n",
      "1702\n",
      "==\n",
      "102910307641576395\n",
      "1675\n",
      "1670\n",
      "1674\n",
      "==\n",
      "102844341905404560\n",
      "1883\n",
      "1880\n",
      "1883\n",
      "==\n",
      "102844341906977427\n",
      "1780\n",
      "1776\n",
      "1780\n",
      "==\n",
      "102844212430075086\n",
      "2283\n",
      "2279\n",
      "2283\n",
      "==\n",
      "102844412711116088\n",
      "1705\n",
      "1701\n",
      "1705\n",
      "==\n",
      "102844401153578660\n",
      "2522\n",
      "2519\n",
      "2522\n",
      "==\n",
      "102844294667405508\n",
      "1828\n",
      "1823\n",
      "1827\n",
      "==\n",
      "102844412706659630\n",
      "1568\n",
      "1564\n",
      "1568\n",
      "==\n",
      "102844212431058132\n",
      "2471\n",
      "2464\n",
      "2470\n",
      "==\n",
      "102844341902586509\n",
      "2143\n",
      "2138\n",
      "2142\n",
      "==\n",
      "102844401152267937\n",
      "2294\n",
      "2289\n",
      "2293\n",
      "==\n",
      "102844212430927059\n",
      "3805\n",
      "3803\n",
      "3804\n",
      "==\n",
      "102844412708953395\n",
      "2061\n",
      "2056\n",
      "2061\n",
      "==\n",
      "102844212429944013\n",
      "2049\n",
      "2046\n",
      "2049\n",
      "==\n",
      "102844341912679064\n",
      "1945\n",
      "1940\n",
      "1945\n",
      "==\n",
      "102844235753749959\n",
      "2219\n",
      "2216\n",
      "2219\n",
      "==\n",
      "102844341908026005\n",
      "2918\n",
      "2917\n",
      "2918\n",
      "==\n",
      "102844283023206486\n",
      "1837\n",
      "1832\n",
      "1836\n",
      "==\n",
      "102844224147717245\n",
      "1837\n",
      "1834\n",
      "1837\n",
      "==\n",
      "102844412704890154\n",
      "2080\n",
      "2075\n",
      "2079\n",
      "==\n",
      "102844212430599377\n",
      "2341\n",
      "2335\n",
      "2340\n",
      "==\n",
      "102844412711443769\n",
      "2549\n",
      "2544\n",
      "2548\n",
      "==\n",
      "102844235747982779\n",
      "2732\n",
      "2728\n",
      "2732\n"
     ]
    }
   ],
   "source": [
    "for i in sample:\n",
    "    print('==')\n",
    "    print(i)\n",
    "    print(len(chat_result[i]))\n",
    "    print(len(audio[i]))\n",
    "    print(len(video[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "\n",
    "        with open('./data/chat_raw.pkl',\"rb\") as f1:  \n",
    "            self.chat_result=pickle.load(f1)\n",
    "        \n",
    "        with open('./data/audio_raw_feature_13.pickle',\"rb\") as f2:  \n",
    "            self.audio=pickle.load(f2)\n",
    "        with open('./data/video_raw_feature_sum_moving_average.pickle',\"rb\") as f2:  \n",
    "            self.video=pickle.load(f2)\n",
    "        with open('./label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            for idx in range(23): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<len(self.audio[game_id]):\n",
    "                    s_window+=list((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=[self.video[game_id][vframe+idx]]\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*1014\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([[ 0.        ,  0.        ,  0.        , ..., -2.99407219,\n",
      "        -3.54347805,  0.01117067],\n",
      "       [ 0.        ,  0.        ,  0.        , ..., -2.54867552,\n",
      "        -3.03780565,  0.02793789],\n",
      "       [ 0.        ,  0.        ,  0.        , ..., -0.24941073,\n",
      "        -0.11264702,  0.03156882],\n",
      "       ...,\n",
      "       [ 0.        ,  0.        ,  0.        , ..., -2.46387674,\n",
      "        -2.8452097 ,  0.02793295],\n",
      "       [ 0.        ,  0.        ,  0.        , ..., -3.52012466,\n",
      "        -4.43745678,  0.03501002],\n",
      "       [ 0.        ,  0.        ,  0.        , ..., -5.56696138,\n",
      "        -3.35553581,  0.04068482]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "\n",
    "print(train[100])\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 1014)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[100][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=1014\n",
    "hidden_size=128\n",
    "length=7\n",
    "num_layers=3\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,3,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=LSTM().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_dir='./C_data+A_data+V_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.6452922821044922,p 0.2901206973625391, r 0.7163355408388521, f 0.4129812281259943\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.4511004090309143,p 0.5520361990950227, r 0.4578366445916115, f 0.500543019186678\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.5397719144821167,p 0.4202429149797571, r 0.6874172185430464, f 0.5216080402010049\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.4119870066642761,p 0.5821478382147838, r 0.4607064017660044, f 0.5143561306223043\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.7676252722740173,p 0.26316133673402653, r 0.8883002207505519, f 0.4060340043388326\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.40578827261924744,p 0.5741367637102234, r 0.37439293598233997, f 0.45323356493853556\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.394549161195755,p 0.5824446267432322, r 0.47019867549668876, f 0.5203371198241115\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.506081759929657,p 0.41790625877069887, r 0.6573951434878588, f 0.5109814687714482\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.5279620289802551,p 0.37213786454567366, r 0.6816777041942604, f 0.4814468350483318\n",
      "\n",
      "9\n",
      "epoch 13 train_loss : 0 , val_loss : 0.4482420086860657,p 0.4712758851035404, r 0.6229580573951435, f 0.5366039170945046\n",
      "\n",
      "14\n",
      "epoch 62 train_loss : 0 , val_loss : 0.5812767744064331,p 0.35672714823690516, r 0.6900662251655629, f 0.4703227262468968\n",
      "\n",
      "63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e9ae891afae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(100):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out,_=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out,_=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "3 0 23 6 tensor(3) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "7 2 13 10 tensor(9) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 10 10 2 tensor(20) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 25 1 tensor(6) tensor(7)\n",
      "11 0 14 7 tensor(11) tensor(18)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 19 6 tensor(7) tensor(13)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 7 8 15 tensor(9) tensor(17)\n",
      "0 10 11 11 tensor(10) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 19 5 tensor(8) tensor(13)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 2 24 tensor(6) tensor(30)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 4 17 11 tensor(4) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 20 9 tensor(3) tensor(12)\n",
      "6 11 12 3 tensor(17) tensor(9)\n",
      "1 0 13 18 tensor(1) tensor(19)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 10 13 tensor(9) tensor(22)\n",
      "17 7 8 0 tensor(24) tensor(17)\n",
      "22 0 4 6 tensor(22) tensor(28)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "17 9 6 0 tensor(26) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 10 4 0 tensor(28) tensor(18)\n",
      "0 8 17 7 tensor(8) tensor(7)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "10 22 0 0 tensor(32) tensor(10)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "10 5 17 0 tensor(15) tensor(10)\n",
      "18 13 1 0 tensor(31) tensor(18)\n",
      "5 15 12 0 tensor(20) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 8 8 0 tensor(24) tensor(16)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "11 7 14 0 tensor(18) tensor(11)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "14 13 1 4 tensor(27) tensor(18)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 2 16 0 tensor(16) tensor(14)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 26 6 0 tensor(26) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 3 14 15 tensor(3) tensor(15)\n",
      "0 24 8 0 tensor(24) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "14 3 12 3 tensor(17) tensor(17)\n",
      "0 10 17 5 tensor(10) tensor(5)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "10 22 0 0 tensor(32) tensor(10)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 5 15 12 tensor(5) tensor(12)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 12 20 tensor(0) tensor(20)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 24 8 0 tensor(24) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 1 26 5 tensor(1) tensor(5)\n",
      "0 24 8 0 tensor(24) tensor(0)\n",
      "3 0 5 24 tensor(3) tensor(27)\n",
      "0 0 7 25 tensor(0) tensor(25)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 14 6 12 tensor(14) tensor(12)\n",
      "9 13 0 10 tensor(22) tensor(19)\n",
      "6 26 0 0 tensor(32) tensor(6)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 3 22 7 tensor(3) tensor(7)\n",
      "3 0 9 20 tensor(3) tensor(23)\n",
      "27 0 0 5 tensor(27) tensor(32)\n",
      "8 14 10 0 tensor(22) tensor(8)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "0 5 25 2 tensor(5) tensor(2)\n",
      "8 3 0 21 tensor(11) tensor(29)\n",
      "16 16 0 0 tensor(32) tensor(16)\n",
      "9 9 7 7 tensor(18) tensor(16)\n",
      "11 9 4 8 tensor(20) tensor(19)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 4 27 0 tensor(5) tensor(1)\n",
      "18 1 13 0 tensor(19) tensor(18)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "23 4 1 4 tensor(27) tensor(27)\n",
      "0 1 19 12 tensor(1) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "22 0 5 5 tensor(22) tensor(27)\n",
      "9 0 11 12 tensor(9) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 2 15 2 tensor(15) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 1 18 1 tensor(13) tensor(13)\n",
      "12 1 17 2 tensor(13) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 8 16 2 tensor(14) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "8 0 21 3 tensor(8) tensor(11)\n",
      "11 0 16 5 tensor(11) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 8 14 tensor(10) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "14 7 9 2 tensor(21) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 15 5 tensor(12) tensor(17)\n",
      "13 3 16 0 tensor(16) tensor(13)\n",
      "0 14 8 10 tensor(14) tensor(10)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 18 8 tensor(6) tensor(14)\n",
      "2 0 21 9 tensor(2) tensor(11)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "15 4 13 0 tensor(19) tensor(15)\n",
      "7 0 23 2 tensor(7) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 29 1 tensor(2) tensor(3)\n",
      "21 0 0 11 tensor(21) tensor(32)\n",
      "10 0 12 10 tensor(10) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 3 12 tensor(17) tensor(29)\n",
      "7 0 20 5 tensor(7) tensor(12)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "14 6 0 12 tensor(20) tensor(26)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "2 5 25 0 tensor(7) tensor(2)\n",
      "20 4 8 0 tensor(24) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "0 4 23 5 tensor(4) tensor(5)\n",
      "10 3 5 14 tensor(13) tensor(24)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "10 4 18 0 tensor(14) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 8 5 tensor(19) tensor(24)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "21 1 6 4 tensor(22) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 7 19 0 tensor(13) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "22 5 5 0 tensor(27) tensor(22)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "13 2 11 6 tensor(15) tensor(19)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "25 0 4 3 tensor(25) tensor(28)\n",
      "5 16 8 3 tensor(21) tensor(8)\n",
      "15 5 10 2 tensor(20) tensor(17)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "13 13 6 0 tensor(26) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "12 0 15 5 tensor(12) tensor(17)\n",
      "13 3 16 0 tensor(16) tensor(13)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 18 2 tensor(12) tensor(14)\n",
      "5 4 23 0 tensor(9) tensor(5)\n",
      "4 19 8 1 tensor(23) tensor(5)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "21 10 1 0 tensor(31) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "14 17 1 0 tensor(31) tensor(14)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 24 4 tensor(4) tensor(8)\n",
      "11 0 8 13 tensor(11) tensor(24)\n",
      "1 0 21 10 tensor(1) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "11 15 5 1 tensor(26) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 27 2 tensor(3) tensor(2)\n",
      "15 0 0 17 tensor(15) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 5 12 12 tensor(8) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 18 5 tensor(9) tensor(14)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "4 0 14 14 tensor(4) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 11 21 tensor(0) tensor(21)\n",
      "29 2 1 0 tensor(31) tensor(29)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "14 0 0 18 tensor(14) tensor(32)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 7 25 tensor(0) tensor(25)\n",
      "18 0 0 14 tensor(18) tensor(32)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 11 3 tensor(18) tensor(21)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "7 0 23 2 tensor(7) tensor(9)\n",
      "30 2 0 0 tensor(32) tensor(30)\n",
      "0 30 2 0 tensor(30) tensor(0)\n",
      "15 3 14 0 tensor(18) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "1 0 28 3 tensor(1) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 19 1 0 tensor(31) tensor(12)\n",
      "0 2 28 2 tensor(2) tensor(2)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "23 5 4 0 tensor(28) tensor(23)\n",
      "2 22 8 0 tensor(24) tensor(2)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 7 18 0 tensor(14) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 5 22 0 tensor(10) tensor(5)\n",
      "9 12 11 0 tensor(21) tensor(9)\n",
      "11 11 10 0 tensor(22) tensor(11)\n",
      "3 14 15 0 tensor(17) tensor(3)\n",
      "7 19 6 0 tensor(26) tensor(7)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 6 25 1 tensor(6) tensor(1)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "10 21 1 0 tensor(31) tensor(10)\n",
      "13 0 0 19 tensor(13) tensor(32)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "6 22 0 4 tensor(28) tensor(10)\n",
      "0 6 23 3 tensor(6) tensor(3)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "6 0 24 2 tensor(6) tensor(8)\n",
      "15 0 3 14 tensor(15) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 24 1 7 tensor(24) tensor(7)\n",
      "1 4 0 27 tensor(5) tensor(28)\n",
      "0 4 19 9 tensor(4) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 11 10 6 tensor(16) tensor(11)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 1 22 9 tensor(1) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 21 4 tensor(7) tensor(4)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "12 9 11 0 tensor(21) tensor(12)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "0 2 27 3 tensor(2) tensor(3)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "3 11 12 6 tensor(14) tensor(9)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "2 2 23 5 tensor(4) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 12 20 tensor(0) tensor(20)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "4 23 0 5 tensor(27) tensor(9)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "1 12 18 1 tensor(13) tensor(2)\n",
      "16 0 10 6 tensor(16) tensor(22)\n",
      "18 0 6 8 tensor(18) tensor(26)\n",
      "8 4 20 0 tensor(12) tensor(8)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "13 4 9 6 tensor(17) tensor(19)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "1 0 20 11 tensor(1) tensor(12)\n",
      "0 6 24 2 tensor(6) tensor(2)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 3 10 2 tensor(20) tensor(19)\n",
      "2 8 22 0 tensor(10) tensor(2)\n",
      "17 4 9 2 tensor(21) tensor(19)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "0 24 8 0 tensor(24) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 3 24 tensor(5) tensor(29)\n",
      "12 0 19 1 tensor(12) tensor(13)\n",
      "4 10 18 0 tensor(14) tensor(4)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "16 7 2 7 tensor(23) tensor(23)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "7 0 13 12 tensor(7) tensor(19)\n",
      "17 1 7 7 tensor(18) tensor(24)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 0 13 5 tensor(14) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "5 15 8 4 tensor(20) tensor(9)\n",
      "9 0 19 4 tensor(9) tensor(13)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "17 10 5 0 tensor(27) tensor(17)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "11 4 17 0 tensor(15) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 21 3 tensor(8) tensor(3)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 7 10 tensor(15) tensor(25)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "6 16 10 0 tensor(22) tensor(6)\n",
      "8 0 22 2 tensor(8) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 0 8 1 tensor(23) tensor(24)\n",
      "6 14 6 6 tensor(20) tensor(12)\n",
      "4 8 20 0 tensor(12) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 16 0 tensor(16) tensor(16)\n",
      "4 0 17 11 tensor(4) tensor(15)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "12 20 0 0 tensor(32) tensor(12)\n",
      "1 11 20 0 tensor(12) tensor(1)\n",
      "5 8 19 0 tensor(13) tensor(5)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 11 21 tensor(0) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "22 3 5 2 tensor(25) tensor(24)\n",
      "0 9 19 4 tensor(9) tensor(4)\n",
      "3 8 21 0 tensor(11) tensor(3)\n",
      "11 0 3 18 tensor(11) tensor(29)\n",
      "1 14 7 10 tensor(15) tensor(11)\n",
      "2 23 7 0 tensor(25) tensor(2)\n",
      "7 9 16 0 tensor(16) tensor(7)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 8 23 0 tensor(9) tensor(1)\n",
      "12 12 0 8 tensor(24) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 24 8 0 tensor(24) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 11 19 tensor(2) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 20 11 tensor(1) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "10 11 11 0 tensor(21) tensor(10)\n",
      "19 0 3 10 tensor(19) tensor(29)\n",
      "18 1 9 4 tensor(19) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 4 12 5 tensor(15) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 9 17 tensor(6) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "25 0 0 7 tensor(25) tensor(32)\n",
      "21 0 4 7 tensor(21) tensor(28)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "21 6 5 0 tensor(27) tensor(21)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 20 11 tensor(1) tensor(12)\n",
      "1 5 22 4 tensor(6) tensor(5)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "25 4 3 0 tensor(29) tensor(25)\n",
      "19 0 13 0 tensor(19) tensor(19)\n",
      "13 12 7 0 tensor(25) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "1 15 0 16 tensor(16) tensor(17)\n",
      "16 2 6 8 tensor(18) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 4 10 2 tensor(20) tensor(18)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 1 11 tensor(20) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 13 19 tensor(0) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 24 3 tensor(5) tensor(8)\n",
      "21 0 6 5 tensor(21) tensor(26)\n",
      "1 26 0 5 tensor(27) tensor(6)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "3 12 13 4 tensor(15) tensor(7)\n",
      "0 1 24 7 tensor(1) tensor(7)\n",
      "13 4 10 5 tensor(17) tensor(18)\n",
      "30 2 0 0 tensor(32) tensor(30)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 11 3 5 tensor(24) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "3 6 18 5 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 2 17 7 tensor(8) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 11 20 tensor(1) tensor(21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0 27 1 tensor(4) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 2 26 4 tensor(2) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "6 0 4 22 tensor(6) tensor(28)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 0 9 10 tensor(13) tensor(23)\n",
      "11 0 18 3 tensor(11) tensor(14)\n",
      "0 1 25 6 tensor(1) tensor(6)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "29 2 1 0 tensor(31) tensor(29)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "22 1 9 0 tensor(23) tensor(22)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 20 6 tensor(6) tensor(12)\n",
      "21 5 6 0 tensor(26) tensor(21)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 16 5 tensor(11) tensor(16)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "20 0 3 9 tensor(20) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "2 3 27 0 tensor(5) tensor(2)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 9 20 tensor(3) tensor(23)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "6 15 11 0 tensor(21) tensor(6)\n",
      "12 17 3 0 tensor(29) tensor(12)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 1 28 tensor(3) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 22 2 tensor(8) tensor(9)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 6 8 0 tensor(24) tensor(18)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 4 15 0 tensor(17) tensor(13)\n",
      "22 9 1 0 tensor(31) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "1 2 29 0 tensor(3) tensor(1)\n",
      "23 0 6 3 tensor(23) tensor(26)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "22 0 0 10 tensor(22) tensor(32)\n",
      "6 16 10 0 tensor(22) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 2 11 8 tensor(13) tensor(19)\n",
      "17 1 14 0 tensor(18) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 25 5 tensor(2) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 29 2 tensor(1) tensor(3)\n",
      "20 2 5 5 tensor(22) tensor(25)\n",
      "12 7 13 0 tensor(19) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 4 20 0 tensor(12) tensor(8)\n",
      "8 0 20 4 tensor(8) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 9 5 tensor(18) tensor(23)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "0 26 6 0 tensor(26) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "17 13 2 0 tensor(30) tensor(17)\n",
      "28 0 1 3 tensor(28) tensor(31)\n",
      "4 18 10 0 tensor(22) tensor(4)\n",
      "3 24 5 0 tensor(27) tensor(3)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "3 7 22 0 tensor(10) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "10 21 1 0 tensor(31) tensor(10)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "6 14 10 2 tensor(20) tensor(8)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "16 0 11 5 tensor(16) tensor(21)\n",
      "13 19 0 0 tensor(32) tensor(13)\n",
      "17 5 6 4 tensor(22) tensor(21)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "3 1 28 0 tensor(4) tensor(3)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "27 3 2 0 tensor(30) tensor(27)\n",
      "11 8 13 0 tensor(19) tensor(11)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 10 9 0 tensor(23) tensor(13)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 20 3 0 tensor(29) tensor(9)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 2 12 3 tensor(17) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "12 1 0 19 tensor(13) tensor(31)\n",
      "18 11 0 3 tensor(29) tensor(21)\n",
      "12 13 7 0 tensor(25) tensor(12)\n",
      "3 0 24 5 tensor(3) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "5 0 17 10 tensor(5) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 0 10 9 tensor(13) tensor(22)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "20 0 11 1 tensor(20) tensor(21)\n",
      "7 0 20 5 tensor(7) tensor(12)\n",
      "5 0 18 9 tensor(5) tensor(14)\n",
      "20 0 12 0 tensor(20) tensor(20)\n",
      "0 13 14 5 tensor(13) tensor(5)\n",
      "13 13 6 0 tensor(26) tensor(13)\n",
      "9 5 13 5 tensor(14) tensor(14)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "6 0 22 4 tensor(6) tensor(10)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "5 8 8 11 tensor(13) tensor(16)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "1 1 30 0 tensor(2) tensor(1)\n",
      "7 8 6 11 tensor(15) tensor(18)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "3 0 2 27 tensor(3) tensor(30)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "24 0 0 8 tensor(24) tensor(32)\n",
      "18 2 1 11 tensor(20) tensor(29)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 2 8 22 tensor(2) tensor(22)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 25 5 tensor(2) tensor(7)\n",
      "12 2 5 13 tensor(14) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 4 7 0 tensor(25) tensor(21)\n",
      "30 0 1 1 tensor(30) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "1 18 13 0 tensor(19) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 5 15 2 tensor(15) tensor(12)\n",
      "20 1 11 0 tensor(21) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 5 0 0 tensor(17) tensor(12)\n",
      "3844 3677 2390\n",
      "[1100/1101], prec:0.5111022470416168, recall:0.6166185434712865, f1:55.89240276263177, acc: 0.8277252463298975\n"
     ]
    }
   ],
   "source": [
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output,_=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212431058132\n",
      "precision : 0.6606334841628959, recall : 0.38320209973753283, f1 : 0.48504983388704326, accuracy : 0.8741883116883117\n",
      "102844341902586509\n",
      "precision : 0.4424131627056673, recall : 0.9565217391304348, f1 : 0.605, accuracy : 0.852198316183349\n",
      "102844401152267937\n",
      "precision : 0.19593613933236576, recall : 0.3358208955223881, f1 : 0.24747937671860684, accuracy : 0.6413280908693753\n",
      "102844212430927059\n",
      "precision : 0.6524300441826215, recall : 0.6712121212121213, f1 : 0.6616878267363705, accuracy : 0.88088351301604\n",
      "102844412708953395\n",
      "precision : 0.5477855477855478, recall : 0.8514492753623188, f1 : 0.6666666666666666, accuracy : 0.8857003891050583\n",
      "102844212429944013\n",
      "precision : 0.6589861751152074, recall : 0.38544474393531, f1 : 0.4863945578231292, accuracy : 0.852394916911046\n",
      "102844341912679064\n",
      "precision : 0.46715328467153283, recall : 0.8495575221238938, f1 : 0.6028257456828886, accuracy : 0.8695876288659794\n",
      "102844235753749959\n",
      "precision : 0.25464684014869887, recall : 0.3486005089058524, f1 : 0.2943071965628356, accuracy : 0.7035198555956679\n",
      "102844341908026005\n",
      "precision : 0.5, recall : 0.6418816388467374, f1 : 0.5621262458471761, accuracy : 0.774082961947206\n",
      "102844283023206486\n",
      "precision : 0.6048192771084338, recall : 0.7030812324929971, f1 : 0.6502590673575129, accuracy : 0.8526200873362445\n",
      "102844224147717245\n",
      "precision : 0.5362318840579711, recall : 0.5967741935483871, f1 : 0.5648854961832062, accuracy : 0.8446019629225736\n",
      "102844412704890154\n",
      "precision : 0.7427385892116183, recall : 0.5830618892508144, f1 : 0.6532846715328468, accuracy : 0.908433734939759\n",
      "102844212430599377\n",
      "precision : 0.3881278538812785, recall : 0.3601694915254237, f1 : 0.3736263736263736, accuracy : 0.8779443254817987\n",
      "102844412711443769\n",
      "precision : 0.5892857142857143, recall : 0.8761061946902655, f1 : 0.7046263345195731, accuracy : 0.8042452830188679\n",
      "102844235747982779\n",
      "precision : 0.6340782122905028, recall : 0.6262068965517241, f1 : 0.630117973629424, accuracy : 0.8046187683284457\n",
      "==precision : 0.5250177472626704, recall : 0.6112726961890801, f1 : 0.5458891577849101, accuracy : 0.8284232097473151\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('./label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
