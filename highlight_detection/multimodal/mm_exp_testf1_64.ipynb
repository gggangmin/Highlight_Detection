{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레인함과 동시에 f1스코어 계산 & csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [option]dataset 확인 (형태확인 및 피쳐수 확인 필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "    chat=json.load(f1)\n",
    "\n",
    "with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "    audio=json.load(f2)\n",
    "with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "    video=json.load(f2)\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio['102844412722519367'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "video 형태가 안맞았는지, 혼자만 코드 이상하게 되어있음. \n",
    "\n",
    "기본 형태 : 'gameid':[[0초 피쳐],[1초 피쳐]]\n",
    "\n",
    "video는 1개의 피쳐가 그냥 'gameid':[0초피쳐,1초피쳐,,,,]로 되어있음.\n",
    " --> 추후 수정시, \n",
    "\n",
    "**s_window+=list(self.video[game_id][vframe+idx])**\n",
    "\n",
    "로만 바꿔주시오~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:1\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "\n",
    "        with open(conf['dataset']['chat_path'],\"rb\") as f1:  \n",
    "            self.chat=json.load(f1)\n",
    "       \n",
    "        with open(conf['dataset']['audio_path'],\"rb\") as f2:  \n",
    "            self.audio=json.load(f2)\n",
    "        with open(conf['dataset']['video_path'],\"rb\") as f2:  \n",
    "            self.video=json.load(f2)\n",
    "        with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.audio[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            window_size=conf['trn_args']['window_size']\n",
    "            std_size = min(len(self.audio[game_id]),min(len(self.chat[game_id]),len(self.video[game_id]))) #데이터가 가장 짧은거에 맞춤 (오류방지)\n",
    "            chat_size = conf['dataset']['chat_size']#c초당 피쳐 개수\n",
    "            audio_size = conf['dataset']['audio_size']\n",
    "            video_size = conf['dataset']['video_size']\n",
    "            global total_size\n",
    "            total_size = int(chat_size)+int(audio_size)+int(video_size)\n",
    "            \n",
    "            \n",
    "            for idx in range(window_size): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<std_size:#아래는 데이터 형태가 조금씩 달라서 다음과 같이 진행.\n",
    "                    s_window+=list((self.chat[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio[game_id][vframe+idx])#vframe의 image\n",
    "                    s_window+=list(self.video[game_id][vframe+idx])\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*(total_size)#초가 초과되는 경우 0으로 피쳐 패\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "\n",
      "\n",
      "datset testing....\n",
      "('102844412722519367', array([[-0.03938836,  0.176522  ,  0.12692975, ...,  0.16814464,\n",
      "        -0.63688719, -0.35005528],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 0)\n",
      "23\n",
      "\n",
      "****************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('test')## 그래프 그리기위해 val 없이 test로 바로진행\n",
    "\n",
    "#test\n",
    "print(\"\\n\\ndatset testing....\")\n",
    "print(train[0])\n",
    "print(len(train[100][1]))\n",
    "print(\"\\n****************\\n\")\n",
    "\n",
    "\n",
    "#loader행\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=conf['trn_args']['sampling'])\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['val_bs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "global input_size,hidden_size,num_layers\n",
    "input_size=total_size\n",
    "hidden_size=conf['trn_args']['hidden_size']\n",
    "num_layers=conf['trn_args']['num_layer']\n",
    "\n",
    "print(input_size)\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,num_layers,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.to(device)\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device)# (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).to(device) # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        feature = out[:,-1,:]\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out,feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = conf['trn_args']['lr']\n",
    "\n",
    "model=LSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best 값을 확인하기위함\n",
    "\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.7018214464187622,p 0, r 0, f 0\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.7013643383979797,p 0, r 0, f 0\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.688821017742157,p 0, r 0, f 0\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.6942642331123352,p 0, r 0, f 0\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.6876134276390076,p 0, r 0, f 0\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.6984437108039856,p 0, r 0, f 0\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.6889368891716003,p 0, r 0, f 0\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.6921672821044922,p 0, r 0, f 0\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.6965859532356262,p 0, r 0, f 0\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.693774402141571,p 0, r 0, f 0\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.6961847543716431,p 0, r 0, f 0\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.6936577558517456,p 0, r 0, f 0\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.6967686414718628,p 0, r 0, f 0\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.6986933350563049,p 0, r 0, f 0\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0 , val_loss : 0.6966803073883057,p 0, r 0, f 0\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0 , val_loss : 0.6858804225921631,p 0, r 0, f 0\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0 , val_loss : 0.6972339749336243,p 0, r 0, f 0\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0 , val_loss : 0.6929621696472168,p 0, r 0, f 0\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0 , val_loss : 0.6932929158210754,p 0, r 0, f 0\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0 , val_loss : 0.6880528926849365,p 0, r 0, f 0\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0 , val_loss : 0.6890940070152283,p 0, r 0, f 0\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0 , val_loss : 0.6907352209091187,p 0, r 0, f 0\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.6921527981758118,p 0, r 0, f 0\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.6921527981758118,p 0, r 0, f 0\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.6930268406867981,p 0, r 0, f 0\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.690877377986908,p 0, r 0, f 0\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.6903653740882874,p 0, r 0, f 0\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.6924691796302795,p 0, r 0, f 0\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.6928671002388,p 0, r 0, f 0\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.6921733617782593,p 0, r 0, f 0\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.6900032758712769,p 0, r 0, f 0\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.6912823915481567,p 0, r 0, f 0\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.6922333836555481,p 0, r 0, f 0\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.6921766996383667,p 0, r 0, f 0\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.6921133995056152,p 0, r 0, f 0\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.6929258108139038,p 0, r 0, f 0\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.6924010515213013,p 0, r 0, f 0\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.6921963691711426,p 0, r 0, f 0\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.6936284899711609,p 0, r 0, f 0\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.6946255564689636,p 0, r 0, f 0\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.692782461643219,p 0, r 0, f 0\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.6912664175033569,p 0, r 0, f 0\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.689942479133606,p 0, r 0, f 0\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.692422091960907,p 0, r 0, f 0\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.6921137571334839,p 0, r 0, f 0\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.6918988227844238,p 0, r 0, f 0\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.692362904548645,p 0, r 0, f 0\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.6942938566207886,p 0, r 0, f 0\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.6941816210746765,p 0, r 0, f 0\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.6940240263938904,p 0, r 0, f 0\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.6929750442504883,p 0, r 0, f 0\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.6928505301475525,p 0, r 0, f 0\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.6924061179161072,p 0, r 0, f 0\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.6932785511016846,p 0, r 0, f 0\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.6945812106132507,p 0, r 0, f 0\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.6940764784812927,p 0, r 0, f 0\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.6930936574935913,p 0, r 0, f 0\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0 , val_loss : 0.6912248730659485,p 0, r 0, f 0\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0 , val_loss : 0.6917774081230164,p 0, r 0, f 0\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0 , val_loss : 0.6913376450538635,p 0, r 0, f 0\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0 , val_loss : 0.6925345063209534,p 0, r 0, f 0\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0 , val_loss : 0.6925413608551025,p 0, r 0, f 0\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0 , val_loss : 0.6924742460250854,p 0, r 0, f 0\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0 , val_loss : 0.691936194896698,p 0, r 0, f 0\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0 , val_loss : 0.693048894405365,p 0, r 0, f 0\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0 , val_loss : 0.6939212083816528,p 0, r 0, f 0\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0 , val_loss : 0.6937151551246643,p 0, r 0, f 0\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0 , val_loss : 0.6934876441955566,p 0, r 0, f 0\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0 , val_loss : 0.6924342513084412,p 0, r 0, f 0\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0 , val_loss : 0.6903907656669617,p 0, r 0, f 0\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0 , val_loss : 0.6922165751457214,p 0, r 0, f 0\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0 , val_loss : 0.691083550453186,p 0, r 0, f 0\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0 , val_loss : 0.6916995048522949,p 0, r 0, f 0\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0 , val_loss : 0.6950342059135437,p 0, r 0, f 0\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0 , val_loss : 0.6951521039009094,p 0, r 0, f 0\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0 , val_loss : 0.6929882764816284,p 0, r 0, f 0\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0 , val_loss : 0.6917282342910767,p 0, r 0, f 0\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0 , val_loss : 0.691721498966217,p 0, r 0, f 0\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0 , val_loss : 0.6935049295425415,p 0, r 0, f 0\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0 , val_loss : 0.6935794949531555,p 0, r 0, f 0\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0 , val_loss : 0.6934545040130615,p 0, r 0, f 0\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0 , val_loss : 0.6949342489242554,p 0, r 0, f 0\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0 , val_loss : 0.6943645477294922,p 0, r 0, f 0\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0 , val_loss : 0.6934629082679749,p 0, r 0, f 0\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0 , val_loss : 0.6921449899673462,p 0, r 0, f 0\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0 , val_loss : 0.6904991269111633,p 0, r 0, f 0\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0 , val_loss : 0.6913137435913086,p 0, r 0, f 0\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0 , val_loss : 0.6909061074256897,p 0, r 0, f 0\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0 , val_loss : 0.6896734237670898,p 0, r 0, f 0\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0 , val_loss : 0.691362738609314,p 0, r 0, f 0\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0 , val_loss : 0.6914362907409668,p 0, r 0, f 0\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0 , val_loss : 0.6910029053688049,p 0, r 0, f 0\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0 , val_loss : 0.6915280222892761,p 0, r 0, f 0\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0 , val_loss : 0.6930352449417114,p 0, r 0, f 0\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0 , val_loss : 0.694639265537262,p 0, r 0, f 0\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0 , val_loss : 0.6916588544845581,p 0, r 0, f 0\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0 , val_loss : 0.6937660574913025,p 0, r 0, f 0\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0 , val_loss : 0.6944111585617065,p 0, r 0, f 0\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0 , val_loss : 0.6950575113296509,p 0, r 0, f 0\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0 , val_loss : 0.6940261125564575,p 0, r 0, f 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global weight_dir\n",
    "weight_dir= conf['dataset']['weight_path']##weight 저장\n",
    "model_epoch = conf['trn_args']['epoch']\n",
    "\n",
    "\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(model_epoch):\n",
    "    if conf['trn_args']['adj_lr']:\n",
    "        lr = adjust_learning_rate(optimizer, epoch)\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out,_=model(inputs)\n",
    "        out=out.to(device)\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    \n",
    "    \n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                out,_=model(inputs)\n",
    "                out=out.to(device)\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                wr = csv.writer(csv_f)\n",
    "                wr.writerow([epoch,precision, recall,f1])\n",
    "                csv_f.close()\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                \n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                csv_f = open(weight_dir+'result.csv','a', newline='')\n",
    "                wr = csv.writer(csv_f)\n",
    "                wr.writerow([epoch,0, 0,0])\n",
    "                csv_f.close()\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_with_adj_lr64/best'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5082/421280374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trn_args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_bs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/t/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/t/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/t/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_with_adj_lr64/best'"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label): ##measure def for test\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "\n",
    "\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=conf['trn_args']['val_bs'])\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "\n",
    "\n",
    "#evaluation\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output,_=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "with open(conf['dataset']['label_path'],\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
