{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(string.printable)\n",
    "## train args\n",
    "weight_dir='./new_label_final data2/'\n",
    "data_mode = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##decoding\n",
    "\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "def linesToTensor(lines):\n",
    "    char_length = 1000\n",
    "\n",
    "    tensor_one_hot = torch.zeros(len(lines), char_length, n_letters)\n",
    "    tensor_label = torch.zeros(len(lines),char_length,1) ##line = batchsize\n",
    "    for b, line in enumerate(lines): \n",
    "        line = line[:char_length]\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor_one_hot[b][li + char_length - len(line)][letterToIndex(letter)] = 1 #뒤로 맞춰줌 batch*character*100\n",
    "            tensor_label[b][li + char_length - len(line)][0] =letterToIndex(letter) #batch*character*1\n",
    "\n",
    "    return tensor_one_hot,tensor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LangModel(nn.Module):\n",
    "    def __init__(self, preTrained='True', input=100):\n",
    "        super(LangModel, self).__init__()\n",
    "\n",
    "        # Language Model\n",
    "        self.lang = nn.LSTM(input, 128, 3, batch_first=True) \n",
    " \n",
    "        # Output \n",
    "        self.output = nn.Linear(128, 2)\n",
    "        n = self.output.in_features * self.output.out_features\n",
    "        self.output.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        self.output.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        text.cuda()\n",
    "        h0 = ( Variable(torch.zeros(3, text.size(0), 128)).cuda(),  Variable(torch.zeros(3, text.size(0), 128)).cuda())\n",
    "\n",
    "        lang_feature, hn = self.lang(text, h0 )\n",
    "        lang_feature = lang_feature[:,-1,:]\n",
    "\n",
    "        pred = self.output(lang_feature)\n",
    "        return pred,lang_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class chat_ds(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.gt_range =  1-0.25\n",
    "        self.d_type=d_type\n",
    "        with open('./label.pickle','rb') as f1:  \n",
    "            self.gt=pickle.load(f1)\n",
    "        with open('./chat_raw.pkl','rb') as f2:  \n",
    "            self.text=pickle.load(f2)\n",
    "        #self.sample=list(map(int,list(self.gt.keys())))\n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "        if d_type =='total':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654'] + ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630'] + ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.gt[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "\n",
    "        begin_pos = 0 \n",
    "        hl_frames = []\n",
    "        for it, cur_pos in enumerate(pos_idx):\n",
    "            if it+1 < len(pos_idx): \n",
    "                if((pos_idx[it+1] - cur_pos) > 1):#cur_pos와 cur_pos+1 간격이 1보다 크면, 즉 다른 구간이면\n",
    "                    begin = int((it+1 - begin_pos) * self.gt_range) + begin_pos\n",
    "                    hl_frames.extend( pos_idx[begin: it] ) #한구간의 하이라이트 25%만 사용하겠다.\n",
    "                    begin_pos = it+1\n",
    "\n",
    "\n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[hl_frames] = len(sampling) / float(len(hl_frames))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        self.sum=np.insert(np.cumsum([len(self.gt[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.WeightedSampling)\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)\n",
    "            vid = np.where(vid[0]>0)[0][0]\n",
    "            vframe=index-self.sum[vid]\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "\n",
    "            win_text=''\n",
    "            for idx in range(7): #7 : window size\n",
    "                if vframe+idx<len(self.text[str(game_id)]):\n",
    "                    win_text+=self.text[str(game_id)][vframe+idx]+'\\n'\n",
    "\n",
    "            label=self.gt[str(game_id)][vframe]\n",
    "            return win_text,label,str(game_id)\n",
    "        \n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleSequentialSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially, always in the same order.\n",
    "    Arguments:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        offset (int): offset between the samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, offset=10):\n",
    "        self.num_samples = len(data_source) \n",
    "        self.offset = offset\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(np.arange(0, self.num_samples, self.offset ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(np.arange(0, self.num_samples, self.offset ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(model, clip_norm):\n",
    "    \"\"\"Computes a gradient clipping coefficient based on gradient norm.\"\"\"\n",
    "    totalnorm = 0\n",
    "    for pm in model.parameters():\n",
    "        if pm.requires_grad:\n",
    "            if pm.grad is not None:\n",
    "                modulenorm = pm.grad.data.norm()\n",
    "                totalnorm += modulenorm ** 2\n",
    "\n",
    "    totalnorm = np.sqrt(totalnorm.cpu())\n",
    "    norm = clip_norm / max(totalnorm, clip_norm)\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            if p.grad is not None:\n",
    "                p.grad.mul_(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n"
     ]
    }
   ],
   "source": [
    "#game_id='102844212428895431'\n",
    "train=chat_ds('train')\n",
    "val=chat_ds('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=10000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=256,sampler=sampler1)\n",
    "sampler2 =  SampleSequentialSampler(val, 30)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=256,sampler= sampler2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### model load #####\n",
    "if data_mode == 'label':\n",
    "    input_val = 1\n",
    "else:\n",
    "    inputs_val = 100\n",
    "model=LangModel(input=input_val).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0.6764121055603027 , val_loss : 0.7917516231536865, val_acc : 0.33181818181818185\n",
      "1\n",
      "epoch 1 train_loss : 0.6785800457000732 , val_loss : 0.7740993499755859, val_acc : 0.35795454545454547\n",
      "2\n",
      "epoch 2 train_loss : 0.675506591796875 , val_loss : 0.7581927180290222, val_acc : 0.38181818181818183\n",
      "3\n",
      "epoch 3 train_loss : 0.6794000864028931 , val_loss : 0.6880141496658325, val_acc : 0.5579545454545455\n",
      "4\n",
      "epoch 4 train_loss : 0.669232964515686 , val_loss : 0.7643585205078125, val_acc : 0.3875\n",
      "5\n",
      "epoch 5 train_loss : 0.6741083860397339 , val_loss : 0.7321354746818542, val_acc : 0.45340909090909093\n",
      "6\n",
      "epoch 6 train_loss : 0.6696631908416748 , val_loss : 0.669026792049408, val_acc : 0.6125\n",
      "7\n",
      "epoch 7 train_loss : 0.6671526432037354 , val_loss : 0.6211780905723572, val_acc : 0.7102272727272727\n",
      "8\n",
      "epoch 8 train_loss : 0.6708670258522034 , val_loss : 0.6346098184585571, val_acc : 0.6761363636363636\n",
      "9\n",
      "epoch 9 train_loss : 0.6770982146263123 , val_loss : 0.732329249382019, val_acc : 0.44886363636363635\n",
      "10\n",
      "epoch 10 train_loss : 0.6718560457229614 , val_loss : 0.7513663172721863, val_acc : 0.42272727272727273\n",
      "11\n",
      "epoch 11 train_loss : 0.6686145663261414 , val_loss : 0.7542561292648315, val_acc : 0.44545454545454544\n",
      "12\n",
      "epoch 12 train_loss : 0.6702944040298462 , val_loss : 0.6541231870651245, val_acc : 0.6568181818181819\n",
      "13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8541/1675707174.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgame_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinesToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinesToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8541/903776921.py\u001b[0m in \u001b[0;36mlinesToTensor\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtensor_one_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchar_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletterToIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#뒤로 맞춰줌 batch*character*100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtensor_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchar_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mletterToIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#batch*character*1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train set\n",
    "\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "\n",
    "\n",
    "best_losses=1000000\n",
    "for epoch in range(60):\n",
    "    lr = adjust_learning_rate(optimizer, epoch)\n",
    "    train_loss=0\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (text,labels,game_id) in enumerate(train_loader):\n",
    "        if data_mode == 'label':\n",
    "            inputs=linesToTensor(text)[1]\n",
    "        else:\n",
    "            inputs=linesToTensor(text)[0]\n",
    "\n",
    "        inputs = Variable(inputs).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output_p,output_f=model(inputs)\n",
    "\n",
    "        loss=criterion(output_p,labels.long())\n",
    "        train_loss+=loss\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.) #rnn 계열 gradient 장치\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    #validation\n",
    "    model.eval()\n",
    "    val_loss=0\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "        with torch.no_grad():\n",
    "            for it, (text,labels,game_id) in enumerate(val_loader):\n",
    "                if data_mode == 'label':\n",
    "                    inputs=linesToTensor(text)[1]\n",
    "                else:\n",
    "                    inputs=linesToTensor(text)[0]\n",
    "                inputs = Variable(inputs).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "                output_p,output_f=model(inputs)\n",
    "                loss=criterion(output_p,labels.long())\n",
    "                val_loss+=loss\n",
    "                TP,FP,TN,FN,pred_len, gt_len=fmeasure(output_p.cpu(),labels.cpu())\n",
    "                acc=acc+TP+TN\n",
    "                gt_sum+=len(output_p)\n",
    "            val_acc=acc/gt_sum\n",
    "            print(\"epoch {} train_loss : {} , val_loss : {}, val_acc : {}\".format(epoch,train_loss/len(train_loader),val_loss/len(val_loader),val_acc))\n",
    "            f.write(\"epoch {} train_loss : {} , val_loss : {}, val_acc : {}\\n\".format(epoch,train_loss/len(train_loader),val_loss/len(val_loader),val_acc))\n",
    "            if best_losses>val_loss:\n",
    "                best_losses=val_loss\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train_best\"))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+\"train_best\"))\n",
    "                f.write(\"epoch {} saved\\n\".format(epoch))\n",
    "            else:\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 33 95 0 tensor(33) tensor(0)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8541/1885420668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "test=chat_ds('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=128)\n",
    "dataset=weight_dir+'26train'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (text,labels,g) in enumerate(test_loader):\n",
    "        if data_mode == 'label':\n",
    "            inputs=linesToTensor(text)[1]\n",
    "        else:\n",
    "            inputs=linesToTensor(text)[0]\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        output_p,output_f=model(inputs)\n",
    "\n",
    "        TP,FP,TN,FN,pred_len, gt_len=fmeasure(output_p.cpu(),labels.cpu())\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output_p)\n",
    "        \n",
    "        \n",
    "        for idx,gi in enumerate(g):\n",
    "            if gi not in result.keys():\n",
    "                result[gi]=output_p[idx].tolist()\n",
    "            else:\n",
    "                result[gi]+=output_p[idx].tolist()\n",
    "                \n",
    "\n",
    "#     with open(weight_dir+'/train_result','a') as f:\n",
    "#         if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "#             precision = tp_sum/(tp_sum+fp_sum)\n",
    "#             recall = tp_sum / (tp_sum+fn_sum)\n",
    "#             f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "#             accuracy=acc/sum\n",
    "#             print( tp_sum, fp_sum, fn_sum)\n",
    "#             print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "#             f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7327/574512869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./label.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mfmeasure2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label): ##measure def for test\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "\n",
    "with open('./label.pickle','rb') as f1:  \n",
    "    gt=pickle.load(f1)\n",
    "fmeasure2(result,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844412722519367\n",
      "102844212429550795\n",
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n",
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n",
      "102844294671796427\n",
      "102844224145685626\n",
      "102844412717407552\n",
      "102844235751390657\n",
      "102844401156069033\n",
      "102904869420860038\n",
      "102910307641576395\n",
      "102844341905404560\n",
      "102844341906977427\n",
      "102844212430075086\n",
      "102844412711116088\n",
      "102844401153578660\n",
      "102844294667405508\n",
      "102844412706659630\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "test=chat_ds('total')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=1)\n",
    "dataset=weight_dir+'26train'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "result={}\n",
    "result2={}\n",
    "result3={}\n",
    "with torch.no_grad():\n",
    "    for it, (text,labels,game_id) in enumerate(test_loader):\n",
    "        if data_mode == 'label':\n",
    "            inputs=linesToTensor(text)[1]\n",
    "        else:\n",
    "            inputs=linesToTensor(text)[0]\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        output_p,output_f=model(inputs)\n",
    "#         output=(output)\n",
    "        _, pred = output_p.topk(1, 1, True, True)\n",
    "        pred = pred.view(-1,1)\n",
    "        if game_id[0] not in result.keys():\n",
    "            print(game_id[0])\n",
    "            result[game_id[0]]=[int(pred[0][0])]\n",
    "            result2[game_id[0]]=[(output_f[0]).tolist()]\n",
    "            result3[game_id[0]]=[(output_p[0]).tolist()]\n",
    "            \n",
    "        else:\n",
    "            result[game_id[0]].append(int(pred[0][0]))\n",
    "            result2[game_id[0]]+=[(output_f[0]).tolist()]\n",
    "            result3[game_id[0]]+=[(output_p[0]).tolist()]\n",
    "\n",
    "        \n",
    "with open(weight_dir+'chat_bin26.json','a') as f:\n",
    "    json.dump(result,f)\n",
    "with open(weight_dir+'chat_prob26.json','a') as f:\n",
    "    json.dump(result3,f)\n",
    "with open(weight_dir+'chat_feature26.json','a') as f:\n",
    "    json.dump(result2,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(weight_dir+'chat_bin_train.json','a') as f:\n",
    "    json.dump(result,f)\n",
    "with open(weight_dir+'chat_prob_train.json','a') as f:\n",
    "    json.dump(result3,f)\n",
    "with open(weight_dir+'chat_feature_train.json','a') as f:\n",
    "    json.dump(result2,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=torch.tensor([[ 0.0124, -0.0438, -0.0314, -0.0224,  0.0108, -0.0189,  0.0026,  0.0232,\n",
    "         -0.0182, -0.0174,  0.0452,  0.0375, -0.0213,  0.0411, -0.0517,  0.0155,\n",
    "          0.0682, -0.0051, -0.0309, -0.0049,  0.0018, -0.0063,  0.0157,  0.0178,\n",
    "          0.0045,  0.0187, -0.0101,  0.0066,  0.0157, -0.0387,  0.0258, -0.0338,\n",
    "          0.0075,  0.0497,  0.0151,  0.0546,  0.0097, -0.0002,  0.0450,  0.0119,\n",
    "         -0.0144,  0.0214,  0.0165,  0.0134,  0.0420,  0.0768, -0.0200,  0.0237,\n",
    "          0.0432,  0.0226,  0.0176,  0.1564,  0.0149, -0.0334,  0.0200,  0.0510,\n",
    "          0.0013, -0.0187, -0.0430,  0.0499,  0.0285,  0.0552, -0.0237,  0.0297,\n",
    "          0.0055, -0.0049, -0.0273,  0.0123, -0.0218, -0.0252, -0.0567, -0.0266,\n",
    "          0.0108, -0.0038,  0.0411,  0.0293,  0.0558, -0.0290, -0.0112, -0.0141,\n",
    "          0.0392, -0.0739,  0.0045, -0.0106, -0.0030,  0.0166,  0.0260,  0.0099,\n",
    "          0.0313,  0.0104,  0.0105,  0.0058,  0.0141, -0.0126, -0.0301,  0.0465,\n",
    "         -0.0182, -0.0304, -0.0034,  0.0460, -0.0364, -0.0233,  0.0174, -0.0238,\n",
    "          0.0647,  0.0091, -0.0461,  0.0063,  0.0016, -0.0056,  0.0563,  0.0176,\n",
    "         -0.0710,  0.0373, -0.0593, -0.0405,  0.0052, -0.0136,  0.0320,  0.0190,\n",
    "          0.0060, -0.0392, -0.0333, -0.0166,  0.0437,  0.0176, -0.0003,  0.0078]],\n",
    "       device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[x[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append(x[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "result['102844224148503678']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c5f5dc638da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'102844235753356742'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x['102844235753356742']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            sample =[102844235753356742,102844294666422466, 102844341906256529, 102979081290790284, 102844212430271695, 102844401155937960, 102844412704496937, 102844412722519367, 102844235749031358, 102844412709674293, 102844341902586509, 102844235750997440, 102844212431975640, 102844294667995333, 102844341912220311, 102844235747261881, 102844294670551241, 102844412707708209, 102844212430599377, 102844224145685626, 102844401152857762, 102844341908026005, 102844341909598870, 102844283023599703, 102844235753749959, 102844294670026952, 102844212430075086, 102844283027531868, 102844212430927059, 102844212429419722, 102844283025696858, 102844224146472059, 102844412712164667, 102844401153971877, 102844235748310460, 102844412711116088, 102844235752111555, 102844283020453971, 102844294666881219, 102844401152267937, 102844212429944013, 102844294671796427, 102844401151874719, 102844412723567946, 102844294669568199, 102844412709346612, 102844212431779031, 102844212430402768, 102844412711443769, 102844283027925085, 102844235746868664, 102844283023206486, 102844401154168486, 102844212429550795, 102844341907370644, 102844412721339716, 102844294667405508, 102844294674876621, 102844212429288649, 102844401154430631]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(weight_dir+'chat_bin.json','rb') as f:\n",
    "    r=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['102844412717014335'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.021551288664340973,\n",
       "  -0.04384525120258331,\n",
       "  -0.03462623432278633,\n",
       "  -0.02016858384013176,\n",
       "  0.006743958685547113,\n",
       "  -0.028185468167066574,\n",
       "  -0.004008247051388025,\n",
       "  0.026203304529190063,\n",
       "  -0.024540366604924202,\n",
       "  -0.03245027735829353,\n",
       "  0.055668849498033524,\n",
       "  0.041380468755960464,\n",
       "  -0.036310501396656036,\n",
       "  0.03796372935175896,\n",
       "  -0.06945107877254486,\n",
       "  0.018607456237077713,\n",
       "  0.07178831845521927,\n",
       "  -0.008162139914929867,\n",
       "  -0.040763359516859055,\n",
       "  -0.0024862613063305616,\n",
       "  0.00035980346729047596,\n",
       "  -0.008969173766672611,\n",
       "  0.020026447251439095,\n",
       "  0.020622877404093742,\n",
       "  0.007058870047330856,\n",
       "  0.014689539559185505,\n",
       "  -0.012295215390622616,\n",
       "  0.008632087148725986,\n",
       "  0.011394845321774483,\n",
       "  -0.04461101070046425,\n",
       "  0.03048529289662838,\n",
       "  -0.04071923717856407,\n",
       "  0.008205780759453773,\n",
       "  0.049318742007017136,\n",
       "  0.015584717504680157,\n",
       "  0.057505540549755096,\n",
       "  0.021161774173378944,\n",
       "  0.01125938631594181,\n",
       "  0.04544339329004288,\n",
       "  0.0056217750534415245,\n",
       "  -0.023245401680469513,\n",
       "  0.03170327469706535,\n",
       "  0.013656782917678356,\n",
       "  0.014859913848340511,\n",
       "  0.04345777630805969,\n",
       "  0.08530088514089584,\n",
       "  -0.023689862340688705,\n",
       "  0.028605079278349876,\n",
       "  0.045009687542915344,\n",
       "  0.02520677261054516,\n",
       "  0.010958461090922356,\n",
       "  0.18990477919578552,\n",
       "  0.018908707424998283,\n",
       "  -0.02873987890779972,\n",
       "  0.015463664196431637,\n",
       "  0.0598624162375927,\n",
       "  -0.0012019595596939325,\n",
       "  -0.01703895442187786,\n",
       "  -0.05803048238158226,\n",
       "  0.06106952205300331,\n",
       "  0.031816981732845306,\n",
       "  0.04603772610425949,\n",
       "  -0.022217784076929092,\n",
       "  0.029683955013751984,\n",
       "  0.014335939660668373,\n",
       "  -0.015362108126282692,\n",
       "  -0.029325466603040695,\n",
       "  0.01745927333831787,\n",
       "  -0.018862811848521233,\n",
       "  -0.03220737725496292,\n",
       "  -0.07142514735460281,\n",
       "  -0.0337599478662014,\n",
       "  0.003936288878321648,\n",
       "  -0.005599449388682842,\n",
       "  0.03655928373336792,\n",
       "  0.028474412858486176,\n",
       "  0.06079210340976715,\n",
       "  -0.03531363606452942,\n",
       "  -0.011131208389997482,\n",
       "  -0.003340167226269841,\n",
       "  0.039133984595537186,\n",
       "  -0.082267627120018,\n",
       "  0.004225998185575008,\n",
       "  -0.004983997903764248,\n",
       "  -0.004094090778380632,\n",
       "  0.013303719460964203,\n",
       "  0.03056332655251026,\n",
       "  0.004445989150553942,\n",
       "  0.030464377254247665,\n",
       "  0.001414382248185575,\n",
       "  0.011133326217532158,\n",
       "  0.004856514744460583,\n",
       "  0.010494066402316093,\n",
       "  -0.009692075662314892,\n",
       "  -0.045083481818437576,\n",
       "  0.05709684640169144,\n",
       "  -0.023101316764950752,\n",
       "  -0.04595688357949257,\n",
       "  -0.0057978848926723,\n",
       "  0.061329685151576996,\n",
       "  -0.03880610316991806,\n",
       "  -0.012366586364805698,\n",
       "  0.011902705766260624,\n",
       "  -0.04201640188694,\n",
       "  0.07126245647668839,\n",
       "  0.017486318945884705,\n",
       "  -0.04910486191511154,\n",
       "  0.00498295109719038,\n",
       "  0.00835510715842247,\n",
       "  0.0025800932198762894,\n",
       "  0.058390840888023376,\n",
       "  0.014191217720508575,\n",
       "  -0.08459734916687012,\n",
       "  0.05484529584646225,\n",
       "  -0.06400438398122787,\n",
       "  -0.04794120043516159,\n",
       "  0.0003198826452717185,\n",
       "  -0.026269245892763138,\n",
       "  0.0352165549993515,\n",
       "  0.016225405037403107,\n",
       "  -0.0016144849359989166,\n",
       "  -0.04086779057979584,\n",
       "  -0.03303077444434166,\n",
       "  -0.018119852989912033,\n",
       "  0.05875939875841141,\n",
       "  0.01822618395090103,\n",
       "  0.008329720236361027,\n",
       "  0.0016269396292045712],\n",
       " [0.051913462579250336,\n",
       "  -0.04185422509908676,\n",
       "  -0.044415343552827835,\n",
       "  -0.013680979609489441,\n",
       "  -0.009241558611392975,\n",
       "  -0.05537745729088783,\n",
       "  -0.025061657652258873,\n",
       "  0.04262518882751465,\n",
       "  -0.03380149230360985,\n",
       "  -0.08103327453136444,\n",
       "  0.09714218229055405,\n",
       "  0.06036151945590973,\n",
       "  -0.08450552821159363,\n",
       "  0.029466919600963593,\n",
       "  -0.12285564839839935,\n",
       "  0.025786899030208588,\n",
       "  0.0784156322479248,\n",
       "  -0.014961818233132362,\n",
       "  -0.07124287635087967,\n",
       "  0.00207160203717649,\n",
       "  -0.00293328077532351,\n",
       "  -0.013896751217544079,\n",
       "  0.03126322478055954,\n",
       "  0.028424235060811043,\n",
       "  0.01898566074669361,\n",
       "  -0.0012617219472303987,\n",
       "  -0.022402893751859665,\n",
       "  0.004508671350777149,\n",
       "  -0.005188313778489828,\n",
       "  -0.06925404071807861,\n",
       "  0.04512753337621689,\n",
       "  -0.05427098646759987,\n",
       "  0.008924806490540504,\n",
       "  0.04609394073486328,\n",
       "  0.013055931776762009,\n",
       "  0.06632717698812485,\n",
       "  0.05610020458698273,\n",
       "  0.03931222856044769,\n",
       "  0.0529591366648674,\n",
       "  -0.006060181185603142,\n",
       "  -0.045613400638103485,\n",
       "  0.05916829779744148,\n",
       "  0.008913461118936539,\n",
       "  0.024751771241426468,\n",
       "  0.04863971844315529,\n",
       "  0.1151280328631401,\n",
       "  -0.03564479574561119,\n",
       "  0.043234940618276596,\n",
       "  0.049578145146369934,\n",
       "  0.03361930325627327,\n",
       "  -0.006091326475143433,\n",
       "  0.27548491954803467,\n",
       "  0.022076230496168137,\n",
       "  -0.02092125453054905,\n",
       "  0.004547435790300369,\n",
       "  0.08156124502420425,\n",
       "  -0.017015231773257256,\n",
       "  -0.008145147003233433,\n",
       "  -0.1026330515742302,\n",
       "  0.09410417824983597,\n",
       "  0.04312128573656082,\n",
       "  0.020473426207900047,\n",
       "  -0.0182506013661623,\n",
       "  0.028017224743962288,\n",
       "  0.039589788764715195,\n",
       "  -0.04182303324341774,\n",
       "  -0.03598453849554062,\n",
       "  0.028336087241768837,\n",
       "  -0.012350838631391525,\n",
       "  -0.0579809732735157,\n",
       "  -0.11615115404129028,\n",
       "  -0.059782180935144424,\n",
       "  -0.01737978681921959,\n",
       "  -0.007690821774303913,\n",
       "  0.024973243474960327,\n",
       "  0.026004672050476074,\n",
       "  0.0809437707066536,\n",
       "  -0.059337738901376724,\n",
       "  -0.0075204987078905106,\n",
       "  0.027481811121106148,\n",
       "  0.038826897740364075,\n",
       "  -0.11089698225259781,\n",
       "  -0.006785144563764334,\n",
       "  0.004839103668928146,\n",
       "  -0.004666487220674753,\n",
       "  0.008427843451499939,\n",
       "  0.04619888588786125,\n",
       "  -0.011439335532486439,\n",
       "  0.029878733679652214,\n",
       "  -0.025671981275081635,\n",
       "  0.010230365209281445,\n",
       "  -0.0038086315616965294,\n",
       "  0.006736095063388348,\n",
       "  -0.001731568481773138,\n",
       "  -0.09755632281303406,\n",
       "  0.09083202481269836,\n",
       "  -0.04362942650914192,\n",
       "  -0.09166207909584045,\n",
       "  -0.014916818588972092,\n",
       "  0.10621491819620132,\n",
       "  -0.049662865698337555,\n",
       "  0.02022136189043522,\n",
       "  0.004002842120826244,\n",
       "  -0.09189103543758392,\n",
       "  0.09262852370738983,\n",
       "  0.05286824330687523,\n",
       "  -0.0593055859208107,\n",
       "  0.002769412938505411,\n",
       "  0.0338687039911747,\n",
       "  0.031343646347522736,\n",
       "  0.06359502673149109,\n",
       "  -0.0028420262970030308,\n",
       "  -0.12724517285823822,\n",
       "  0.10943151265382767,\n",
       "  -0.07489942759275436,\n",
       "  -0.06997665017843246,\n",
       "  -0.011129527352750301,\n",
       "  -0.06836333870887756,\n",
       "  0.04393295571208,\n",
       "  0.010025662370026112,\n",
       "  -0.016091380268335342,\n",
       "  -0.04449319466948509,\n",
       "  -0.027748391032218933,\n",
       "  -0.02353910356760025,\n",
       "  0.1023351326584816,\n",
       "  0.020827792584896088,\n",
       "  0.03285767510533333,\n",
       "  -0.01580728217959404],\n",
       " [0.006124874111264944,\n",
       "  -0.044015392661094666,\n",
       "  -0.02724749781191349,\n",
       "  -0.021531840786337852,\n",
       "  0.01296948455274105,\n",
       "  -0.014493982307612896,\n",
       "  0.005003905389457941,\n",
       "  0.02047600969672203,\n",
       "  -0.01712755300104618,\n",
       "  -0.007166686002165079,\n",
       "  0.03704346716403961,\n",
       "  0.03428719565272331,\n",
       "  -0.012275791727006435,\n",
       "  0.04350435361266136,\n",
       "  -0.0406755767762661,\n",
       "  0.012178248725831509,\n",
       "  0.0648709386587143,\n",
       "  -0.004954841453582048,\n",
       "  -0.024488553404808044,\n",
       "  -0.0060363332740962505,\n",
       "  0.002505880780518055,\n",
       "  -0.0063535068184137344,\n",
       "  0.014190705493092537,\n",
       "  0.016128195449709892,\n",
       "  0.0030788055155426264,\n",
       "  0.020751502364873886,\n",
       "  -0.006073924712836742,\n",
       "  0.007088444661349058,\n",
       "  0.018376709893345833,\n",
       "  -0.033587682992219925,\n",
       "  0.02420203387737274,\n",
       "  -0.034619685262441635,\n",
       "  0.005687518045306206,\n",
       "  0.04938792809844017,\n",
       "  0.01567542739212513,\n",
       "  0.054155249148607254,\n",
       "  0.004338783212006092,\n",
       "  -0.0069908699952065945,\n",
       "  0.04337583854794502,\n",
       "  0.01112518459558487,\n",
       "  -0.011192342266440392,\n",
       "  0.018436584621667862,\n",
       "  0.01813121698796749,\n",
       "  0.009924438782036304,\n",
       "  0.04236112907528877,\n",
       "  0.06819155067205429,\n",
       "  -0.018734324723482132,\n",
       "  0.021937740966677666,\n",
       "  0.04311835393309593,\n",
       "  0.01908027194440365,\n",
       "  0.0208435095846653,\n",
       "  0.13918714225292206,\n",
       "  0.012898660264909267,\n",
       "  -0.03293972089886665,\n",
       "  0.022214965894818306,\n",
       "  0.04706043377518654,\n",
       "  0.003708690870553255,\n",
       "  -0.01932201161980629,\n",
       "  -0.03275294974446297,\n",
       "  0.04312349483370781,\n",
       "  0.028529155999422073,\n",
       "  0.05853728950023651,\n",
       "  -0.02629191055893898,\n",
       "  0.03151862695813179,\n",
       "  0.0013880978804081678,\n",
       "  -0.00029721111059188843,\n",
       "  -0.022655552253127098,\n",
       "  0.010938292369246483,\n",
       "  -0.0237279050052166,\n",
       "  -0.020843641832470894,\n",
       "  -0.0482790544629097,\n",
       "  -0.02273397520184517,\n",
       "  0.0148561280220747,\n",
       "  -0.0031830635853111744,\n",
       "  0.04212946072220802,\n",
       "  0.030664335936307907,\n",
       "  0.05354322865605354,\n",
       "  -0.02520047128200531,\n",
       "  -0.012525681406259537,\n",
       "  -0.018349766731262207,\n",
       "  0.037351012229919434,\n",
       "  -0.06876451522111893,\n",
       "  0.0066469581797719,\n",
       "  -0.011465716175734997,\n",
       "  -0.00283892173320055,\n",
       "  0.017372548580169678,\n",
       "  0.022384556010365486,\n",
       "  0.013796568848192692,\n",
       "  0.031123315915465355,\n",
       "  0.014194751158356667,\n",
       "  0.010832036845386028,\n",
       "  0.008188177831470966,\n",
       "  0.014075957238674164,\n",
       "  -0.014124413952231407,\n",
       "  -0.018955476582050323,\n",
       "  0.041579894721508026,\n",
       "  -0.014714615419507027,\n",
       "  -0.023227335885167122,\n",
       "  -0.0008073605713434517,\n",
       "  0.0378325916826725,\n",
       "  -0.03574848175048828,\n",
       "  -0.02916806936264038,\n",
       "  0.016816318035125732,\n",
       "  -0.015900203958153725,\n",
       "  0.06090105324983597,\n",
       "  0.0015322250546887517,\n",
       "  -0.04449097067117691,\n",
       "  0.006582066882401705,\n",
       "  -0.002558012492954731,\n",
       "  -0.010156561620533466,\n",
       "  0.05628949776291847,\n",
       "  0.02088192291557789,\n",
       "  -0.06313982605934143,\n",
       "  0.029360920190811157,\n",
       "  -0.05740351229906082,\n",
       "  -0.036392804235219955,\n",
       "  0.008496017195284367,\n",
       "  -0.004955768119543791,\n",
       "  0.030704131349921227,\n",
       "  0.02046266570687294,\n",
       "  0.008722103200852871,\n",
       "  -0.03798945993185043,\n",
       "  -0.03309211879968643,\n",
       "  -0.01733512431383133,\n",
       "  0.03457558527588844,\n",
       "  0.01632762886583805,\n",
       "  -0.003985623363405466,\n",
       "  0.009028955362737179],\n",
       " [0.03961247205734253,\n",
       "  -0.04217762127518654,\n",
       "  -0.04189148545265198,\n",
       "  -0.015189539641141891,\n",
       "  -0.002906753681600094,\n",
       "  -0.04595181345939636,\n",
       "  -0.01672104187309742,\n",
       "  0.037686076015233994,\n",
       "  -0.030964400619268417,\n",
       "  -0.0633407011628151,\n",
       "  0.08221422880887985,\n",
       "  0.05318563058972359,\n",
       "  -0.06716961413621902,\n",
       "  0.03305991739034653,\n",
       "  -0.10336185246706009,\n",
       "  0.024190030992031097,\n",
       "  0.07664991915225983,\n",
       "  -0.013005641289055347,\n",
       "  -0.05873415619134903,\n",
       "  -0.0010248865000903606,\n",
       "  -0.002058186335489154,\n",
       "  -0.0119931036606431,\n",
       "  0.02618296444416046,\n",
       "  0.02587343379855156,\n",
       "  0.014745080843567848,\n",
       "  0.005605808459222317,\n",
       "  -0.018971819430589676,\n",
       "  0.006628404371440411,\n",
       "  0.0015581928892061114,\n",
       "  -0.06041097268462181,\n",
       "  0.038647379726171494,\n",
       "  -0.04928860813379288,\n",
       "  0.010421528480947018,\n",
       "  0.04718497768044472,\n",
       "  0.014037254266440868,\n",
       "  0.06435630470514297,\n",
       "  0.04345056042075157,\n",
       "  0.029963433742523193,\n",
       "  0.05067269504070282,\n",
       "  0.0006933701224625111,\n",
       "  -0.03798741102218628,\n",
       "  0.048068322241306305,\n",
       "  0.010194252245128155,\n",
       "  0.020459597930312157,\n",
       "  0.04652988538146019,\n",
       "  0.10565381497144699,\n",
       "  -0.03162581846117973,\n",
       "  0.03751855716109276,\n",
       "  0.046666719019412994,\n",
       "  0.029367176815867424,\n",
       "  0.0012133679119870067,\n",
       "  0.2460549920797348,\n",
       "  0.019968001171946526,\n",
       "  -0.024930864572525024,\n",
       "  0.00828432198613882,\n",
       "  0.07280158996582031,\n",
       "  -0.011639390140771866,\n",
       "  -0.011350567452609539,\n",
       "  -0.08594732731580734,\n",
       "  0.08252697438001633,\n",
       "  0.03976180776953697,\n",
       "  0.02878514677286148,\n",
       "  -0.019442180171608925,\n",
       "  0.027804456651210785,\n",
       "  0.030633851885795593,\n",
       "  -0.03225761279463768,\n",
       "  -0.032966528087854385,\n",
       "  0.023353954777121544,\n",
       "  -0.015160421840846539,\n",
       "  -0.04881271347403526,\n",
       "  -0.09877283126115799,\n",
       "  -0.0498945377767086,\n",
       "  -0.008154709823429585,\n",
       "  -0.005530056543648243,\n",
       "  0.02803841233253479,\n",
       "  0.0272342711687088,\n",
       "  0.07281546294689178,\n",
       "  -0.050218041986227036,\n",
       "  -0.00820120144635439,\n",
       "  0.016297362744808197,\n",
       "  0.03948703780770302,\n",
       "  -0.09931103885173798,\n",
       "  -0.0015031335642561316,\n",
       "  0.0005160472937859595,\n",
       "  -0.0041403998620808125,\n",
       "  0.010540524497628212,\n",
       "  0.03906957805156708,\n",
       "  -0.005927982274442911,\n",
       "  0.029473286122083664,\n",
       "  -0.014592181891202927,\n",
       "  0.010619877837598324,\n",
       "  -0.0008020874811336398,\n",
       "  0.0074118017219007015,\n",
       "  -0.004883735906332731,\n",
       "  -0.07977062463760376,\n",
       "  0.07795459777116776,\n",
       "  -0.03602343425154686,\n",
       "  -0.07493907958269119,\n",
       "  -0.012422395870089531,\n",
       "  0.08986592292785645,\n",
       "  -0.046846553683280945,\n",
       "  0.007604283280670643,\n",
       "  0.0074225785210728645,\n",
       "  -0.07299620658159256,\n",
       "  0.08501581102609634,\n",
       "  0.04072422906756401,\n",
       "  -0.056355372071266174,\n",
       "  0.004269370809197426,\n",
       "  0.025341911241412163,\n",
       "  0.02163889817893505,\n",
       "  0.06173286214470863,\n",
       "  0.004601148422807455,\n",
       "  -0.11151184141635895,\n",
       "  0.09098601341247559,\n",
       "  -0.07043036073446274,\n",
       "  -0.06236052140593529,\n",
       "  -0.007038470823317766,\n",
       "  -0.053314078599214554,\n",
       "  0.04081029072403908,\n",
       "  0.012544653378427029,\n",
       "  -0.01095490250736475,\n",
       "  -0.04313816502690315,\n",
       "  -0.028593596071004868,\n",
       "  -0.022111844271421432,\n",
       "  0.08651416003704071,\n",
       "  0.021289711818099022,\n",
       "  0.023988867178559303,\n",
       "  -0.009753096848726273],\n",
       " [0.035943370312452316,\n",
       "  -0.044866323471069336,\n",
       "  -0.03660896047949791,\n",
       "  -0.01759365387260914,\n",
       "  -0.0023557532113045454,\n",
       "  -0.03916445001959801,\n",
       "  -0.012565366923809052,\n",
       "  0.03402310982346535,\n",
       "  -0.026040563359856606,\n",
       "  -0.05452612042427063,\n",
       "  0.07514774054288864,\n",
       "  0.04854052886366844,\n",
       "  -0.057959046214818954,\n",
       "  0.03315788134932518,\n",
       "  -0.09127704054117203,\n",
       "  0.020813986659049988,\n",
       "  0.0725160464644432,\n",
       "  -0.010047399438917637,\n",
       "  -0.052778709679841995,\n",
       "  -0.0004146662831772119,\n",
       "  -0.0015200836351141334,\n",
       "  -0.01162668876349926,\n",
       "  0.0251785758882761,\n",
       "  0.02210293337702751,\n",
       "  0.011299509555101395,\n",
       "  0.005929884500801563,\n",
       "  -0.01629505306482315,\n",
       "  0.005964283831417561,\n",
       "  0.0025005682837218046,\n",
       "  -0.05711043253540993,\n",
       "  0.039968471974134445,\n",
       "  -0.047228217124938965,\n",
       "  0.007073224987834692,\n",
       "  0.04493251442909241,\n",
       "  0.013925055973231792,\n",
       "  0.06324726343154907,\n",
       "  0.03552635386586189,\n",
       "  0.023881545290350914,\n",
       "  0.05006489157676697,\n",
       "  0.00011737856402760372,\n",
       "  -0.034383200109004974,\n",
       "  0.04547189176082611,\n",
       "  0.012709262780845165,\n",
       "  0.019419671967625618,\n",
       "  0.04555805027484894,\n",
       "  0.098884217441082,\n",
       "  -0.02694634534418583,\n",
       "  0.035864148288965225,\n",
       "  0.04958610609173775,\n",
       "  0.02646925486624241,\n",
       "  0.005094646476209164,\n",
       "  0.22767972946166992,\n",
       "  0.02138761430978775,\n",
       "  -0.026707923039793968,\n",
       "  0.011216530576348305,\n",
       "  0.06823531538248062,\n",
       "  -0.00830816850066185,\n",
       "  -0.011851208284497261,\n",
       "  -0.07788311690092087,\n",
       "  0.0769035741686821,\n",
       "  0.036683063954114914,\n",
       "  0.03277532756328583,\n",
       "  -0.0206010565161705,\n",
       "  0.030900942161679268,\n",
       "  0.026325466111302376,\n",
       "  -0.02728177420794964,\n",
       "  -0.03387438505887985,\n",
       "  0.022760409861803055,\n",
       "  -0.016526665538549423,\n",
       "  -0.04573286697268486,\n",
       "  -0.08986055105924606,\n",
       "  -0.04444361478090286,\n",
       "  -0.006313562858849764,\n",
       "  -0.007804472465068102,\n",
       "  0.030185094103217125,\n",
       "  0.027688411995768547,\n",
       "  0.0703040212392807,\n",
       "  -0.04666200652718544,\n",
       "  -0.011202835477888584,\n",
       "  0.011387862265110016,\n",
       "  0.038136426359415054,\n",
       "  -0.09486935287714005,\n",
       "  -0.0007135699852369726,\n",
       "  0.001356263062916696,\n",
       "  -0.004336345940828323,\n",
       "  0.011236763559281826,\n",
       "  0.03578683361411095,\n",
       "  -0.0016462334897369146,\n",
       "  0.031348906457424164,\n",
       "  -0.011096151545643806,\n",
       "  0.00923208799213171,\n",
       "  0.00010975929035339504,\n",
       "  0.009499188512563705,\n",
       "  -0.006187893450260162,\n",
       "  -0.06875894218683243,\n",
       "  0.07403060048818588,\n",
       "  -0.03310657665133476,\n",
       "  -0.06400848925113678,\n",
       "  -0.011939824558794498,\n",
       "  0.08146921545267105,\n",
       "  -0.044326525181531906,\n",
       "  0.0015426804311573505,\n",
       "  0.00839960016310215,\n",
       "  -0.06423354893922806,\n",
       "  0.08057713508605957,\n",
       "  0.033128522336483,\n",
       "  -0.05275743454694748,\n",
       "  0.003932761959731579,\n",
       "  0.02123330347239971,\n",
       "  0.014921887777745724,\n",
       "  0.06040027365088463,\n",
       "  0.007347813807427883,\n",
       "  -0.10504534095525742,\n",
       "  0.08156576752662659,\n",
       "  -0.0698949545621872,\n",
       "  -0.057267967611551285,\n",
       "  -0.0019249406177550554,\n",
       "  -0.047318339347839355,\n",
       "  0.04042326658964157,\n",
       "  0.012901722453534603,\n",
       "  -0.007417572662234306,\n",
       "  -0.04237596318125725,\n",
       "  -0.030839858576655388,\n",
       "  -0.02163400501012802,\n",
       "  0.07901439815759659,\n",
       "  0.017850063741207123,\n",
       "  0.02064499631524086,\n",
       "  -0.00645027868449688],\n",
       " [0.04413307458162308,\n",
       "  -0.04376300796866417,\n",
       "  -0.044283803552389145,\n",
       "  -0.015497824177145958,\n",
       "  -0.005978449247777462,\n",
       "  -0.049849316477775574,\n",
       "  -0.021854091435670853,\n",
       "  0.038613200187683105,\n",
       "  -0.03378988057374954,\n",
       "  -0.07120216637849808,\n",
       "  0.08630876243114471,\n",
       "  0.05597107112407684,\n",
       "  -0.07554730027914047,\n",
       "  0.03187604993581772,\n",
       "  -0.1120157241821289,\n",
       "  0.02479473501443863,\n",
       "  0.07663454860448837,\n",
       "  -0.014695280231535435,\n",
       "  -0.06280713528394699,\n",
       "  0.0002213609404861927,\n",
       "  -0.0018121461616829038,\n",
       "  -0.014055325649678707,\n",
       "  0.027878589928150177,\n",
       "  0.02553832158446312,\n",
       "  0.016508307307958603,\n",
       "  0.004104038700461388,\n",
       "  -0.021404488012194633,\n",
       "  0.006925404071807861,\n",
       "  -0.0007369692320935428,\n",
       "  -0.06349809467792511,\n",
       "  0.03787406161427498,\n",
       "  -0.04996849596500397,\n",
       "  0.009604454040527344,\n",
       "  0.04766872152686119,\n",
       "  0.014145726338028908,\n",
       "  0.06320547312498093,\n",
       "  0.04927000403404236,\n",
       "  0.03330954536795616,\n",
       "  0.052739210426807404,\n",
       "  -0.002159436931833625,\n",
       "  -0.0399646982550621,\n",
       "  0.051867883652448654,\n",
       "  0.008983634412288666,\n",
       "  0.020617686212062836,\n",
       "  0.04759081080555916,\n",
       "  0.109002985060215,\n",
       "  -0.033082377165555954,\n",
       "  0.04046705737709999,\n",
       "  0.04735684022307396,\n",
       "  0.03059268370270729,\n",
       "  -0.001661628601141274,\n",
       "  0.25928258895874023,\n",
       "  0.02189498394727707,\n",
       "  -0.022677065804600716,\n",
       "  0.008824474178254604,\n",
       "  0.0776410922408104,\n",
       "  -0.013172416016459465,\n",
       "  -0.011090033687651157,\n",
       "  -0.09333666414022446,\n",
       "  0.08725818246603012,\n",
       "  0.040675994008779526,\n",
       "  0.02637181058526039,\n",
       "  -0.020410191267728806,\n",
       "  0.026936251670122147,\n",
       "  0.03165150061249733,\n",
       "  -0.03543594852089882,\n",
       "  -0.03307560086250305,\n",
       "  0.02422335371375084,\n",
       "  -0.014042004011571407,\n",
       "  -0.05097898840904236,\n",
       "  -0.10526718199253082,\n",
       "  -0.05436927080154419,\n",
       "  -0.010981437750160694,\n",
       "  -0.004753578919917345,\n",
       "  0.027440084144473076,\n",
       "  0.026502637192606926,\n",
       "  0.0757831409573555,\n",
       "  -0.05359790846705437,\n",
       "  -0.00798716675490141,\n",
       "  0.019700469449162483,\n",
       "  0.04006865620613098,\n",
       "  -0.10129353404045105,\n",
       "  -0.0037683341652154922,\n",
       "  0.0020970567129552364,\n",
       "  -0.004757952410727739,\n",
       "  0.008162111975252628,\n",
       "  0.042152147740125656,\n",
       "  -0.007263092324137688,\n",
       "  0.028699684888124466,\n",
       "  -0.01749941147863865,\n",
       "  0.010265626944601536,\n",
       "  -0.0014389154966920614,\n",
       "  0.00680195027962327,\n",
       "  -0.004569098353385925,\n",
       "  -0.0854836031794548,\n",
       "  0.08063828200101852,\n",
       "  -0.03768200799822807,\n",
       "  -0.08216001093387604,\n",
       "  -0.01215211022645235,\n",
       "  0.09524612873792648,\n",
       "  -0.047149207442998886,\n",
       "  0.0114076416939497,\n",
       "  0.006457423325628042,\n",
       "  -0.07897810637950897,\n",
       "  0.08675648272037506,\n",
       "  0.045811522752046585,\n",
       "  -0.05710532143712044,\n",
       "  0.00390738807618618,\n",
       "  0.028395576402544975,\n",
       "  0.026440000161528587,\n",
       "  0.06290853023529053,\n",
       "  0.002569015836343169,\n",
       "  -0.11556056886911392,\n",
       "  0.09813302755355835,\n",
       "  -0.07082106173038483,\n",
       "  -0.06511899083852768,\n",
       "  -0.009682574309408665,\n",
       "  -0.057978399097919464,\n",
       "  0.04127417504787445,\n",
       "  0.011313408613204956,\n",
       "  -0.012427322566509247,\n",
       "  -0.04523087292909622,\n",
       "  -0.02850845828652382,\n",
       "  -0.021716324612498283,\n",
       "  0.09227602183818817,\n",
       "  0.021573735401034355,\n",
       "  0.026013396680355072,\n",
       "  -0.011260215193033218],\n",
       " [0.024310801178216934,\n",
       "  -0.04290356859564781,\n",
       "  -0.03202970698475838,\n",
       "  -0.01928437501192093,\n",
       "  0.005530312657356262,\n",
       "  -0.029147855937480927,\n",
       "  -0.004211688879877329,\n",
       "  0.02875528298318386,\n",
       "  -0.020734919235110283,\n",
       "  -0.03558032959699631,\n",
       "  0.06014018505811691,\n",
       "  0.041164372116327286,\n",
       "  -0.03806998208165169,\n",
       "  0.03653594106435776,\n",
       "  -0.06948675960302353,\n",
       "  0.016573648899793625,\n",
       "  0.06867847591638565,\n",
       "  -0.008247018791735172,\n",
       "  -0.040639013051986694,\n",
       "  -0.0037503871135413647,\n",
       "  -0.0012778897071257234,\n",
       "  -0.00982385128736496,\n",
       "  0.02082122303545475,\n",
       "  0.02016143500804901,\n",
       "  0.0071512931026518345,\n",
       "  0.010867826640605927,\n",
       "  -0.010583494789898396,\n",
       "  0.005323885940015316,\n",
       "  0.0073143066838383675,\n",
       "  -0.0470576286315918,\n",
       "  0.03627588599920273,\n",
       "  -0.04142564907670021,\n",
       "  0.005898690316826105,\n",
       "  0.04294492304325104,\n",
       "  0.012601636350154877,\n",
       "  0.06145118549466133,\n",
       "  0.02061651460826397,\n",
       "  0.01137913390994072,\n",
       "  0.04782074689865112,\n",
       "  0.005668426398187876,\n",
       "  -0.026464400812983513,\n",
       "  0.0337778702378273,\n",
       "  0.017806675285100937,\n",
       "  0.015033157542347908,\n",
       "  0.043151456862688065,\n",
       "  0.08602288365364075,\n",
       "  -0.022772498428821564,\n",
       "  0.0297204852104187,\n",
       "  0.048530369997024536,\n",
       "  0.021693821996450424,\n",
       "  0.011108873412013054,\n",
       "  0.19072990119457245,\n",
       "  0.01800559088587761,\n",
       "  -0.031211962923407555,\n",
       "  0.014206526800990105,\n",
       "  0.05785028636455536,\n",
       "  -0.0032799693290144205,\n",
       "  -0.01470878068357706,\n",
       "  -0.057855863124132156,\n",
       "  0.06428958475589752,\n",
       "  0.03272733464837074,\n",
       "  0.03965790569782257,\n",
       "  -0.02166781760752201,\n",
       "  0.03160054236650467,\n",
       "  0.018668901175260544,\n",
       "  -0.017369668930768967,\n",
       "  -0.030116982758045197,\n",
       "  0.017947420477867126,\n",
       "  -0.01941658742725849,\n",
       "  -0.037491168826818466,\n",
       "  -0.07336095720529556,\n",
       "  -0.03641252592206001,\n",
       "  0.003227479290217161,\n",
       "  -0.005375865381211042,\n",
       "  0.03527713194489479,\n",
       "  0.02942553162574768,\n",
       "  0.06271538138389587,\n",
       "  -0.04023277014493942,\n",
       "  -0.01084396056830883,\n",
       "  -0.0005751153803430498,\n",
       "  0.040042899549007416,\n",
       "  -0.08329825848340988,\n",
       "  0.003162969835102558,\n",
       "  -0.0036676034796983004,\n",
       "  -0.002284070011228323,\n",
       "  0.013426283374428749,\n",
       "  0.02777426317334175,\n",
       "  0.0026630801148712635,\n",
       "  0.03237931430339813,\n",
       "  -0.0008943306165747344,\n",
       "  0.010965317487716675,\n",
       "  0.0035392423160374165,\n",
       "  0.010351153090596199,\n",
       "  -0.008806807920336723,\n",
       "  -0.0479607917368412,\n",
       "  0.06215696409344673,\n",
       "  -0.02616705372929573,\n",
       "  -0.044572487473487854,\n",
       "  -0.008493148721754551,\n",
       "  0.06416483968496323,\n",
       "  -0.042406994849443436,\n",
       "  -0.011371790431439877,\n",
       "  0.0123906210064888,\n",
       "  -0.04372859001159668,\n",
       "  0.07227706909179688,\n",
       "  0.020595988258719444,\n",
       "  -0.04876500368118286,\n",
       "  0.0048469738103449345,\n",
       "  0.012367436662316322,\n",
       "  0.0036047284957021475,\n",
       "  0.05843304097652435,\n",
       "  0.013779725879430771,\n",
       "  -0.08955807983875275,\n",
       "  0.0626484602689743,\n",
       "  -0.06547462940216064,\n",
       "  -0.04851578548550606,\n",
       "  0.0043078018352389336,\n",
       "  -0.031715620309114456,\n",
       "  0.03700973093509674,\n",
       "  0.016661934554576874,\n",
       "  -0.0008600117289461195,\n",
       "  -0.040945980697870255,\n",
       "  -0.030546415597200394,\n",
       "  -0.02039424702525139,\n",
       "  0.061125364154577255,\n",
       "  0.017077073454856873,\n",
       "  0.010607823729515076,\n",
       "  -0.0016151081072166562],\n",
       " [0.047309234738349915,\n",
       "  -0.04294981434941292,\n",
       "  -0.04447101056575775,\n",
       "  -0.014796925708651543,\n",
       "  -0.006571982521563768,\n",
       "  -0.051896654069423676,\n",
       "  -0.02207842282950878,\n",
       "  0.04004383832216263,\n",
       "  -0.03534062206745148,\n",
       "  -0.0750175416469574,\n",
       "  0.09001478552818298,\n",
       "  0.05659239739179611,\n",
       "  -0.0786614716053009,\n",
       "  0.030406353995203972,\n",
       "  -0.11613776534795761,\n",
       "  0.026541993021965027,\n",
       "  0.07873900234699249,\n",
       "  -0.0154471630230546,\n",
       "  -0.0668816938996315,\n",
       "  0.0012137779267504811,\n",
       "  -0.001955656101927161,\n",
       "  -0.013514313846826553,\n",
       "  0.028620226308703423,\n",
       "  0.027673833072185516,\n",
       "  0.016149668022990227,\n",
       "  0.002238955581560731,\n",
       "  -0.022215889766812325,\n",
       "  0.0077468231320381165,\n",
       "  -0.0019440485630184412,\n",
       "  -0.06483113020658493,\n",
       "  0.041244469583034515,\n",
       "  -0.052412547171115875,\n",
       "  0.010469826869666576,\n",
       "  0.048489879816770554,\n",
       "  0.014896207489073277,\n",
       "  0.06404358148574829,\n",
       "  0.05135153606534004,\n",
       "  0.037610821425914764,\n",
       "  0.052143681794404984,\n",
       "  -0.003575474489480257,\n",
       "  -0.04257924109697342,\n",
       "  0.05491867661476135,\n",
       "  0.009339777752757072,\n",
       "  0.021811623126268387,\n",
       "  0.047934725880622864,\n",
       "  0.11131724715232849,\n",
       "  -0.034384239464998245,\n",
       "  0.041620638221502304,\n",
       "  0.0477716438472271,\n",
       "  0.03258509188890457,\n",
       "  -0.003731718985363841,\n",
       "  0.26670241355895996,\n",
       "  0.023441113531589508,\n",
       "  -0.021903906017541885,\n",
       "  0.005800867453217506,\n",
       "  0.08020372688770294,\n",
       "  -0.012800144031643867,\n",
       "  -0.010544789023697376,\n",
       "  -0.09725414961576462,\n",
       "  0.090037040412426,\n",
       "  0.04060295969247818,\n",
       "  0.023869404569268227,\n",
       "  -0.018346309661865234,\n",
       "  0.02749859169125557,\n",
       "  0.03574294596910477,\n",
       "  -0.03952624276280403,\n",
       "  -0.0348820723593235,\n",
       "  0.027131181210279465,\n",
       "  -0.012535319663584232,\n",
       "  -0.05370825156569481,\n",
       "  -0.10929836332798004,\n",
       "  -0.0559096522629261,\n",
       "  -0.013753391802310944,\n",
       "  -0.0055421204306185246,\n",
       "  0.025938455015420914,\n",
       "  0.025643637403845787,\n",
       "  0.0775371566414833,\n",
       "  -0.05530121177434921,\n",
       "  -0.008162546902894974,\n",
       "  0.02255382016301155,\n",
       "  0.03973656892776489,\n",
       "  -0.10529877990484238,\n",
       "  -0.003999780863523483,\n",
       "  0.0037647592835128307,\n",
       "  -0.005928372964262962,\n",
       "  0.00826303381472826,\n",
       "  0.04373374953866005,\n",
       "  -0.008326553739607334,\n",
       "  0.028805524110794067,\n",
       "  -0.01978377439081669,\n",
       "  0.010554956272244453,\n",
       "  -0.0032246748451143503,\n",
       "  0.005470804870128632,\n",
       "  -0.0030249906703829765,\n",
       "  -0.08967275172472,\n",
       "  0.08446138352155685,\n",
       "  -0.03891821578145027,\n",
       "  -0.08641017973423004,\n",
       "  -0.013531604781746864,\n",
       "  0.09988854080438614,\n",
       "  -0.04868654906749725,\n",
       "  0.015263224951922894,\n",
       "  0.004244971089065075,\n",
       "  -0.08526881039142609,\n",
       "  0.0885668471455574,\n",
       "  0.04743924364447594,\n",
       "  -0.058418963104486465,\n",
       "  0.002709058579057455,\n",
       "  0.030369214713573456,\n",
       "  0.027577530592679977,\n",
       "  0.06342264264822006,\n",
       "  0.0007360129966400564,\n",
       "  -0.1202116310596466,\n",
       "  0.10111475735902786,\n",
       "  -0.07293503731489182,\n",
       "  -0.06668323278427124,\n",
       "  -0.010833676904439926,\n",
       "  -0.062171995639801025,\n",
       "  0.04239119216799736,\n",
       "  0.010459303855895996,\n",
       "  -0.015874003991484642,\n",
       "  -0.04549624025821686,\n",
       "  -0.029778793454170227,\n",
       "  -0.02215403877198696,\n",
       "  0.0968819111585617,\n",
       "  0.021988017484545708,\n",
       "  0.02898881584405899,\n",
       "  -0.012293841689825058],\n",
       " [0.017423130571842194,\n",
       "  -0.04565354809165001,\n",
       "  -0.027821607887744904,\n",
       "  -0.02040877565741539,\n",
       "  0.007576867006719112,\n",
       "  -0.02118544839322567,\n",
       "  0.0018243110971525311,\n",
       "  0.023476773872971535,\n",
       "  -0.015959691256284714,\n",
       "  -0.020909564569592476,\n",
       "  0.049943242222070694,\n",
       "  0.035253673791885376,\n",
       "  -0.024728577584028244,\n",
       "  0.040515266358852386,\n",
       "  -0.05310535430908203,\n",
       "  0.014602440409362316,\n",
       "  0.0646737664937973,\n",
       "  -0.004116828087717295,\n",
       "  -0.030103689059615135,\n",
       "  -0.004797703120857477,\n",
       "  0.000646806787699461,\n",
       "  -0.008115742355585098,\n",
       "  0.01884426549077034,\n",
       "  0.017151936888694763,\n",
       "  0.003280606819316745,\n",
       "  0.014381599612534046,\n",
       "  -0.008133560419082642,\n",
       "  0.006030465941876173,\n",
       "  0.011494634672999382,\n",
       "  -0.04190249368548393,\n",
       "  0.035425055772066116,\n",
       "  -0.03820836544036865,\n",
       "  0.004486893769353628,\n",
       "  0.043697014451026917,\n",
       "  0.014195030555129051,\n",
       "  0.05938384309411049,\n",
       "  0.010097295045852661,\n",
       "  0.0030483785085380077,\n",
       "  0.04586034268140793,\n",
       "  0.007079231087118387,\n",
       "  -0.018503325060009956,\n",
       "  0.027736535295844078,\n",
       "  0.0182312224060297,\n",
       "  0.013978196308016777,\n",
       "  0.04249696806073189,\n",
       "  0.07690160721540451,\n",
       "  -0.018453992903232574,\n",
       "  0.026162520051002502,\n",
       "  0.04724361002445221,\n",
       "  0.01996610313653946,\n",
       "  0.016405174508690834,\n",
       "  0.16176670789718628,\n",
       "  0.01637742854654789,\n",
       "  -0.033039677888154984,\n",
       "  0.018532030284404755,\n",
       "  0.052286297082901,\n",
       "  0.0017272932454943657,\n",
       "  -0.017018010839819908,\n",
       "  -0.04631265997886658,\n",
       "  0.05478920787572861,\n",
       "  0.030246226117014885,\n",
       "  0.047459907829761505,\n",
       "  -0.022727955132722855,\n",
       "  0.03355882316827774,\n",
       "  0.013166047632694244,\n",
       "  -0.009814156219363213,\n",
       "  -0.028583679348230362,\n",
       "  0.01683466136455536,\n",
       "  -0.021692082285881042,\n",
       "  -0.03175025433301926,\n",
       "  -0.05854065343737602,\n",
       "  -0.027736082673072815,\n",
       "  0.008229583501815796,\n",
       "  -0.007422735448926687,\n",
       "  0.0379122756421566,\n",
       "  0.029855897650122643,\n",
       "  0.057760801166296005,\n",
       "  -0.03300176560878754,\n",
       "  -0.013540121726691723,\n",
       "  -0.008619382977485657,\n",
       "  0.038877934217453,\n",
       "  -0.07680805027484894,\n",
       "  0.006157133262604475,\n",
       "  -0.004952282179147005,\n",
       "  -0.0032731930259615183,\n",
       "  0.015034450218081474,\n",
       "  0.02415657788515091,\n",
       "  0.009594960138201714,\n",
       "  0.03368258476257324,\n",
       "  0.005234548822045326,\n",
       "  0.009722735732793808,\n",
       "  0.004734943620860577,\n",
       "  0.01100249495357275,\n",
       "  -0.011253707110881805,\n",
       "  -0.03180484473705292,\n",
       "  0.05453687533736229,\n",
       "  -0.02117646485567093,\n",
       "  -0.029557790607213974,\n",
       "  -0.00704504270106554,\n",
       "  0.04981759935617447,\n",
       "  -0.038883503526449203,\n",
       "  -0.019098857417702675,\n",
       "  0.014112881384789944,\n",
       "  -0.03150836378335953,\n",
       "  0.06640935689210892,\n",
       "  0.011872807517647743,\n",
       "  -0.04560470208525658,\n",
       "  0.006126085761934519,\n",
       "  0.006392017472535372,\n",
       "  -0.005835628602653742,\n",
       "  0.05566238611936569,\n",
       "  0.01827782206237316,\n",
       "  -0.07715009897947311,\n",
       "  0.048239026218652725,\n",
       "  -0.06400256603956223,\n",
       "  -0.04143757000565529,\n",
       "  0.009545546025037766,\n",
       "  -0.019978854805231094,\n",
       "  0.034969981759786606,\n",
       "  0.016120392829179764,\n",
       "  0.003148420946672559,\n",
       "  -0.03956229239702225,\n",
       "  -0.033394716680049896,\n",
       "  -0.020281938835978508,\n",
       "  0.048239123076200485,\n",
       "  0.016296591609716415,\n",
       "  0.00398073997348547,\n",
       "  0.0024542768951505423],\n",
       " [0.04712657257914543,\n",
       "  -0.04411846399307251,\n",
       "  -0.04542577266693115,\n",
       "  -0.014875363558530807,\n",
       "  -0.007602653931826353,\n",
       "  -0.04927220940589905,\n",
       "  -0.022571410983800888,\n",
       "  0.039660170674324036,\n",
       "  -0.03346005454659462,\n",
       "  -0.07500139623880386,\n",
       "  0.08996766805648804,\n",
       "  0.05770469829440117,\n",
       "  -0.07958157360553741,\n",
       "  0.030162464827299118,\n",
       "  -0.11560423672199249,\n",
       "  0.02581421285867691,\n",
       "  0.07769665122032166,\n",
       "  -0.01589679904282093,\n",
       "  -0.06745181977748871,\n",
       "  0.0008389872964471579,\n",
       "  -0.0021297147031873465,\n",
       "  -0.013879304751753807,\n",
       "  0.028855163604021072,\n",
       "  0.02694716490805149,\n",
       "  0.017703594639897346,\n",
       "  0.0032265642657876015,\n",
       "  -0.022335611283779144,\n",
       "  0.006991716101765633,\n",
       "  -0.0021892383228987455,\n",
       "  -0.06594042479991913,\n",
       "  0.039504434913396835,\n",
       "  -0.05178988724946976,\n",
       "  0.011031018570065498,\n",
       "  0.04859430342912674,\n",
       "  0.015071425586938858,\n",
       "  0.06363720446825027,\n",
       "  0.05105869472026825,\n",
       "  0.03559548780322075,\n",
       "  0.052781201899051666,\n",
       "  -0.0041144127026200294,\n",
       "  -0.041289471089839935,\n",
       "  0.05503813549876213,\n",
       "  0.008838392794132233,\n",
       "  0.022321470081806183,\n",
       "  0.04773808643221855,\n",
       "  0.11180945485830307,\n",
       "  -0.03508932888507843,\n",
       "  0.0413578562438488,\n",
       "  0.04801240563392639,\n",
       "  0.03272392228245735,\n",
       "  -0.0029137886594980955,\n",
       "  0.2654194235801697,\n",
       "  0.02199149690568447,\n",
       "  -0.021781573072075844,\n",
       "  0.00679666455835104,\n",
       "  0.0795971155166626,\n",
       "  -0.014753920957446098,\n",
       "  -0.01048863586038351,\n",
       "  -0.09673726558685303,\n",
       "  0.08910126984119415,\n",
       "  0.04074428230524063,\n",
       "  0.02557843178510666,\n",
       "  -0.02020837366580963,\n",
       "  0.026964334771037102,\n",
       "  0.03267725184559822,\n",
       "  -0.03799064829945564,\n",
       "  -0.03361169621348381,\n",
       "  0.024794448167085648,\n",
       "  -0.013218178413808346,\n",
       "  -0.05303841084241867,\n",
       "  -0.10896403342485428,\n",
       "  -0.05456417426466942,\n",
       "  -0.013930104672908783,\n",
       "  -0.005056218709796667,\n",
       "  0.025841211900115013,\n",
       "  0.02465967647731304,\n",
       "  0.07758766412734985,\n",
       "  -0.054426923394203186,\n",
       "  -0.007613292895257473,\n",
       "  0.02239742875099182,\n",
       "  0.03884095326066017,\n",
       "  -0.10680155456066132,\n",
       "  -0.005138306878507137,\n",
       "  0.002072614850476384,\n",
       "  -0.005972454324364662,\n",
       "  0.009017138741910458,\n",
       "  0.04497535154223442,\n",
       "  -0.00859143864363432,\n",
       "  0.028706781566143036,\n",
       "  -0.018678078427910805,\n",
       "  0.009744219481945038,\n",
       "  -0.00295667489990592,\n",
       "  0.007559179328382015,\n",
       "  -0.004108732100576162,\n",
       "  -0.0914703905582428,\n",
       "  0.08385967463254929,\n",
       "  -0.04001838341355324,\n",
       "  -0.08684161305427551,\n",
       "  -0.012863499112427235,\n",
       "  0.09945196658372879,\n",
       "  -0.04687662795186043,\n",
       "  0.014972388744354248,\n",
       "  0.00532147940248251,\n",
       "  -0.08303084224462509,\n",
       "  0.08837105333805084,\n",
       "  0.047678206115961075,\n",
       "  -0.05775809288024902,\n",
       "  0.003448210656642914,\n",
       "  0.02847628854215145,\n",
       "  0.028905561193823814,\n",
       "  0.06359334290027618,\n",
       "  -1.2121715371904429e-05,\n",
       "  -0.11916138231754303,\n",
       "  0.09904398024082184,\n",
       "  -0.07323320209980011,\n",
       "  -0.06759853661060333,\n",
       "  -0.011053908616304398,\n",
       "  -0.06121691316366196,\n",
       "  0.0420072004199028,\n",
       "  0.010501516982913017,\n",
       "  -0.014864365570247173,\n",
       "  -0.04469925910234451,\n",
       "  -0.027829423546791077,\n",
       "  -0.021370073780417442,\n",
       "  0.09649490565061569,\n",
       "  0.021391253918409348,\n",
       "  0.028897816315293312,\n",
       "  -0.011039535515010357]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['102844412710001974'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n"
     ]
    }
   ],
   "source": [
    "data = chat_ds('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
