{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda288b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300ee99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config_test.yaml') as f:\n",
    "    conf = yaml.full_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945cb123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:1\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "global cuda_dev\n",
    "cuda_dev = conf['trn_args']['device_id']\n",
    "\n",
    "device = torch.device(cuda_dev if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6faeb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(string.printable)\n",
    "## train args\n",
    "weight_dir=conf['dataset']['weight_path']\n",
    "data_mode = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67981791",
   "metadata": {},
   "outputs": [],
   "source": [
    "##decoding\n",
    "\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "def linesToTensor(lines):\n",
    "    char_length = 7000\n",
    "\n",
    "    tensor_one_hot = torch.zeros(len(lines), char_length, n_letters)\n",
    "    tensor_label = torch.zeros(len(lines),char_length,1) ##line = batchsize\n",
    "    \n",
    "    for b, line in enumerate(lines): \n",
    "        len_line = min(char_length,len(line))\n",
    "        line = line[:len_line]\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor_one_hot[b][li + char_length - (len_line)][letterToIndex(letter)] = 1 #뒤로 맞춰줌 batch*character*100\n",
    "            tensor_label[b][li + char_length - (len_line)][0] =letterToIndex(letter) #batch*character*1\n",
    "\n",
    "    return tensor_one_hot,tensor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8061dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global input_size,hidden_size,num_layers\n",
    "hidden_size=conf['trn_args']['hidden_size']\n",
    "num_layers=conf['trn_args']['num_layer']\n",
    "class LangModel(nn.Module):\n",
    "\n",
    "    def __init__(self, preTrained='True', input=100):\n",
    "        super(LangModel, self).__init__()\n",
    "\n",
    "        # Language Model\n",
    "        self.lang = nn.LSTM(input, hidden_size, num_layers, batch_first=True) \n",
    " \n",
    "        # Output \n",
    "        self.output = nn.Linear(hidden_size, 2)\n",
    "        n = self.output.in_features * self.output.out_features\n",
    "        self.output.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        self.output.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        text.to(device)\n",
    "        h0 = ( Variable(torch.zeros(num_layers, text.size(0), hidden_size)).to(device),  Variable(torch.zeros(num_layers, text.size(0), hidden_size)).to(device))\n",
    "\n",
    "        lang_feature, hn = self.lang(text, h0 )\n",
    "        lang_feature = lang_feature[:,-1,:]\n",
    "\n",
    "        pred = self.output(lang_feature)\n",
    "        return pred,lang_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add8dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class chat_ds(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.gt_range =  1-conf['trn_args']['hl_range']\n",
    "        self.d_type=d_type\n",
    "        with open(conf['dataset']['label_path'],'rb') as f1:  \n",
    "            self.gt=pickle.load(f1)\n",
    "        with open(conf['dataset']['chat_path'],'rb') as f2:  \n",
    "            self.text=pickle.load(f2)\n",
    "        #self.sample=list(map(int,list(self.gt.keys())))\n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "        if d_type =='total':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654'] + ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630'] + ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.gt[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "\n",
    "        begin_pos = 0 \n",
    "        hl_frames = []\n",
    "        for it, cur_pos in enumerate(pos_idx):\n",
    "            if it+1 < len(pos_idx): \n",
    "                if((pos_idx[it+1] - cur_pos) > 1):#cur_pos와 cur_pos+1 간격이 1보다 크면, 즉 다른 구간이면\n",
    "                    begin = int((it+1 - begin_pos) * self.gt_range) + begin_pos\n",
    "                    hl_frames.extend( pos_idx[begin: it] ) #한구간의 하이라이트 25%만 사용하겠다.\n",
    "                    begin_pos = it+1\n",
    "\n",
    "\n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[hl_frames] = len(sampling) / float(len(hl_frames))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        self.sum=np.insert(np.cumsum([len(self.gt[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.WeightedSampling)\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)\n",
    "            vid = np.where(vid[0]>0)[0][0]\n",
    "            vframe=index-self.sum[vid]\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "\n",
    "            win_text=''\n",
    "            for idx in range(conf['trn_args']['window_size']): #7 : window size\n",
    "                if vframe+idx<len(self.text[str(game_id)]):\n",
    "                    win_text+=self.text[str(game_id)][vframe+idx][:1000]+'\\n'\n",
    "\n",
    "            label=self.gt[str(game_id)][vframe]\n",
    "            return win_text,label,str(game_id)\n",
    "        \n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b90a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleSequentialSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially, always in the same order.\n",
    "    Arguments:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        offset (int): offset between the samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, offset=10):\n",
    "        self.num_samples = len(data_source) \n",
    "        self.offset = offset\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(np.arange(0, self.num_samples, self.offset ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(np.arange(0, self.num_samples, self.offset ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5059a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6633796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be449eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n"
     ]
    }
   ],
   "source": [
    "#game_id='102844212428895431'\n",
    "train=chat_ds('train')\n",
    "val=chat_ds('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221da96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=conf['trn_args']['trn_bs'],sampler=sampler1)\n",
    "# sampler2 =  SampleSequentialSampler(val, 30)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=conf['trn_args']['trn_bs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a808d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### model load #####\n",
    "if data_mode == 'label':\n",
    "    input_val = 1\n",
    "else:\n",
    "    inputs_val = 100\n",
    "model=LangModel(input=input_val).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c13ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dir=conf['dataset']['weight_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "104caf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "tensor([[ 0.6615, -0.6501],\n",
      "        [ 0.7244, -0.7003],\n",
      "        [ 0.7247, -0.7524],\n",
      "        ...,\n",
      "        [-0.3310,  0.2938],\n",
      "        [-0.0055,  0.0037],\n",
      "        [-0.4293,  0.3347]], device='cuda:1')\n",
      "35 256 667 66 tensor(291) tensor(101)\n",
      "tensor([[-0.5311,  0.4072],\n",
      "        [-0.8501,  0.7421],\n",
      "        [-0.8436,  0.6959],\n",
      "        ...,\n",
      "        [-0.7389,  0.6274],\n",
      "        [-0.2710,  0.2499],\n",
      "        [-0.2352,  0.1562]], device='cuda:1')\n",
      "109 384 487 44 tensor(493) tensor(153)\n",
      "tensor([[-1.0422,  0.9344],\n",
      "        [ 0.1201, -0.1587],\n",
      "        [ 0.6692, -0.6609],\n",
      "        ...,\n",
      "        [ 0.4201, -0.5264],\n",
      "        [ 0.5620, -0.5660],\n",
      "        [ 0.6489, -0.6481]], device='cuda:1')\n",
      "76 177 703 68 tensor(253) tensor(144)\n",
      "tensor([[ 0.4906, -0.5920],\n",
      "        [ 0.7379, -0.7733],\n",
      "        [ 0.6286, -0.6296],\n",
      "        ...,\n",
      "        [-0.9287,  0.7963],\n",
      "        [-0.6596,  0.5851],\n",
      "        [-0.4784,  0.4389]], device='cuda:1')\n",
      "63 235 697 29 tensor(298) tensor(92)\n",
      "tensor([[ 0.2691, -0.2997],\n",
      "        [ 0.0268, -0.0662],\n",
      "        [ 0.1063, -0.1465],\n",
      "        ...,\n",
      "        [ 0.2169, -0.2731],\n",
      "        [ 0.2084, -0.3052],\n",
      "        [ 0.5059, -0.5051]], device='cuda:1')\n",
      "132 289 560 43 tensor(421) tensor(175)\n",
      "tensor([[ 0.3911, -0.3949],\n",
      "        [ 0.2995, -0.3115],\n",
      "        [ 0.3918, -0.4385],\n",
      "        ...,\n",
      "        [ 0.5947, -0.6744],\n",
      "        [ 0.4823, -0.4782],\n",
      "        [ 0.4184, -0.4206]], device='cuda:1')\n",
      "35 396 520 73 tensor(431) tensor(108)\n",
      "tensor([[ 0.4804, -0.5617],\n",
      "        [ 0.3734, -0.3945],\n",
      "        [ 0.5789, -0.6554],\n",
      "        ...,\n",
      "        [-0.2136,  0.1042],\n",
      "        [-0.2651,  0.1611],\n",
      "        [ 0.0472, -0.1428]], device='cuda:1')\n",
      "156 340 421 107 tensor(496) tensor(263)\n",
      "tensor([[-0.4245,  0.3843],\n",
      "        [-0.7423,  0.6726],\n",
      "        [-0.6694,  0.5472],\n",
      "        ...,\n",
      "        [ 0.6306, -0.7403],\n",
      "        [ 0.5261, -0.6395],\n",
      "        [ 0.5238, -0.5891]], device='cuda:1')\n",
      "102 372 499 51 tensor(474) tensor(153)\n",
      "tensor([[ 0.3035, -0.3746],\n",
      "        [-0.1395,  0.0062],\n",
      "        [ 0.5794, -0.5884],\n",
      "        ...,\n",
      "        [-0.3839,  0.2598],\n",
      "        [ 0.1243, -0.1335],\n",
      "        [ 0.0168, -0.1096]], device='cuda:1')\n",
      "71 351 542 60 tensor(422) tensor(131)\n",
      "tensor([[-0.2310,  0.0954],\n",
      "        [ 0.3316, -0.3848],\n",
      "        [ 0.0857, -0.1178],\n",
      "        ...,\n",
      "        [ 0.7192, -0.6961],\n",
      "        [ 0.5095, -0.6081],\n",
      "        [ 0.5076, -0.5376]], device='cuda:1')\n",
      "133 309 509 73 tensor(442) tensor(206)\n",
      "tensor([[ 0.6322, -0.6205],\n",
      "        [ 0.3358, -0.4495],\n",
      "        [ 0.4037, -0.4121],\n",
      "        ...,\n",
      "        [-0.1074,  0.0089],\n",
      "        [-0.0926, -0.0143],\n",
      "        [-0.3315,  0.1938]], device='cuda:1')\n",
      "104 194 586 140 tensor(298) tensor(244)\n",
      "tensor([[-0.2205,  0.1610],\n",
      "        [-0.4409,  0.3636],\n",
      "        [ 0.0523, -0.1576],\n",
      "        ...,\n",
      "        [ 0.1282, -0.1807],\n",
      "        [ 0.1291, -0.1945],\n",
      "        [ 0.4322, -0.5146]], device='cuda:1')\n",
      "33 125 813 53 tensor(158) tensor(86)\n",
      "tensor([[ 0.6559, -0.6372],\n",
      "        [ 0.4656, -0.5735],\n",
      "        [ 0.6189, -0.6209],\n",
      "        ...,\n",
      "        [-0.5764,  0.5054],\n",
      "        [-0.6484,  0.5680],\n",
      "        [-0.8895,  0.7446]], device='cuda:1')\n",
      "129 361 445 89 tensor(490) tensor(218)\n",
      "tensor([[-0.9208,  0.7749],\n",
      "        [-0.8408,  0.6997],\n",
      "        [-1.0596,  0.9312],\n",
      "        ...,\n",
      "        [ 0.0679, -0.1049],\n",
      "        [ 0.2641, -0.2504],\n",
      "        [ 0.1170, -0.2239]], device='cuda:1')\n",
      "68 378 542 36 tensor(446) tensor(104)\n",
      "tensor([[ 0.3320, -0.3180],\n",
      "        [ 0.2450, -0.2905],\n",
      "        [-0.1734,  0.1183],\n",
      "        ...,\n",
      "        [ 0.2998, -0.3244],\n",
      "        [ 0.4530, -0.4809],\n",
      "        [ 0.2112, -0.3148]], device='cuda:1')\n",
      "140 195 575 114 tensor(335) tensor(254)\n",
      "tensor([[ 0.4805, -0.5164],\n",
      "        [ 0.2082, -0.3092],\n",
      "        [ 0.1197, -0.2457],\n",
      "        ...,\n",
      "        [ 0.2696, -0.3906],\n",
      "        [ 0.3656, -0.4521],\n",
      "        [ 0.2475, -0.3829]], device='cuda:1')\n",
      "10 69 892 53 tensor(79) tensor(63)\n",
      "tensor([[-0.0334, -0.0909],\n",
      "        [-0.2700,  0.1620],\n",
      "        [ 0.2316, -0.3091],\n",
      "        ...,\n",
      "        [-0.2892,  0.1834],\n",
      "        [ 0.0015, -0.1168],\n",
      "        [-0.2671,  0.1200]], device='cuda:1')\n",
      "106 359 488 71 tensor(465) tensor(177)\n",
      "tensor([[-0.4290,  0.2924],\n",
      "        [-0.7569,  0.6312],\n",
      "        [-0.7805,  0.6814],\n",
      "        ...,\n",
      "        [ 0.0852, -0.2109],\n",
      "        [-0.0212, -0.0392],\n",
      "        [-0.5289,  0.4225]], device='cuda:1')\n",
      "90 561 324 49 tensor(651) tensor(139)\n",
      "tensor([[-0.7098,  0.6110],\n",
      "        [-0.3616,  0.2453],\n",
      "        [-0.1404,  0.1010],\n",
      "        ...,\n",
      "        [-0.4462,  0.3225],\n",
      "        [ 0.3041, -0.3020],\n",
      "        [ 0.4059, -0.3752]], device='cuda:1')\n",
      "121 366 444 93 tensor(487) tensor(214)\n",
      "tensor([[ 0.0020, -0.0315],\n",
      "        [ 0.0146, -0.0143],\n",
      "        [ 0.0869, -0.1982],\n",
      "        ...,\n",
      "        [ 0.2334, -0.2205],\n",
      "        [-0.0412,  0.0319],\n",
      "        [-0.3700,  0.3156]], device='cuda:1')\n",
      "173 412 365 74 tensor(585) tensor(247)\n",
      "tensor([[ 0.0508, -0.1667],\n",
      "        [-0.6848,  0.5532],\n",
      "        [-0.5555,  0.4218],\n",
      "        ...,\n",
      "        [ 0.5699, -0.6550],\n",
      "        [ 0.4842, -0.5771],\n",
      "        [ 0.4481, -0.4351]], device='cuda:1')\n",
      "175 439 329 81 tensor(614) tensor(256)\n",
      "tensor([[ 0.6143, -0.6078],\n",
      "        [ 0.5213, -0.5475],\n",
      "        [ 0.3845, -0.3941],\n",
      "        ...,\n",
      "        [-0.8923,  0.7683],\n",
      "        [-1.0241,  0.8767],\n",
      "        [-0.9965,  0.8528]], device='cuda:1')\n",
      "112 409 435 68 tensor(521) tensor(180)\n",
      "tensor([[ 0.0075, -0.0794],\n",
      "        [ 0.3435, -0.3358],\n",
      "        [-0.1112,  0.0512],\n",
      "        ...,\n",
      "        [-0.2583,  0.1739],\n",
      "        [-0.0140, -0.0620],\n",
      "        [ 0.1156, -0.1420]], device='cuda:1')\n",
      "135 266 551 72 tensor(401) tensor(207)\n",
      "tensor([[-0.5299,  0.4104],\n",
      "        [ 0.2358, -0.2401],\n",
      "        [ 0.0931, -0.2268],\n",
      "        ...,\n",
      "        [-0.0113,  0.0439],\n",
      "        [ 0.0981, -0.0826],\n",
      "        [ 0.1564, -0.1375]], device='cuda:1')\n",
      "102 371 506 45 tensor(473) tensor(147)\n",
      "tensor([[ 0.1397, -0.1648],\n",
      "        [-0.2078,  0.1830],\n",
      "        [-0.1266,  0.0504],\n",
      "        ...,\n",
      "        [-1.0724,  0.9484],\n",
      "        [-1.1451,  1.0231],\n",
      "        [-1.1711,  1.0493]], device='cuda:1')\n",
      "134 342 456 92 tensor(476) tensor(226)\n",
      "tensor([[-0.9576,  0.8400],\n",
      "        [-1.1428,  1.0214],\n",
      "        [-1.2383,  1.0617],\n",
      "        ...,\n",
      "        [ 0.7066, -0.6997],\n",
      "        [ 0.6906, -0.7085],\n",
      "        [ 0.5679, -0.6070]], device='cuda:1')\n",
      "42 433 522 27 tensor(475) tensor(69)\n",
      "tensor([[ 0.5165, -0.5641],\n",
      "        [ 0.5551, -0.6312],\n",
      "        [ 0.6044, -0.5880],\n",
      "        ...,\n",
      "        [ 0.3195, -0.3454],\n",
      "        [-0.0986,  0.0309],\n",
      "        [ 0.4256, -0.5367]], device='cuda:1')\n",
      "156 320 466 82 tensor(476) tensor(238)\n",
      "tensor([[ 0.3358, -0.3726],\n",
      "        [ 0.4737, -0.5710],\n",
      "        [ 0.3219, -0.3582],\n",
      "        ...,\n",
      "        [-0.3243,  0.2281],\n",
      "        [-0.5615,  0.4605],\n",
      "        [ 0.2557, -0.3595]], device='cuda:1')\n",
      "61 368 572 23 tensor(429) tensor(84)\n",
      "tensor([[ 0.3719, -0.3642],\n",
      "        [ 0.0838, -0.1104],\n",
      "        [ 0.1553, -0.2545],\n",
      "        ...,\n",
      "        [-0.6679,  0.5178],\n",
      "        [-0.1636,  0.0829],\n",
      "        [-1.0133,  0.8688]], device='cuda:1')\n",
      "37 246 691 50 tensor(283) tensor(87)\n",
      "tensor([[-0.1489,  0.0480],\n",
      "        [ 0.1628, -0.1667],\n",
      "        [ 0.2618, -0.2627],\n",
      "        ...,\n",
      "        [-0.1568,  0.1376],\n",
      "        [ 0.0160, -0.0261],\n",
      "        [ 0.0091, -0.0096]], device='cuda:1')\n",
      "118 306 518 82 tensor(424) tensor(200)\n",
      "tensor([[-0.0308,  0.0313],\n",
      "        [-0.5379,  0.4187],\n",
      "        [-0.0552,  0.0294],\n",
      "        ...,\n",
      "        [-1.1350,  1.0065],\n",
      "        [-1.0790,  0.9136],\n",
      "        [-1.5094,  1.3489]], device='cuda:1')\n",
      "204 355 397 68 tensor(559) tensor(272)\n",
      "tensor([[-0.5095,  0.4502],\n",
      "        [-1.3459,  1.2034],\n",
      "        [-1.3426,  1.1997],\n",
      "        ...,\n",
      "        [-0.2687,  0.1820],\n",
      "        [-0.4535,  0.4284],\n",
      "        [-0.9558,  0.8133]], device='cuda:1')\n",
      "230 377 358 59 tensor(607) tensor(289)\n",
      "tensor([[-0.5050,  0.3815],\n",
      "        [-0.2887,  0.1698],\n",
      "        [-0.1067,  0.0899],\n",
      "        ...,\n",
      "        [-0.2173,  0.1673],\n",
      "        [ 0.1025, -0.0975],\n",
      "        [ 0.0268, -0.0982]], device='cuda:1')\n",
      "194 398 310 122 tensor(592) tensor(316)\n",
      "tensor([[-0.0937, -0.0150],\n",
      "        [ 0.2815, -0.2891],\n",
      "        [ 0.2895, -0.2864],\n",
      "        ...,\n",
      "        [ 0.2151, -0.3394],\n",
      "        [ 0.3165, -0.3217],\n",
      "        [ 0.3346, -0.3410]], device='cuda:1')\n",
      "158 330 418 118 tensor(488) tensor(276)\n",
      "tensor([[ 3.1148e-01, -2.9194e-01],\n",
      "        [ 2.9195e-01, -3.9215e-01],\n",
      "        [ 5.6919e-01, -5.9148e-01],\n",
      "        [ 2.5323e-01, -3.6583e-01],\n",
      "        [ 3.1653e-01, -4.3027e-01],\n",
      "        [ 3.9324e-01, -4.0963e-01],\n",
      "        [ 2.2782e-01, -3.2152e-01],\n",
      "        [ 2.7002e-01, -3.6417e-01],\n",
      "        [ 1.8237e-01, -1.7864e-01],\n",
      "        [ 3.1106e-01, -4.0659e-01],\n",
      "        [ 4.0319e-01, -4.0154e-01],\n",
      "        [ 4.4174e-01, -4.4643e-01],\n",
      "        [ 2.5609e-01, -3.2149e-01],\n",
      "        [ 1.4615e-01, -1.5534e-01],\n",
      "        [ 2.6992e-01, -2.7918e-01],\n",
      "        [ 3.7598e-01, -4.6010e-01],\n",
      "        [ 3.2899e-01, -3.3030e-01],\n",
      "        [ 3.5603e-01, -3.7609e-01],\n",
      "        [ 1.5492e-01, -2.5220e-01],\n",
      "        [-2.5325e-01,  1.3656e-01],\n",
      "        [-7.9802e-02, -4.2696e-02],\n",
      "        [-5.5989e-01,  4.3382e-01],\n",
      "        [-3.6983e-01,  2.9186e-01],\n",
      "        [-3.1513e-01,  2.5923e-01],\n",
      "        [-2.8389e-02, -7.9853e-02],\n",
      "        [ 2.2774e-01, -3.2552e-01],\n",
      "        [-1.5014e-01,  3.1067e-02],\n",
      "        [ 1.7865e-01, -1.7743e-01],\n",
      "        [ 1.6321e-01, -1.6409e-01],\n",
      "        [-2.8240e-01,  2.0932e-01],\n",
      "        [-1.5864e-01,  1.0327e-01],\n",
      "        [ 1.9975e-01, -2.0670e-01],\n",
      "        [-3.5287e-01,  2.3686e-01],\n",
      "        [ 7.9378e-02, -1.7399e-01],\n",
      "        [ 9.1375e-02, -1.2104e-01],\n",
      "        [-1.1852e-01,  8.0181e-02],\n",
      "        [-2.2639e-01,  1.1590e-01],\n",
      "        [ 9.3720e-02, -2.0404e-01],\n",
      "        [-3.4826e-01,  3.0249e-01],\n",
      "        [-5.2799e-02,  1.9860e-02],\n",
      "        [ 9.4005e-02, -7.1131e-02],\n",
      "        [-2.6362e-02, -5.3679e-02],\n",
      "        [-2.6165e-02, -6.6313e-02],\n",
      "        [-3.4529e-02, -6.7860e-02],\n",
      "        [ 1.6462e-01, -2.0947e-01],\n",
      "        [ 2.3881e-01, -2.3802e-01],\n",
      "        [-1.7528e-01,  1.0595e-01],\n",
      "        [ 4.3269e-02, -1.5903e-01],\n",
      "        [ 5.2437e-03, -1.0318e-01],\n",
      "        [-2.3655e-01,  1.2196e-01],\n",
      "        [-1.5159e-01,  1.1028e-01],\n",
      "        [-2.8840e-01,  1.6742e-01],\n",
      "        [-9.6545e-02,  3.6446e-02],\n",
      "        [ 4.5026e-01, -4.3387e-01],\n",
      "        [ 6.8290e-02, -4.6653e-02],\n",
      "        [-6.3064e-01,  5.0865e-01],\n",
      "        [-5.7173e-01,  4.4398e-01],\n",
      "        [-3.8270e-01,  3.0261e-01],\n",
      "        [-6.2002e-01,  4.9821e-01],\n",
      "        [ 9.3603e-02, -1.0316e-01],\n",
      "        [-2.5238e-01,  2.2850e-01],\n",
      "        [-4.2524e-01,  3.9383e-01],\n",
      "        [-2.1590e-01,  1.3794e-01],\n",
      "        [-5.3894e-02, -4.4613e-02],\n",
      "        [-6.7933e-01,  5.7807e-01],\n",
      "        [-9.3436e-01,  7.8217e-01],\n",
      "        [-7.2610e-01,  5.7072e-01],\n",
      "        [-1.0984e+00,  9.7943e-01],\n",
      "        [-1.1068e+00,  9.5294e-01],\n",
      "        [-1.3346e+00,  1.1955e+00],\n",
      "        [-1.0603e+00,  9.0172e-01],\n",
      "        [-1.0741e+00,  9.0821e-01],\n",
      "        [-9.7902e-01,  8.1808e-01],\n",
      "        [-9.5740e-01,  8.3091e-01],\n",
      "        [-8.1564e-01,  6.5868e-01],\n",
      "        [-1.8700e-01,  9.3760e-02],\n",
      "        [-2.2109e-01,  1.2931e-01],\n",
      "        [-2.3220e-01,  1.2267e-01],\n",
      "        [-5.2426e-01,  3.8673e-01],\n",
      "        [-6.9269e-01,  5.6402e-01],\n",
      "        [-1.1737e+00,  1.0161e+00],\n",
      "        [-1.3047e+00,  1.1754e+00],\n",
      "        [-8.6103e-01,  7.2509e-01],\n",
      "        [-1.1065e+00,  9.6108e-01],\n",
      "        [-1.8255e-01,  8.0072e-02],\n",
      "        [ 1.8861e-01, -1.9015e-01],\n",
      "        [ 1.4617e-01, -1.4880e-01],\n",
      "        [-5.5702e-02, -2.9360e-02],\n",
      "        [ 2.7613e-01, -2.7668e-01],\n",
      "        [-9.7797e-03, -7.6561e-02],\n",
      "        [-4.5913e-02, -8.1084e-02],\n",
      "        [ 1.2734e-01, -2.5466e-01],\n",
      "        [ 2.9226e-01, -3.3044e-01],\n",
      "        [-1.9201e-02, -6.2144e-02],\n",
      "        [ 2.0449e-01, -1.8836e-01],\n",
      "        [-6.6234e-02, -4.5645e-02],\n",
      "        [-3.9548e-02, -8.1450e-02],\n",
      "        [ 1.6928e-01, -1.5965e-01],\n",
      "        [ 3.1295e-01, -3.4773e-01],\n",
      "        [ 1.1245e-01, -1.9671e-01],\n",
      "        [-2.6718e-01,  2.1484e-01],\n",
      "        [ 4.4489e-01, -4.2458e-01],\n",
      "        [ 6.8711e-02, -1.4161e-01],\n",
      "        [ 1.5641e-01, -2.7660e-01],\n",
      "        [-1.7634e-01,  4.8448e-02],\n",
      "        [ 2.3946e-01, -2.5572e-01],\n",
      "        [ 2.5310e-01, -3.0070e-01],\n",
      "        [-3.5096e-02, -4.4462e-02],\n",
      "        [ 3.1584e-01, -3.6727e-01],\n",
      "        [ 4.1286e-01, -3.7718e-01],\n",
      "        [ 9.1366e-02, -1.8867e-01],\n",
      "        [-2.5771e-01,  1.4183e-01],\n",
      "        [ 1.6985e-02, -1.0731e-01],\n",
      "        [ 9.0020e-02, -1.0820e-01],\n",
      "        [ 1.0049e-01, -1.9695e-01],\n",
      "        [ 1.5724e-01, -1.5536e-01],\n",
      "        [-1.6666e-01,  1.0502e-01],\n",
      "        [-2.5627e-01,  1.8293e-01],\n",
      "        [-2.3839e-01,  2.1942e-01],\n",
      "        [-6.2657e-01,  5.4535e-01],\n",
      "        [-9.3751e-01,  8.0167e-01],\n",
      "        [-9.2905e-01,  8.1129e-01],\n",
      "        [-6.3589e-01,  5.1654e-01],\n",
      "        [-2.9571e-01,  1.9209e-01],\n",
      "        [ 1.0984e-01, -1.0743e-01],\n",
      "        [-9.5978e-02,  6.7124e-03],\n",
      "        [-5.3225e-01,  4.3232e-01],\n",
      "        [-7.7792e-01,  6.5265e-01],\n",
      "        [-9.1235e-01,  7.7036e-01],\n",
      "        [-8.2098e-01,  6.7564e-01],\n",
      "        [-9.3919e-01,  7.9496e-01],\n",
      "        [-7.0483e-01,  6.0761e-01],\n",
      "        [-6.1460e-01,  5.4468e-01],\n",
      "        [-5.2771e-01,  3.9100e-01],\n",
      "        [-5.1979e-01,  4.5595e-01],\n",
      "        [-2.6439e-01,  1.9108e-01],\n",
      "        [-2.8179e-01,  1.3948e-01],\n",
      "        [-5.0282e-01,  3.5874e-01],\n",
      "        [-4.3787e-01,  3.7153e-01],\n",
      "        [ 1.3745e-01, -2.4943e-01],\n",
      "        [-1.8356e-01,  1.1378e-01],\n",
      "        [ 2.9823e-01, -2.8680e-01],\n",
      "        [ 4.1396e-01, -4.0713e-01],\n",
      "        [ 1.7973e-01, -2.8301e-01],\n",
      "        [ 2.7397e-01, -3.8022e-01],\n",
      "        [ 3.2566e-01, -4.3605e-01],\n",
      "        [ 2.6524e-01, -3.8766e-01],\n",
      "        [-1.5421e-01,  5.5293e-02],\n",
      "        [-4.5974e-01,  3.2771e-01],\n",
      "        [-3.0972e-01,  2.3223e-01],\n",
      "        [ 1.1859e-01, -2.2116e-01],\n",
      "        [-1.5424e-01,  2.2432e-02],\n",
      "        [ 3.1630e-01, -3.0815e-01],\n",
      "        [ 1.7327e-01, -2.8244e-01],\n",
      "        [ 4.0773e-01, -3.8609e-01],\n",
      "        [ 3.8421e-01, -3.9138e-01],\n",
      "        [ 4.0295e-01, -4.0092e-01],\n",
      "        [ 2.5034e-01, -2.5446e-01],\n",
      "        [-3.4899e-01,  2.1324e-01],\n",
      "        [ 1.8825e-01, -2.0034e-01],\n",
      "        [ 2.0175e-01, -1.8824e-01],\n",
      "        [ 2.0422e-01, -2.1318e-01],\n",
      "        [ 5.6403e-02, -1.5018e-01],\n",
      "        [ 3.4874e-02, -1.5288e-01],\n",
      "        [ 1.6692e-01, -2.7891e-01],\n",
      "        [ 1.5497e-01, -2.6872e-01],\n",
      "        [-1.7468e-01,  3.9253e-02],\n",
      "        [ 4.1131e-01, -4.2115e-01],\n",
      "        [ 4.8867e-01, -5.3100e-01],\n",
      "        [ 4.6105e-01, -4.9847e-01],\n",
      "        [ 1.7426e-01, -2.5799e-01],\n",
      "        [ 4.7038e-01, -4.6979e-01],\n",
      "        [ 2.7121e-03, -1.3998e-01],\n",
      "        [-2.2224e-01,  9.4540e-02],\n",
      "        [-5.6282e-01,  4.2635e-01],\n",
      "        [-1.7677e-01,  6.9273e-02],\n",
      "        [-4.0593e-01,  2.7384e-01],\n",
      "        [-1.8406e-01,  1.5690e-01],\n",
      "        [-1.2227e-01,  5.8671e-02],\n",
      "        [-3.4052e-01,  2.4740e-01],\n",
      "        [-8.6056e-02, -2.4372e-02],\n",
      "        [ 3.4836e-01, -3.2894e-01],\n",
      "        [ 7.7918e-02, -1.9379e-01],\n",
      "        [-6.2244e-02, -4.6088e-02],\n",
      "        [-3.7590e-02, -6.6593e-02],\n",
      "        [ 4.3970e-02, -1.5496e-01],\n",
      "        [-2.6867e-02, -3.2731e-02],\n",
      "        [ 4.1092e-02, -1.5342e-01],\n",
      "        [-1.6514e-01,  4.4040e-02],\n",
      "        [-1.4114e-01,  1.8450e-02],\n",
      "        [-4.0349e-01,  2.9550e-01],\n",
      "        [-9.4991e-02,  5.6628e-02],\n",
      "        [-1.7032e-01,  1.3708e-01],\n",
      "        [-4.8681e-01,  4.5423e-01],\n",
      "        [ 2.6272e-02, -1.7856e-02],\n",
      "        [-8.4649e-01,  7.3063e-01],\n",
      "        [ 1.2549e-01, -2.3109e-01],\n",
      "        [ 1.0459e-01, -2.0779e-01],\n",
      "        [-1.3063e-01,  4.9933e-02],\n",
      "        [-1.8083e-01,  1.3507e-01],\n",
      "        [-3.0563e-01,  1.6337e-01],\n",
      "        [-3.7784e-01,  2.3747e-01],\n",
      "        [ 7.2005e-02, -1.8096e-01],\n",
      "        [-9.2331e-02, -2.2797e-02],\n",
      "        [ 1.3697e-02, -1.1148e-02],\n",
      "        [-7.8884e-01,  6.8504e-01],\n",
      "        [-1.0542e+00,  9.0497e-01],\n",
      "        [-1.0591e+00,  9.2232e-01],\n",
      "        [-9.4832e-01,  7.8830e-01],\n",
      "        [-7.5224e-01,  6.0653e-01],\n",
      "        [-9.9742e-01,  8.4090e-01],\n",
      "        [-9.8915e-01,  8.2332e-01],\n",
      "        [-1.0648e+00,  9.2901e-01],\n",
      "        [-1.0648e+00,  9.1436e-01],\n",
      "        [-1.2795e+00,  1.1280e+00],\n",
      "        [-1.0606e+00,  9.4279e-01],\n",
      "        [-1.1003e+00,  9.7531e-01],\n",
      "        [-9.9633e-01,  8.4947e-01],\n",
      "        [-1.2017e+00,  1.0687e+00],\n",
      "        [-1.2551e+00,  1.1176e+00],\n",
      "        [-1.1267e+00,  9.7016e-01],\n",
      "        [-1.3115e+00,  1.1700e+00],\n",
      "        [-1.3589e+00,  1.2330e+00],\n",
      "        [-2.0579e-02, -1.7336e-03],\n",
      "        [-2.7968e-02,  2.9841e-02],\n",
      "        [-5.3476e-01,  4.5009e-01],\n",
      "        [-8.3540e-01,  6.8475e-01],\n",
      "        [-1.0924e+00,  9.5966e-01],\n",
      "        [-5.4549e-01,  4.2212e-01],\n",
      "        [-8.4675e-01,  7.1917e-01],\n",
      "        [-1.3650e+00,  1.2216e+00],\n",
      "        [-1.1259e+00,  9.6001e-01],\n",
      "        [-1.1501e+00,  1.0243e+00],\n",
      "        [-1.3373e+00,  1.1926e+00],\n",
      "        [-1.3270e+00,  1.1677e+00],\n",
      "        [-1.1970e+00,  1.0350e+00],\n",
      "        [-2.5248e-01,  1.6800e-01],\n",
      "        [-5.6205e-01,  4.2539e-01],\n",
      "        [-5.2939e-01,  3.9458e-01],\n",
      "        [-5.9605e-01,  4.5063e-01],\n",
      "        [-7.6593e-01,  6.2920e-01],\n",
      "        [-1.0594e+00,  9.2394e-01],\n",
      "        [-8.9318e-02, -3.2015e-02],\n",
      "        [-6.4984e-01,  5.1675e-01],\n",
      "        [-1.0901e+00,  9.5595e-01],\n",
      "        [-6.2416e-01,  4.7102e-01],\n",
      "        [-6.2770e-01,  5.1687e-01],\n",
      "        [-7.8457e-01,  6.3784e-01],\n",
      "        [-9.9162e-01,  8.6545e-01],\n",
      "        [-1.1862e+00,  1.0728e+00],\n",
      "        [-1.0753e+00,  9.7542e-01],\n",
      "        [-9.2711e-01,  7.7471e-01],\n",
      "        [-2.1979e-01,  1.0208e-01],\n",
      "        [-8.7071e-02, -1.1687e-02],\n",
      "        [-1.0185e+00,  8.9331e-01],\n",
      "        [-7.1598e-01,  5.6108e-01],\n",
      "        [-4.4631e-01,  3.2091e-01],\n",
      "        [-8.7456e-01,  7.5577e-01],\n",
      "        [ 1.5680e-01, -1.5354e-01],\n",
      "        [-4.7592e-02, -5.6585e-02],\n",
      "        [ 2.5313e-01, -2.5410e-01],\n",
      "        [-3.0044e-01,  1.7152e-01],\n",
      "        [-1.5184e-01,  4.0050e-02],\n",
      "        [-2.2810e-01,  1.0446e-01],\n",
      "        [ 4.4149e-02, -1.3150e-01],\n",
      "        [ 2.9402e-01, -2.7698e-01],\n",
      "        [ 6.8395e-02, -1.7732e-01],\n",
      "        [-3.8320e-02, -1.7054e-02],\n",
      "        [-2.4110e-01,  1.1838e-01],\n",
      "        [ 2.8333e-02, -1.1753e-01],\n",
      "        [-1.9483e-02, -5.5942e-02],\n",
      "        [-9.6100e-02, -8.2686e-03],\n",
      "        [ 1.3689e-01, -1.3376e-01],\n",
      "        [-3.9444e-01,  2.5428e-01],\n",
      "        [-1.7304e-01,  5.6775e-02],\n",
      "        [ 1.0537e-01, -2.0285e-01],\n",
      "        [ 3.6276e-02, -1.4331e-01],\n",
      "        [-4.1028e-02, -7.4262e-02],\n",
      "        [ 4.2464e-01, -4.1300e-01],\n",
      "        [ 3.6756e-01, -4.0168e-01],\n",
      "        [ 2.9684e-01, -3.8227e-01],\n",
      "        [ 3.8022e-01, -3.7118e-01],\n",
      "        [ 1.3100e-01, -2.4647e-01],\n",
      "        [-8.1599e-03, -7.8869e-02],\n",
      "        [-2.4515e-01,  1.4730e-01],\n",
      "        [ 8.1177e-02, -1.5954e-01],\n",
      "        [ 1.1661e-01, -1.2331e-01],\n",
      "        [-8.3707e-02,  4.4238e-03],\n",
      "        [ 9.1102e-02, -1.1631e-01],\n",
      "        [-8.3704e-02,  2.4202e-02],\n",
      "        [-2.1830e-01,  1.3792e-01],\n",
      "        [-1.2243e-01,  5.4093e-02],\n",
      "        [-4.4996e-01,  3.6286e-01],\n",
      "        [-2.4478e-01,  1.3382e-01],\n",
      "        [-5.5853e-01,  4.6043e-01],\n",
      "        [-9.4146e-01,  7.8521e-01],\n",
      "        [-5.4522e-01,  4.2245e-01],\n",
      "        [-1.1850e+00,  1.0579e+00],\n",
      "        [-1.2705e+00,  1.1620e+00],\n",
      "        [-2.8163e-01,  2.4771e-01],\n",
      "        [-2.1082e-01,  1.3578e-01],\n",
      "        [-5.8860e-02, -2.2367e-03],\n",
      "        [ 2.8809e-01, -2.7577e-01],\n",
      "        [-1.7987e-01,  1.0667e-01],\n",
      "        [-6.2112e-01,  5.0510e-01],\n",
      "        [-4.7518e-01,  3.4349e-01],\n",
      "        [-5.2922e-01,  4.3491e-01],\n",
      "        [-2.4992e-01,  1.8416e-01],\n",
      "        [-5.6578e-02,  4.0669e-02],\n",
      "        [-5.4478e-01,  4.2041e-01],\n",
      "        [-1.7282e-01,  1.3580e-01],\n",
      "        [-2.2888e-01,  1.2178e-01],\n",
      "        [ 1.0855e-01, -1.7299e-01],\n",
      "        [ 5.0616e-03, -4.1064e-02],\n",
      "        [-1.2664e-01,  9.1345e-02],\n",
      "        [-1.0057e-01, -8.1696e-03],\n",
      "        [-1.0527e-02, -1.3254e-03],\n",
      "        [ 1.9419e-01, -2.2083e-01],\n",
      "        [-1.6634e-01,  5.3975e-02],\n",
      "        [ 3.5200e-01, -3.3223e-01],\n",
      "        [ 5.1824e-01, -4.9045e-01],\n",
      "        [ 1.4444e-01, -2.4637e-01],\n",
      "        [ 2.5127e-01, -2.8785e-01],\n",
      "        [ 2.3662e-02, -9.7981e-02],\n",
      "        [ 1.9878e-01, -1.9643e-01],\n",
      "        [-8.8832e-02,  4.0882e-02],\n",
      "        [-7.0816e-01,  6.0002e-01],\n",
      "        [ 1.8036e-01, -1.7621e-01],\n",
      "        [-5.6493e-02, -4.0018e-02],\n",
      "        [-2.1245e-01,  1.4902e-01],\n",
      "        [-4.5447e-01,  3.8405e-01],\n",
      "        [ 3.1334e-01, -2.9758e-01],\n",
      "        [ 3.1522e-01, -3.5222e-01],\n",
      "        [ 5.0536e-01, -5.6004e-01],\n",
      "        [ 2.4294e-01, -2.6455e-01],\n",
      "        [ 3.9022e-01, -3.8262e-01],\n",
      "        [ 2.6954e-01, -2.7630e-01],\n",
      "        [-9.7489e-02,  1.2412e-02],\n",
      "        [ 2.0071e-01, -2.8235e-01],\n",
      "        [ 2.1761e-01, -2.2517e-01],\n",
      "        [ 1.7695e-01, -1.7158e-01],\n",
      "        [-4.6036e-01,  3.3059e-01],\n",
      "        [-7.6452e-01,  6.6442e-01],\n",
      "        [-6.8966e-01,  5.4287e-01],\n",
      "        [-8.5000e-01,  7.3341e-01],\n",
      "        [-1.1732e+00,  1.0626e+00],\n",
      "        [-1.2832e+00,  1.1780e+00],\n",
      "        [-1.2257e+00,  1.1254e+00],\n",
      "        [-1.1212e+00,  9.9956e-01],\n",
      "        [-1.1507e+00,  1.0000e+00],\n",
      "        [-9.4874e-01,  7.9697e-01],\n",
      "        [-9.9857e-01,  8.8722e-01],\n",
      "        [-9.0731e-01,  7.9225e-01],\n",
      "        [-1.2799e+00,  1.1415e+00],\n",
      "        [-1.0852e+00,  9.3604e-01],\n",
      "        [-1.1497e+00,  1.0278e+00],\n",
      "        [-1.1166e+00,  9.6126e-01],\n",
      "        [-1.5785e-01,  1.4701e-01],\n",
      "        [ 1.9414e-01, -1.8354e-01],\n",
      "        [-4.7175e-01,  3.2951e-01],\n",
      "        [-6.4005e-01,  5.3378e-01],\n",
      "        [-6.6999e-01,  5.4252e-01],\n",
      "        [-5.6886e-01,  4.7228e-01],\n",
      "        [-5.6902e-01,  4.2307e-01],\n",
      "        [-6.7144e-01,  5.8819e-01],\n",
      "        [-1.1663e+00,  1.0309e+00],\n",
      "        [-1.2928e+00,  1.1611e+00],\n",
      "        [-1.1007e+00,  9.4175e-01],\n",
      "        [-1.1500e+00,  1.0185e+00],\n",
      "        [-1.1459e+00,  1.0121e+00],\n",
      "        [-1.0391e+00,  8.9005e-01],\n",
      "        [-1.3498e+00,  1.2107e+00],\n",
      "        [-1.3994e+00,  1.2763e+00],\n",
      "        [-1.0574e+00,  8.9486e-01],\n",
      "        [-1.0306e+00,  8.8697e-01],\n",
      "        [-1.1812e+00,  1.0546e+00],\n",
      "        [-1.2936e+00,  1.1534e+00],\n",
      "        [-1.0406e+00,  8.9314e-01],\n",
      "        [-1.0924e+00,  9.6715e-01],\n",
      "        [-1.1220e+00,  9.5766e-01],\n",
      "        [-4.7816e-01,  3.8401e-01],\n",
      "        [ 6.6570e-02, -1.7799e-01],\n",
      "        [-8.9138e-01,  7.6445e-01],\n",
      "        [-6.9321e-01,  5.5720e-01],\n",
      "        [-8.3060e-02,  7.4685e-04],\n",
      "        [ 2.8703e-01, -2.9501e-01],\n",
      "        [ 2.8037e-01, -3.8347e-01],\n",
      "        [ 7.3333e-02, -1.2267e-01],\n",
      "        [-3.4856e-01,  2.3603e-01],\n",
      "        [ 4.0908e-01, -3.9735e-01],\n",
      "        [ 1.4248e-01, -2.1347e-01],\n",
      "        [ 2.3143e-01, -2.6161e-01],\n",
      "        [-2.1462e-01,  9.5151e-02],\n",
      "        [-7.0365e-02, -2.7118e-03],\n",
      "        [ 4.7712e-02, -6.0748e-02],\n",
      "        [-2.1820e-01,  1.0275e-01],\n",
      "        [-7.8342e-01,  6.3128e-01],\n",
      "        [-8.1909e-01,  6.6735e-01],\n",
      "        [-1.1609e+00,  1.0261e+00],\n",
      "        [-1.1697e+00,  1.0344e+00],\n",
      "        [-1.0631e+00,  9.3212e-01]], device='cuda:1')\n",
      "86 162 124 29 tensor(248) tensor(115)\n",
      "3830 11251 2404\n",
      "[34/35], prec:0.25396193886347057, recall:0.6143727943535451, f1:35.93713347407928, acc: 0.6122611238890309\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "test=chat_ds('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=1024)\n",
    "dataset=weight_dir+'train_best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:1')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (text,labels,g) in enumerate(test_loader):\n",
    "        if data_mode == 'label':\n",
    "            inputs=linesToTensor(text)[1]\n",
    "        else:\n",
    "            inputs=linesToTensor(text)[0]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output_p,output_f=model(inputs)\n",
    "        \n",
    "        \n",
    "        print(output_p)\n",
    "\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output_p.cpu(),labels.cpu())\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output_p)\n",
    "        for idx,gi in enumerate(g):\n",
    "            if gi not in result.keys():\n",
    "                result[gi]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[gi]+=pred[idx].tolist()\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "310f9415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2545d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
