{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import & preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../video/lolData/exp_data/gamedata.pickle',\"rb\") as dt:\n",
    "    data = pickle.load(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for game in data.keys():\n",
    "    data[game]['Time'] = list(map(lambda x:int(x.split('-')[0])*3600+int(x.split('-')[1])*60+int(x.split('-')[2]),data[game]['Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for game in data.keys():\n",
    "    init = data[game]['Time'][0]\n",
    "    data[game]['Time'] = list(map(lambda x:x-init,data[game]['Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    index = 0\n",
    "    time = 0\n",
    "    datas = pd.DataFrame(columns = data[i].columns)\n",
    "    while(time<data[i].iloc[-1]['Time']):\n",
    "        temp = data[i].iloc[[index],:]\n",
    "        if int(temp['Time']) == time:\n",
    "            datas = pd.concat([datas,temp],ignore_index=True)\n",
    "            index+=1\n",
    "        else:\n",
    "            temp['Time'] = time\n",
    "            datas = pd.concat([datas,temp],ignore_index=True)\n",
    "        time+=1\n",
    "    data[i] = datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    data[i] = data[i].drop(['Time','Timestamp'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654','102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630','102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=[]\n",
    "for i in data:\n",
    "    if i not in sample:\n",
    "        temp.append(i)\n",
    "for i in temp:\n",
    "    data.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#변화율만 계산\n",
    "for i in data:\n",
    "    temp = pd.concat([data[i][data[i].index<1],data[i].drop(len(data[i])-1)],ignore_index=True)\n",
    "    data[i] -= temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler=MinMaxScaler()\n",
    "data_scaled={}\n",
    "for i in data:\n",
    "    min_max_scaler.fit(data[i])\n",
    "    output = min_max_scaler.transform(data[i])\n",
    "    data_scaled[i] = pd.DataFrame(output,columns=data[i].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shift window, highlight 25%, dataset 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_i = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "val_i = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "test_i = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label load\n",
    "with open('../../multimodal/label/label.pickle','rb') as f:\n",
    "    label=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 자르기 \n",
    "for i in data_scaled:\n",
    "    data_scaled[i] = data_scaled[i][:len(label[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with open('./video_raw_feature.pickle','wb') as f:\n",
    "    pickle.dump(data_scaled,f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './video_raw_feature.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20258/1223501808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./video_raw_feature.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './video_raw_feature.pickle'"
     ]
    }
   ],
   "source": [
    "with open('./video_raw_feature.pickle','rb') as f:\n",
    "    data_scaled = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2069, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_scaled['102844412722519367']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#25% 추출\n",
    "label_scaled={}\n",
    "for i in label:\n",
    "    index=[]\n",
    "    temp=[]\n",
    "    for j,v in enumerate(label[i]):\n",
    "        if v==1:\n",
    "            temp.append(j)\n",
    "        if len(temp) !=0 and (v==0 or j == len(label[i])-1):\n",
    "            temp=temp[-int(len(temp)/4):]\n",
    "            index+=temp\n",
    "            temp=[]\n",
    "    result=[]\n",
    "    for j in range(len(label[i])):\n",
    "        if j in index:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    label_scaled[i] = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sliding window\n",
    "data_shifted={}\n",
    "for i in data_scaled:\n",
    "    temp = []\n",
    "    for j in range(len(data_scaled[i])):\n",
    "        if j == len(label_scaled[i]):\n",
    "            break\n",
    "        if j+7<=len(data_scaled[i]):\n",
    "            temp.append(data_scaled[i][j:j+7])\n",
    "        else:\n",
    "            temp.append(pd.concat([data_scaled[i][j:len(data_scaled[i])],data_scaled[i][0:j+7-len(data_scaled[i])]],ignore_index=True))\n",
    "    data_shifted[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('video_label.pickle','wb') as f:\n",
    "    pickle.dump(label_scaled,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('video_feature.pickle','wb') as f:\n",
    "    pickle.dump(data_shifted,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('video_feature.pickle','rb')as f:\n",
    "    data_shifted = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('video_label.pickle','rb') as f:\n",
    "    label_scaled = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset 나누기\n",
    "data_train=[]\n",
    "label_train=np.array([])\n",
    "data_val=[]\n",
    "label_val=np.array([])\n",
    "data_test=[]\n",
    "label_test=np.array([])\n",
    "\n",
    "for i in data_shifted:\n",
    "    if i in train_i:\n",
    "        temp=[]\n",
    "        for j in data_shifted[i]:\n",
    "            temp.append(np.array(j))\n",
    "        data_train+=temp\n",
    "        \n",
    "        label_train = np.concatenate((label_train,label_scaled[i]),axis=None)\n",
    "    elif i in val_i:\n",
    "        temp=[]\n",
    "        for j in data_shifted[i]:\n",
    "            temp.append(np.array(j))\n",
    "        data_val+=temp\n",
    "        \n",
    "        label_val = np.concatenate((label_val,label_scaled[i]),axis=None)\n",
    "    elif i in test_i:\n",
    "        temp=[]\n",
    "        for j in data_shifted[i]:\n",
    "            temp.append(np.array(j))\n",
    "        data_test+=temp\n",
    "        \n",
    "        label_test = np.concatenate((label_test,label_scaled[i]),axis=None)\n",
    "        \n",
    "data_train = np.array(data_train)\n",
    "data_val = np.array(data_val)\n",
    "data_test = np.array(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_dir='./video_weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 전체 데이터에 대해서 score\n",
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input=10):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # Language Model\n",
    "        self.lang = nn.LSTM(input, 128, 3, batch_first=True) \n",
    " \n",
    "        # Output \n",
    "        self.output = nn.Linear(128, 2)\n",
    "        n = self.output.in_features * self.output.out_features\n",
    "        self.output.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        self.output.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        text.cuda()\n",
    "        h0 = ( Variable(torch.zeros(3, text.size(0), 128)).cuda(),  Variable(torch.zeros(3, text.size(0), 128)).cuda())\n",
    "        \n",
    "        lang_feature, hn = self.lang(text, h0 )\n",
    "        lang_feature = lang_feature[:,-1,:]\n",
    "\n",
    "        pred = self.output(lang_feature)\n",
    "        return pred,lang_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTM().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self,data,label):\n",
    "        self.x_data = data\n",
    "        self.y_data = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(data_train,label_train)\n",
    "train_loader = DataLoader(dataset=dataset,batch_size=32)\n",
    "dataset = Dataset(data_val,label_val)\n",
    "val_loader = DataLoader(dataset=dataset,batch_size=32)\n",
    "dataset = Dataset(data_test,label_test)\n",
    "test_loader = DataLoader(dataset=dataset,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch<20:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train_loss : 0.17973992228507996 , val_loss : 0.16942070424556732, val_acc : 0.959872683869501\n",
      "1\n",
      "epoch 1 train_loss : 0.17968693375587463 , val_loss : 0.16941627860069275, val_acc : 0.959872683869501\n",
      "2\n",
      "epoch 2 train_loss : 0.17964766919612885 , val_loss : 0.16941162943840027, val_acc : 0.959872683869501\n",
      "3\n",
      "epoch 3 train_loss : 0.1796165108680725 , val_loss : 0.16940844058990479, val_acc : 0.959872683869501\n",
      "4\n",
      "epoch 4 train_loss : 0.1795918345451355 , val_loss : 0.1694047600030899, val_acc : 0.959872683869501\n",
      "5\n",
      "epoch 5 train_loss : 0.17957188189029694 , val_loss : 0.1694021224975586, val_acc : 0.959872683869501\n",
      "6\n",
      "epoch 6 train_loss : 0.17955587804317474 , val_loss : 0.16940176486968994, val_acc : 0.959872683869501\n",
      "7\n",
      "epoch 7 train_loss : 0.17954225838184357 , val_loss : 0.1694008708000183, val_acc : 0.959872683869501\n",
      "8\n",
      "epoch 8 train_loss : 0.17953065037727356 , val_loss : 0.16939863562583923, val_acc : 0.959872683869501\n",
      "9\n",
      "epoch 9 train_loss : 0.1795206218957901 , val_loss : 0.16939885914325714, val_acc : 0.959872683869501\n",
      "10\n",
      "epoch 10 train_loss : 0.17951256036758423 , val_loss : 0.16939741373062134, val_acc : 0.959872683869501\n",
      "11\n",
      "epoch 11 train_loss : 0.17950519919395447 , val_loss : 0.16939733922481537, val_acc : 0.959872683869501\n",
      "12\n",
      "epoch 12 train_loss : 0.1794995218515396 , val_loss : 0.16939568519592285, val_acc : 0.959872683869501\n",
      "13\n",
      "epoch 13 train_loss : 0.17949418723583221 , val_loss : 0.16939662396907806, val_acc : 0.959872683869501\n",
      "14\n",
      "epoch 14 train_loss : 0.17948977649211884 , val_loss : 0.16939693689346313, val_acc : 0.959872683869501\n",
      "15\n",
      "epoch 15 train_loss : 0.17948640882968903 , val_loss : 0.1693951040506363, val_acc : 0.959872683869501\n",
      "16\n",
      "epoch 16 train_loss : 0.17948299646377563 , val_loss : 0.16939502954483032, val_acc : 0.959872683869501\n",
      "17\n",
      "epoch 17 train_loss : 0.17948080599308014 , val_loss : 0.16939547657966614, val_acc : 0.959872683869501\n",
      "18\n",
      "epoch 18 train_loss : 0.17947833240032196 , val_loss : 0.16939517855644226, val_acc : 0.959872683869501\n",
      "19\n",
      "epoch 19 train_loss : 0.1794762909412384 , val_loss : 0.16939538717269897, val_acc : 0.959872683869501\n",
      "20\n",
      "epoch 20 train_loss : 0.17922177910804749 , val_loss : 0.16914699971675873, val_acc : 0.959872683869501\n",
      "21\n",
      "epoch 21 train_loss : 0.17918770015239716 , val_loss : 0.16914153099060059, val_acc : 0.959872683869501\n",
      "22\n",
      "epoch 22 train_loss : 0.17918696999549866 , val_loss : 0.1691417396068573, val_acc : 0.959872683869501\n",
      "23\n",
      "epoch 23 train_loss : 0.17918691039085388 , val_loss : 0.1691417545080185, val_acc : 0.959872683869501\n",
      "24\n",
      "epoch 24 train_loss : 0.17918695509433746 , val_loss : 0.16914178431034088, val_acc : 0.959872683869501\n",
      "25\n",
      "epoch 25 train_loss : 0.17918691039085388 , val_loss : 0.1691417694091797, val_acc : 0.959872683869501\n",
      "26\n",
      "epoch 26 train_loss : 0.1791868954896927 , val_loss : 0.1691417545080185, val_acc : 0.959872683869501\n",
      "27\n",
      "epoch 27 train_loss : 0.17918698489665985 , val_loss : 0.16914165019989014, val_acc : 0.959872683869501\n",
      "28\n",
      "epoch 28 train_loss : 0.17918696999549866 , val_loss : 0.16914168000221252, val_acc : 0.959872683869501\n",
      "29\n",
      "epoch 29 train_loss : 0.17918699979782104 , val_loss : 0.16914165019989014, val_acc : 0.959872683869501\n",
      "30\n",
      "epoch 30 train_loss : 0.17918704450130463 , val_loss : 0.16914162039756775, val_acc : 0.959872683869501\n",
      "31\n",
      "epoch 31 train_loss : 0.17918698489665985 , val_loss : 0.16914157569408417, val_acc : 0.959872683869501\n",
      "32\n",
      "epoch 32 train_loss : 0.17918696999549866 , val_loss : 0.16914154589176178, val_acc : 0.959872683869501\n",
      "33\n",
      "epoch 33 train_loss : 0.17918696999549866 , val_loss : 0.16914153099060059, val_acc : 0.959872683869501\n",
      "34\n",
      "epoch 34 train_loss : 0.17918698489665985 , val_loss : 0.16914157569408417, val_acc : 0.959872683869501\n",
      "35\n",
      "epoch 35 train_loss : 0.17918698489665985 , val_loss : 0.16914314031600952, val_acc : 0.959872683869501\n",
      "36\n",
      "epoch 36 train_loss : 0.17918698489665985 , val_loss : 0.16914308071136475, val_acc : 0.959872683869501\n",
      "37\n",
      "epoch 37 train_loss : 0.17918698489665985 , val_loss : 0.1691436767578125, val_acc : 0.959872683869501\n",
      "38\n",
      "epoch 38 train_loss : 0.17918699979782104 , val_loss : 0.1691436916589737, val_acc : 0.959872683869501\n",
      "39\n",
      "epoch 39 train_loss : 0.17918696999549866 , val_loss : 0.16914361715316772, val_acc : 0.959872683869501\n",
      "40\n",
      "epoch 40 train_loss : 0.17918699979782104 , val_loss : 0.16914360225200653, val_acc : 0.959872683869501\n",
      "41\n",
      "epoch 41 train_loss : 0.17918705940246582 , val_loss : 0.16914354264736176, val_acc : 0.959872683869501\n",
      "42\n",
      "epoch 42 train_loss : 0.17918704450130463 , val_loss : 0.16914357244968414, val_acc : 0.959872683869501\n",
      "43\n",
      "epoch 43 train_loss : 0.17918707430362701 , val_loss : 0.16914351284503937, val_acc : 0.959872683869501\n",
      "44\n",
      "epoch 44 train_loss : 0.17918705940246582 , val_loss : 0.16914349794387817, val_acc : 0.959872683869501\n",
      "45\n",
      "epoch 45 train_loss : 0.17918702960014343 , val_loss : 0.16914354264736176, val_acc : 0.959872683869501\n",
      "46\n",
      "epoch 46 train_loss : 0.17918699979782104 , val_loss : 0.16914349794387817, val_acc : 0.959872683869501\n",
      "47\n",
      "epoch 47 train_loss : 0.17918701469898224 , val_loss : 0.16914351284503937, val_acc : 0.959872683869501\n",
      "48\n",
      "epoch 48 train_loss : 0.17918702960014343 , val_loss : 0.16914339363574982, val_acc : 0.959872683869501\n",
      "49\n",
      "epoch 49 train_loss : 0.17918702960014343 , val_loss : 0.16914339363574982, val_acc : 0.959872683869501\n",
      "50\n",
      "epoch 50 train_loss : 0.17918707430362701 , val_loss : 0.16914336383342743, val_acc : 0.959872683869501\n",
      "51\n",
      "epoch 51 train_loss : 0.17918705940246582 , val_loss : 0.16914337873458862, val_acc : 0.959872683869501\n",
      "52\n",
      "epoch 52 train_loss : 0.17918702960014343 , val_loss : 0.16914330422878265, val_acc : 0.959872683869501\n",
      "53\n",
      "epoch 53 train_loss : 0.17918701469898224 , val_loss : 0.16914328932762146, val_acc : 0.959872683869501\n",
      "54\n",
      "epoch 54 train_loss : 0.17918701469898224 , val_loss : 0.16914328932762146, val_acc : 0.959872683869501\n",
      "55\n",
      "epoch 55 train_loss : 0.17918699979782104 , val_loss : 0.16914376616477966, val_acc : 0.959872683869501\n",
      "56\n",
      "epoch 56 train_loss : 0.17918701469898224 , val_loss : 0.16914372146129608, val_acc : 0.959872683869501\n",
      "57\n",
      "epoch 57 train_loss : 0.17918701469898224 , val_loss : 0.1691436767578125, val_acc : 0.959872683869501\n",
      "58\n",
      "epoch 58 train_loss : 0.17918701469898224 , val_loss : 0.1691436618566513, val_acc : 0.959872683869501\n",
      "59\n",
      "epoch 59 train_loss : 0.17918699979782104 , val_loss : 0.16914361715316772, val_acc : 0.959872683869501\n"
     ]
    }
   ],
   "source": [
    "best_losses=1000000\n",
    "for epoch in range(60):\n",
    "    lr = adjust_learning_rate(optimizer, epoch)\n",
    "    train_loss=0\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (text,labels) in enumerate(train_loader):\n",
    "        inputs=torch.tensor(text).float()\n",
    "        inputs = Variable(inputs).cuda()\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = Variable(labels).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output,_=model(inputs)\n",
    "\n",
    "        loss=criterion(output,labels.long())\n",
    "        train_loss+=loss\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.) #rnn 계열 gradient 장치\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    #validation\n",
    "    model.eval()\n",
    "    val_loss=0\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    val_result ={}\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "        with torch.no_grad():\n",
    "            for it, (text,labels) in enumerate(val_loader):\n",
    "                inputs=torch.tensor(text).float()\n",
    "                inputs = Variable(inputs).cuda()\n",
    "                labels = torch.tensor(labels)\n",
    "                labels = Variable(labels).cuda()\n",
    "                output,_=model(inputs)\n",
    "                loss=criterion(output,labels.long())\n",
    "                val_loss+=loss\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "                acc=acc+TP+TN\n",
    "                gt_sum+=len(output)\n",
    "            val_acc=acc/gt_sum\n",
    "            print(\"epoch {} train_loss : {} , val_loss : {}, val_acc : {}\".format(epoch,train_loss/len(train_loader),val_loss/len(val_loader),val_acc))\n",
    "            f.write(\"epoch {} train_loss : {} , val_loss : {}, val_acc : {}\\n\".format(epoch,train_loss/len(train_loader),val_loss/len(val_loader),val_acc))\n",
    "            if best_losses>val_loss:\n",
    "                best_losses=val_loss\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train_best\"))#epoch 변화 확인위해\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+\"train_best\"))#train best 덮어써짐\n",
    "\n",
    "                f.write(\"epoch {} saved\\n\".format(epoch))\n",
    "            else:\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 18 14 tensor(0) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 4 13 tensor(0) tensor(13)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "dataset=weight_dir+'train_best' #best weight\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')#model weight load\n",
    "model.load_state_dict(checkpoint)\n",
    "model.cuda()\n",
    "\n",
    "#test exp\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (text,labels) in enumerate(test_loader):\n",
    "        inputs= torch.tensor(text).float()\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        output,_=model(inputs)\n",
    "\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmpark/anaconda3/envs/mm/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'game_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3994/3819408348.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#feature 만 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mgame_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgame_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'game_id' is not defined"
     ]
    }
   ],
   "source": [
    "save_dir = './' #feature 어디에 저장할지\n",
    "dataset=weight_dir+'train_best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (text,labels) in enumerate(test_loader):\n",
    "        inputs= torch.tensor(text).float()\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        _,output_f=model(inputs) #feature 만 추출\n",
    "        print(labels)\n",
    "        if game_id[0] not in result.keys():\n",
    "            result[game_id[0]]=[(output_f[0]).tolist()]\n",
    "            \n",
    "        else:\n",
    "            result[game_id[0]]+=[(output_f[0]).tolist()]\n",
    "\n",
    "#with open(weight_dir+save_dir,'video_final_feature') as f:\n",
    "#    json.dump(result,f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47cfe0b77a86444241c9d26f8eb452e44deb4d4dd9b2830dc549158d4e6f39d5"
  },
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
